{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b125ac61",
   "metadata": {},
   "source": [
    "## initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e8804",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda130c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "from functools import reduce\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ececc088",
   "metadata": {},
   "source": [
    "### configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7052f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRADE = '/home/user1/Data/'\n",
    "PATH_PORTFOLIO = '/home/user1/Data/Portfolio/'\n",
    "PRICE_PATH =  '/home/user1/Data/'\n",
    "VALID_SYMBOLS_PATH = '/home/user1/Data/'\n",
    "\n",
    "HOUR_SECONDS = 60 * 60\n",
    "MINUTE_SECONDS = 60\n",
    "\n",
    "MIN_ANALYSIS_DATE = 13980101\n",
    "MAX_ANALYSIS_DATE = 13980331\n",
    "\n",
    "N_QUANTILES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3319d2e0",
   "metadata": {},
   "source": [
    "### general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b0de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_df(df):\n",
    "    df.persist()\n",
    "    print(df.count())\n",
    "    df.show(3, False)\n",
    "\n",
    "def min_max(df):\n",
    "    return df.agg(F.min('date').alias('min_date'), F.max('date').alias('max_date')).show()\n",
    "\n",
    "def modify_time(x):\n",
    "    hour = x // 10000\n",
    "    minute = (x % 10000) // 100\n",
    "    second = x % 100\n",
    "    return HOUR_SECONDS * 3600 + MINUTE_SECONDS * 60 + second\n",
    "modify_time_udf = F.udf(modify_time, T.IntegerType())\n",
    "\n",
    "dropSpace = F.udf(lambda x: x.replace(' ', ''), T.StringType())\n",
    "\n",
    "mappingDict = {\n",
    "              'ما  ' : 'ما',\n",
    "              'جم  ' : 'جم',\n",
    "              'جمپیلن' : 'جم پیلن',\n",
    "              'افقملت' : 'افق ملت',\n",
    "              'آسپ' : 'آ س پ',\n",
    "              'آپ  ' : 'آپ',\n",
    "              'سپ  ' : 'سپ',\n",
    "              'غپاذر' : 'غپآذر',\n",
    "              'هدشت' : 'دهدشت',\n",
    "              'نگان' : 'زنگان',\n",
    "              'فبورس' : 'فرابورس',\n",
    "              'شیری' : 'دشیری',\n",
    "              'وتعان' : 'وتعاون',\n",
    "              'آس پ' : 'آ س پ',\n",
    "              'انرژی1': 'انرژی 1',\n",
    "              'انرژی2' : 'انرژی 2',\n",
    "              'انرژی3' : 'انرژی 3',\n",
    "              'انرژیح1' : 'انرژیح 1',\n",
    "              'انرژیح2' : 'انرژیح 2',\n",
    "              'انرژیح3' : 'انرژیح 3',\n",
    "              'فناوا' : 'فن آوا',\n",
    "              'فنآوا' : 'فن آوا',\n",
    "              'امینیکم' : 'امین یکم',\n",
    "              'هایوب' : 'های وب',\n",
    "              'کیبیسی' : 'کی بی سی',\n",
    "              'کیبیسیح' : 'کی بی سیح',\n",
    "              'واتوس' : 'وآتوس'\n",
    "              }\n",
    "\n",
    "def replace_arabic_characters_and_correct_symbol_names(data):\n",
    "    mapping = {\n",
    "        'ك': 'ک',\n",
    "        'گ': 'گ',\n",
    "        'دِ': 'د',\n",
    "        'بِ': 'ب',\n",
    "        'زِ': 'ز',\n",
    "        'ذِ': 'ذ',\n",
    "        'شِ': 'ش',\n",
    "        'سِ': 'س',\n",
    "        'ى': 'ی',\n",
    "        'ي': 'ی',\n",
    "    }\n",
    "    for i in mapping:\n",
    "        data = (\n",
    "            data\n",
    "            .withColumn('symbol', F.regexp_replace('symbol', i, mapping[i]))\n",
    "        )\n",
    "    data = (\n",
    "        data\n",
    "        .withColumn(\n",
    "        'symbol',\n",
    "        F.when((F.col('symbol').substr(1, 1) == 'ذ') & (F.col('symbol') != 'ذوب'), F.col('symbol').substr(2, 30)).otherwise(\n",
    "            F.col('symbol'))\n",
    "        )\n",
    "        .withColumn(\n",
    "        'symbol',\n",
    "        F.when(F.col('symbol').substr(1, 2) == 'گژ', F.col('symbol').substr(3, 30)).otherwise(\n",
    "            F.col('symbol'))\n",
    "        )\n",
    "        .withColumn(\n",
    "        'symbol',\n",
    "        F.when(F.col('symbol').substr(1, 1) == 'ژ', F.col('symbol').substr(2, 30)).otherwise(\n",
    "            F.col('symbol'))\n",
    "        )\n",
    "        .replace(mappingDict,subset=['symbol'])\n",
    "    )\n",
    "    return data\n",
    "\n",
    "spaceDeleteUDF1 = F.udf(lambda s: s.replace('\\u200d', ''), T.StringType())\n",
    "spaceDeleteUDF2 = F.udf(lambda s: s.replace('\\u200c', ''), T.StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469fdf04",
   "metadata": {},
   "source": [
    "### Spark instaniation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36e89f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:12:02 WARN Utils: Your hostname, user1-ubuntu resolves to a loopback address: 127.0.1.1; using 172.16.32.107 instead (on interface eth0)\n",
      "22/02/22 17:12:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/user1/.local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/22 17:12:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf()\n",
    "conf.set('spark.driver.memory', '130g').set('spark.shuffle.service.index.cache.size', '1g').setAppName('Practice') #.set('spark.executer.cores', '58')\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c797ab",
   "metadata": {},
   "source": [
    "## data inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348884b3",
   "metadata": {},
   "source": [
    "### load daily trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f79ea4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27464132\n",
      "+--------+------+------+------------------------------------+------------------------------------+------------+----------+--------------------+\n",
      "|date    |time  |symbol|buyerAccountId                      |sellerAccountId                     |nTradeShares|tradePrice|tradeSettlementValue|\n",
      "+--------+------+------+------------------------------------+------------------------------------+------------+----------+--------------------+\n",
      "|13980110|115203|ثامان |ECC77A89-C9AD-494F-8B49-4F178C2D7F3E|2AF253F2-7044-44EA-858B-09DA6A224E86|24928       |3390.0    |8.450592            |\n",
      "|13980110|120816|ثاباد |9288482E-9715-4DE3-AAB6-D20D2FB157DE|02F7AA8E-29E7-4594-ACD4-FDAEE6BA957B|2000        |2320.0    |0.464               |\n",
      "|13980110|122054|آسیا  |5D9B391F-C8F1-48E8-A9D0-2215FFCB9FCB|C7470FDD-F4DA-472D-895A-EBD1ED249BAD|7573        |1876.0    |1.4206948           |\n",
      "+--------+------+------+------------------------------------+------------------------------------+------------+----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_trade_df = spark.read.parquet(PATH_TRADE + \"tradeData.parquet\")\n",
    "\n",
    "display_df(raw_trade_df)\n",
    "# capital increas?\n",
    "# make sure trade value and number of shares are not zero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e1526d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:===================================================>     (60 + 7) / 67]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|min_date|max_date|\n",
      "+--------+--------+\n",
      "|13980105|13980329|\n",
      "+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "min_max(raw_trade_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64043f6e",
   "metadata": {},
   "source": [
    "### load portfolio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d850965f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12109854\n",
      "+------+--------+------------------------------------+------+\n",
      "|SPSYMB|SPDATE  |SPACC#                              |SPTROH|\n",
      "+------+--------+------------------------------------+------+\n",
      "|خساپا |13980105|7432095E-8BDB-41E5-B841-AAD78C46548B|12956 |\n",
      "|خساپا |13980105|58EC36FA-E468-4D74-9C95-14B630E6C68F|7561  |\n",
      "|ثامان |13980105|0DCCFEE2-FA77-44D8-A27D-139B38EDD72A|3824  |\n",
      "+------+--------+------------------------------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_portfolio_df = (\n",
    "    spark.read.parquet(PATH_PORTFOLIO + '{}'.format('portfolio.parquet'))\n",
    ")\n",
    "\n",
    "for i in raw_portfolio_df.columns:\n",
    "    raw_portfolio_df = (\n",
    "        raw_portfolio_df\n",
    "        .withColumn(i, spaceDeleteUDF1(i))\n",
    "        .withColumn(i, spaceDeleteUDF2(i))\n",
    "    )\n",
    "    \n",
    "for i in ['SPTROH', 'SPBYNS', 'SPBYNR', 'SPSLNS', 'SPPLGE']:\n",
    "    raw_portfolio_df = (\n",
    "        raw_portfolio_df\n",
    "        .withColumn(i, F.col(i).cast('int'))\n",
    "    )\n",
    "    \n",
    "raw_portfolio_df = (\n",
    "    raw_portfolio_df\n",
    "    .withColumn('SPTROH', F.col('SPTROH') + F.col('SPBYNS') + F.col('SPBYNR') + F.col('SPSLNS') + F.col('SPPLGE'))\n",
    "    .select(\n",
    "        'SPSYMB',\n",
    "        'SPDATE',\n",
    "        'SPACC#',\n",
    "        'SPTROH'\n",
    "    )\n",
    "    .dropDuplicates()\n",
    "    )\n",
    "\n",
    "display_df(raw_portfolio_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dab27c",
   "metadata": {},
   "source": [
    "### load daily price and shrout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00fd371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:15:30 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:15:47 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+--------------------+------+---------+\n",
      "|date    |symbol|close_price|close_price_adjusted|shrout|mktcap   |\n",
      "+--------+------+-----------+--------------------+------+---------+\n",
      "|13980221|آ س پ |1366.0     |1249.0              |9.0E8 |122940.0 |\n",
      "|13980125|آتیمس |30009.0    |30380.0             |1.0E9 |3000900.0|\n",
      "|13980202|آتیمس |30880.0    |31262.0             |1.0E9 |3088000.0|\n",
      "+--------+------+-----------+--------------------+------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "price_df = (\n",
    "    spark.read.parquet(PRICE_PATH.format('Cleaned_Stock_Prices_14001116.parquet'))\n",
    "    .filter(F.col('jalaliDate').between(MIN_ANALYSIS_DATE, MAX_ANALYSIS_DATE))\n",
    "    .select(\n",
    "        F.col('jalaliDate').alias('date'),\n",
    "        F.col('name').alias('symbol'),\n",
    "        'close_price',\n",
    "        'close_price_adjusted',\n",
    "        'shrout',\n",
    "        (F.col('MarketCap') / 10**7).alias('mktcap')\n",
    "    )\n",
    "    .dropDuplicates()\n",
    ")\n",
    "\n",
    "price_df = replace_arabic_characters_and_correct_symbol_names(price_df)\n",
    "\n",
    "display_df(price_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1e07d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_price_df = spark.createDataFrame(pd.DataFrame({\n",
    "                                                        'date' : [13980105],\n",
    "                                                        'symbol' : ['ومشان'],\n",
    "                                                        'close_price' : [561],\n",
    "                                                        'close_price_adjusted' : [np.nan],\n",
    "                                                        'shrout' : [20000000],\n",
    "                                                        'mktcap' : [1122]\n",
    "                                                    })\n",
    "                                      )\n",
    "\n",
    "price_df = price_df.union(added_price_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f9068e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:15:48 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "[Stage 25:=========================================>           (200 + 58) / 258]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|min_date|max_date|\n",
      "+--------+--------+\n",
      "|13980105|13980329|\n",
      "+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "min_max(price_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dcc44b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:15:52 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:15:56 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:15:58 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:16:06 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|count(symbol)|\n",
      "+-------------+\n",
      "|         1031|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:16:07 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:16:10 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|count(symbol)|\n",
      "+-------------+\n",
      "|         1014|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:16:11 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:16:13 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|count(symbol)|\n",
      "+-------------+\n",
      "|         1024|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "MIN_PRICE_DATE = price_df.agg(F.min('date')).collect()[0][0]\n",
    "MAX_PRICE_DATE = price_df.agg(F.max('date')).collect()[0][0]\n",
    "\n",
    "price_df.agg(F.countDistinct('symbol')).show()\n",
    "price_df.filter(F.col('date') == MIN_PRICE_DATE).agg(F.countDistinct('symbol')).show()\n",
    "price_df.filter(F.col('date') == MAX_PRICE_DATE).agg(F.countDistinct('symbol')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5a63c",
   "metadata": {},
   "source": [
    "### load valid symbols data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f80d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:16:22 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:16:26 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:16:26 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|symbol|\n",
      "+------+\n",
      "|دسبحان|\n",
      "|فن آوا|\n",
      "|دلقما |\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valid_symbols_df = (\n",
    "    spark.read.parquet(VALID_SYMBOLS_PATH + '{}'.format('Symbols_14001116.parquet'))\n",
    "    .select('Ticker')\n",
    "    .withColumnRenamed('Ticker','symbol')\n",
    "    .dropDuplicates()\n",
    ")\n",
    "\n",
    "valid_symbols_df = replace_arabic_characters_and_correct_symbol_names(valid_symbols_df)\n",
    "\n",
    "display_df(valid_symbols_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44389b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:16:27 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:16:28 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:16:30 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:16:31 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|symbol|\n",
      "+------+\n",
      "|دسبحان|\n",
      "|فن آوا|\n",
      "|دلقما |\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:16:32 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:16:33 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:16:35 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:16:35 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|symbol|\n",
      "+------+\n",
      "|دسبحان|\n",
      "|فن آوا|\n",
      "|بکابح |\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:16:36 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:16:39 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:16:40 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:16:41 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|symbol|\n",
      "+------+\n",
      "|دسبحان|\n",
      "|فن آوا|\n",
      "|بکابح |\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:16:42 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:16:44 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:16:44 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|symbol|\n",
      "+------+\n",
      "|دسبحان|\n",
      "|فن آوا|\n",
      "|بکابح |\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ETFs = ['آتیمس',\n",
    " 'آرمانی',\n",
    " 'آساس',\n",
    " 'آسام',\n",
    " 'آسامید',\n",
    " 'آوا',\n",
    " 'آکورد',\n",
    " 'آگاس',\n",
    " 'ارزش',\n",
    " 'اطلس',\n",
    " 'اعتماد',\n",
    " 'افران',\n",
    " 'افق ملت',\n",
    " 'الماس',\n",
    " 'امین یکم',\n",
    " 'انار',\n",
    " 'اهرم',\n",
    " 'اوج',\n",
    " 'اوصتا',\n",
    " 'بذر',\n",
    " 'تاراز',\n",
    " 'تصمیم',\n",
    " 'ثبات',\n",
    " 'ثروتم',\n",
    " 'ثمین',\n",
    " 'ثهام',\n",
    " 'خاتم',\n",
    " 'دارا',\n",
    " 'دارا یکم',\n",
    " 'داریوش',\n",
    " 'داریک',\n",
    " 'رماس',\n",
    " 'رویش',\n",
    " 'زر',\n",
    " 'زرین',\n",
    " 'زیتون',\n",
    " 'سبز',\n",
    " 'سحرخیز',\n",
    " 'سخند',\n",
    " 'سرو',\n",
    " 'سپاس',\n",
    " 'سپر',\n",
    " 'سپیدما',\n",
    " 'سیناد',\n",
    " 'صایند',\n",
    " 'صغرب',\n",
    " 'صنم',\n",
    " 'صنوین',\n",
    " 'طلا',\n",
    " 'عیار',\n",
    " 'فراز',\n",
    " 'فردا',\n",
    " 'فیروزا',\n",
    " 'مانی',\n",
    " 'مثقال',\n",
    " 'مدیر',\n",
    " 'نارون',\n",
    " 'نسیم',\n",
    " 'نهال',\n",
    " 'هامرز',\n",
    " 'همای',\n",
    " 'وبازار',\n",
    " 'ویستا',\n",
    " 'پادا',\n",
    " 'پارند',\n",
    " 'پالایش',\n",
    " 'کارا',\n",
    " 'کاردان',\n",
    " 'کاریس',\n",
    " 'کارین',\n",
    " 'کامیاب',\n",
    " 'کمند',\n",
    " 'کهربا',\n",
    " 'کیان',\n",
    " 'گنبد',\n",
    " 'گنجین',\n",
    " 'گنجینه',\n",
    " 'گوهر',\n",
    " 'یارا',\n",
    " 'یاقوت',\n",
    " 'فیروزه',]\n",
    "ETFs = [(i,) for i in ETFs]\n",
    "ETFs = spark.createDataFrame(data= ETFs,  schema= valid_symbols_df.schema)\n",
    "valid_symbols_df = valid_symbols_df.union(ETFs).dropDuplicates()\n",
    "display_df(valid_symbols_df)\n",
    "\n",
    "\n",
    "right_offers = ['آ س پح',\n",
    " 'آرمانح',\n",
    " 'آریانح',\n",
    " 'آرینح',\n",
    " 'آکنتورح',\n",
    " 'اتکامح',\n",
    " 'اتکایح',\n",
    " 'اخابرح',\n",
    " 'ارفعح',\n",
    " 'اعتلاح',\n",
    " 'افراح',\n",
    " 'افقح',\n",
    " 'البرزح',\n",
    " 'امیدح',\n",
    " 'امینح',\n",
    " 'اوانح',\n",
    " 'بالبرح',\n",
    " 'بایکاح',\n",
    " 'بترانسح',\n",
    " 'بتکح',\n",
    " 'بدکوح',\n",
    " 'برکتح',\n",
    " 'بزاگرسح',\n",
    " 'بساماح',\n",
    " 'بسویچح',\n",
    " 'بشهابح',\n",
    " 'بصباح',\n",
    " 'بفجرح',\n",
    " 'بموتوح',\n",
    " 'بمیلاح',\n",
    " 'بنوح',\n",
    " 'بنیروح',\n",
    " 'بهپاکح',\n",
    " 'بپاسح',\n",
    " 'بکابح',\n",
    " 'بکامح',\n",
    " 'بکهنوجح',\n",
    " 'تاصیکوح',\n",
    " 'تاپکیشح',\n",
    " 'تاپیکوح',\n",
    " 'تایراح',\n",
    " 'تجلیح',\n",
    " 'تشتادح',\n",
    " 'تفیروح',\n",
    " 'تلیسهح',\n",
    " 'تماوندح',\n",
    " 'تمحرکهح',\n",
    " 'تملتح',\n",
    " 'تنوینح',\n",
    " 'توریلح',\n",
    " 'تپمپیح',\n",
    " 'تپکوح',\n",
    " 'تکشاح',\n",
    " 'تکمباح',\n",
    " 'تکنارح',\n",
    " 'تکنوح',\n",
    " 'تیپیکوح',\n",
    " 'ثابادح',\n",
    " 'ثاختح',\n",
    " 'ثاصفاح',\n",
    " 'ثالوندح',\n",
    " 'ثامانح',\n",
    " 'ثاژنح',\n",
    " 'ثباغح',\n",
    " 'ثترانح',\n",
    " 'ثرودح',\n",
    " 'ثشاهدح',\n",
    " 'ثشرقح',\n",
    " 'ثعتماح',\n",
    " 'ثعمراح',\n",
    " 'ثغربح',\n",
    " 'ثفارسح',\n",
    " 'ثقزویح',\n",
    " 'ثمسکنح',\n",
    " 'ثنورح',\n",
    " 'ثنوساح',\n",
    " 'ثپردیسح',\n",
    " 'جمح',\n",
    " 'جهرمح',\n",
    " 'حبندرح',\n",
    " 'حتایدح',\n",
    " 'حتوکاح',\n",
    " 'حخزرح',\n",
    " 'حسیناح',\n",
    " 'حفاریح',\n",
    " 'حپارساح',\n",
    " 'حپتروح',\n",
    " 'حکشتیح',\n",
    " 'حکمتح',\n",
    " 'خاذینح',\n",
    " 'خاهنح',\n",
    " 'خاورح',\n",
    " 'خبهمنح',\n",
    " 'ختراکح',\n",
    " 'ختورح',\n",
    " 'ختوقاح',\n",
    " 'خدیزلح',\n",
    " 'خریختح',\n",
    " 'خرینگح',\n",
    " 'خزامیاح',\n",
    " 'خزرح',\n",
    " 'خساپاح',\n",
    " 'خشرقح',\n",
    " 'خصدراح',\n",
    " 'خفناورح',\n",
    " 'خفنرح',\n",
    " 'خفولاح',\n",
    " 'خلنتح',\n",
    " 'خمحرکهح',\n",
    " 'خمحورح',\n",
    " 'خمهرح',\n",
    " 'خموتورح',\n",
    " 'خنصیرح',\n",
    " 'خودروح',\n",
    " 'خوسازح',\n",
    " 'خپارسح',\n",
    " 'خپویشح',\n",
    " 'خچرخشح',\n",
    " 'خکارح',\n",
    " 'خکاوهح',\n",
    " 'خکمکح',\n",
    " 'خگسترح',\n",
    " 'دابورح',\n",
    " 'دارابح',\n",
    " 'داروح',\n",
    " 'داسوهح',\n",
    " 'دالبرح',\n",
    " 'دامینح',\n",
    " 'داناح',\n",
    " 'دبالکح',\n",
    " 'دتمادح',\n",
    " 'دتهرانح',\n",
    " 'دتوزیعح',\n",
    " 'دتولیح',\n",
    " 'دتولیدح',\n",
    " 'دجابرح',\n",
    " 'ددامح',\n",
    " 'درازکح',\n",
    " 'درهآورح',\n",
    " 'دروزح',\n",
    " 'دزهراویح',\n",
    " 'دسانکوح',\n",
    " 'دسبحاح',\n",
    " 'دسبحانح',\n",
    " 'دسیناح',\n",
    " 'دشیریح',\n",
    " 'دشیمیح',\n",
    " 'دعبیدح',\n",
    " 'دفاراح',\n",
    " 'دفراح',\n",
    " 'دقاضیح',\n",
    " 'دلرح',\n",
    " 'دلقماح',\n",
    " 'دهدشتح',\n",
    " 'دپارسح',\n",
    " 'دکوثرح',\n",
    " 'دکپسولح',\n",
    " 'دکیمیح',\n",
    " 'دیرانح',\n",
    " 'رانفورح',\n",
    " 'رتاپح',\n",
    " 'رتکوح',\n",
    " 'رمپناح',\n",
    " 'رنیکح',\n",
    " 'رپارسح',\n",
    " 'رکیشح',\n",
    " 'زفکاح',\n",
    " 'زقیامح',\n",
    " 'زملاردح',\n",
    " 'زمگساح',\n",
    " 'زنجانح',\n",
    " 'زنگانح',\n",
    " 'زگلدشتح',\n",
    " 'ساذریح',\n",
    " 'سارابح',\n",
    " 'ساربیلح',\n",
    " 'ساروجح',\n",
    " 'سارومح',\n",
    " 'سامانح',\n",
    " 'سباقرح',\n",
    " 'سبجنوح',\n",
    " 'سبحانح',\n",
    " 'سبهانح',\n",
    " 'سترانح',\n",
    " 'سجامح',\n",
    " 'سخاشح',\n",
    " 'سخزرح',\n",
    " 'سخوافح',\n",
    " 'سخوزح',\n",
    " 'سدبیرح',\n",
    " 'سدشتح',\n",
    " 'سدورح',\n",
    " 'سرودح',\n",
    " 'سرچشمهح',\n",
    " 'سشرقح',\n",
    " 'سشمالح',\n",
    " 'سصفهاح',\n",
    " 'سصوفیح',\n",
    " 'سغربح',\n",
    " 'سفارح',\n",
    " 'سفارسح',\n",
    " 'سفارودح',\n",
    " 'سفاسیتح',\n",
    " 'سفانوح',\n",
    " 'سقاینح',\n",
    " 'سلارح',\n",
    " 'سمازنح',\n",
    " 'سمایهح',\n",
    " 'سمگاح',\n",
    " 'سنوینح',\n",
    " 'سنیرح',\n",
    " 'سهرمزح',\n",
    " 'سهگمتح',\n",
    " 'سپاهاح',\n",
    " 'سپح',\n",
    " 'سپرمیح',\n",
    " 'سکارونح',\n",
    " 'سکردح',\n",
    " 'سکرماح',\n",
    " 'سیدکوح',\n",
    " 'سیلامح',\n",
    " 'شاراکح',\n",
    " 'شاملاح',\n",
    " 'شبریزح',\n",
    " 'شبهرنح',\n",
    " 'شتهرانح',\n",
    " 'شتولیح',\n",
    " 'شتوکاح',\n",
    " 'شجمح',\n",
    " 'شخارکح',\n",
    " 'شدوصح',\n",
    " 'شرانلح',\n",
    " 'شرنگیح',\n",
    " 'شزنگح',\n",
    " 'شسمح',\n",
    " 'شسیناح',\n",
    " 'شصدفح',\n",
    " 'شصفهاح',\n",
    " 'شفاراح',\n",
    " 'شفارسح',\n",
    " 'شفنح',\n",
    " 'شلردح',\n",
    " 'شلعابح',\n",
    " 'شموادح',\n",
    " 'شنفتح',\n",
    " 'شپارسح',\n",
    " 'شپاسح',\n",
    " 'شپاکساح',\n",
    " 'شپتروح',\n",
    " 'شپدیسح',\n",
    " 'شپلیح',\n",
    " 'شپناح',\n",
    " 'شکبیرح',\n",
    " 'شکربنح',\n",
    " 'شکفح',\n",
    " 'شکلرح',\n",
    " 'شگلح',\n",
    " 'شیرازح',\n",
    " 'شیرانح',\n",
    " 'صباح',\n",
    " 'غاذرح',\n",
    " 'غالبرح',\n",
    " 'غبشهرح',\n",
    " 'غبهنوشح',\n",
    " 'غبهپاکح',\n",
    " 'غدامح',\n",
    " 'غدشتح',\n",
    " 'غسالمح',\n",
    " 'غشاذرح',\n",
    " 'غشانح',\n",
    " 'غشصفاح',\n",
    " 'غشهدابح',\n",
    " 'غشهدح',\n",
    " 'غشوکوح',\n",
    " 'غصینوح',\n",
    " 'غمارگح',\n",
    " 'غمشهدح',\n",
    " 'غمهراح',\n",
    " 'غمینوح',\n",
    " 'غنابح',\n",
    " 'غنوشح',\n",
    " 'غنیلیح',\n",
    " 'غویتاح',\n",
    " 'غپاکح',\n",
    " 'غپینوح',\n",
    " 'غچینح',\n",
    " 'غگرجیح',\n",
    " 'غگرگح',\n",
    " 'غگلح',\n",
    " 'فاذرح',\n",
    " 'فاراکح',\n",
    " 'فاسمینح',\n",
    " 'فافزاح',\n",
    " 'فالبرح',\n",
    " 'فالومح',\n",
    " 'فاماح',\n",
    " 'فاهوازح',\n",
    " 'فایراح',\n",
    " 'فباهنرح',\n",
    " 'فبیراح',\n",
    " 'فجامح',\n",
    " 'فجرح',\n",
    " 'فجوشح',\n",
    " 'فخاسح',\n",
    " 'فخوزح',\n",
    " 'فرآورح',\n",
    " 'فرومح',\n",
    " 'فزرینح',\n",
    " 'فساح',\n",
    " 'فسازانح',\n",
    " 'فسدیدح',\n",
    " 'فسربح',\n",
    " 'فسپاح',\n",
    " 'فلاتح',\n",
    " 'فلامیح',\n",
    " 'فلولهح',\n",
    " 'فماکح',\n",
    " 'فملیح',\n",
    " 'فن آواح',\n",
    " 'فنفتح',\n",
    " 'فنوالح',\n",
    " 'فنوردح',\n",
    " 'فولادح',\n",
    " 'فولاژح',\n",
    " 'فولایح',\n",
    " 'فوکاح',\n",
    " 'فپنتاح',\n",
    " 'قاسمح',\n",
    " 'قجامح',\n",
    " 'قرنح',\n",
    " 'قزوینح',\n",
    " 'قشرینح',\n",
    " 'قشهدح',\n",
    " 'قشکرح',\n",
    " 'قشیرح',\n",
    " 'قصفهاح',\n",
    " 'قلرستح',\n",
    " 'قنقشح',\n",
    " 'قنیشاح',\n",
    " 'قپارسح',\n",
    " 'لابساح',\n",
    " 'لازماح',\n",
    " 'لبوتانح',\n",
    " 'لخانهح',\n",
    " 'لخزرح',\n",
    " 'لراداح',\n",
    " 'لسرماح',\n",
    " 'لوتوسح',\n",
    " 'لپیامح',\n",
    " 'لکماح',\n",
    " 'مادیراح',\n",
    " 'مدارانح',\n",
    " 'مرقامح',\n",
    " 'معیارح',\n",
    " 'ملتح',\n",
    " 'میدکوح',\n",
    " 'میهنح',\n",
    " 'نبروجح',\n",
    " 'نتوسح',\n",
    " 'نشیراح',\n",
    " 'نمرینوح',\n",
    " 'نوینح',\n",
    " 'نیروح',\n",
    " 'هجرتح',\n",
    " 'همراهح',\n",
    " 'وآذرح',\n",
    " 'وآرینح',\n",
    " 'وآفریح',\n",
    " 'وآیندح',\n",
    " 'واتیح',\n",
    " 'وارسح',\n",
    " 'واعتبارح',\n",
    " 'والبرح',\n",
    " 'وامیدح',\n",
    " 'وانصارح',\n",
    " 'وبانکح',\n",
    " 'وبشهرح',\n",
    " 'وبملتح',\n",
    " 'وبهمنح',\n",
    " 'وبوعلیح',\n",
    " 'وبیمهح',\n",
    " 'وتجارتح',\n",
    " 'وتعاونح',\n",
    " 'وتوسح',\n",
    " 'وتوسمح',\n",
    " 'وتوسکاح',\n",
    " 'وتوشهح',\n",
    " 'وتوصاح',\n",
    " 'وتوکاح',\n",
    " 'وثوقح',\n",
    " 'وحافظح',\n",
    " 'وخارزمح',\n",
    " 'وخاورح',\n",
    " 'وداناح',\n",
    " 'ودیح',\n",
    " 'ورازیح',\n",
    " 'ورناح',\n",
    " 'وزمینح',\n",
    " 'وساختح',\n",
    " 'وساپاح',\n",
    " 'وسدیدح',\n",
    " 'وسرمدح',\n",
    " 'وسناح',\n",
    " 'وسپهح',\n",
    " 'وسکابح',\n",
    " 'وسیناح',\n",
    " 'وسینح',\n",
    " 'وشمالح',\n",
    " 'وصناح',\n",
    " 'وصندوقح',\n",
    " 'وصنعتح',\n",
    " 'وغدیرح',\n",
    " 'وقوامح',\n",
    " 'ولبهمنح',\n",
    " 'ولتجارح',\n",
    " 'ولرازح',\n",
    " 'ولساپاح',\n",
    " 'ولشرقح',\n",
    " 'ولصنمح',\n",
    " 'ولغدرح',\n",
    " 'ولقمانح',\n",
    " 'ولملتح',\n",
    " 'ولیزح',\n",
    " 'ومعادنح',\n",
    " 'وملتح',\n",
    " 'ومللح',\n",
    " 'وملیح',\n",
    " 'ونفتح',\n",
    " 'ونوینح',\n",
    " 'ونیروح',\n",
    " 'ونیکیح',\n",
    " 'وهامونح',\n",
    " 'وهورح',\n",
    " 'وپارسح',\n",
    " 'وپاسارح',\n",
    " 'وپتروح',\n",
    " 'وپخشح',\n",
    " 'وکادوح',\n",
    " 'وکارح',\n",
    " 'وکوثرح',\n",
    " 'وگردشح',\n",
    " 'پارتاح',\n",
    " 'پارسانح',\n",
    " 'پارسیانح',\n",
    " 'پاساح',\n",
    " 'پاکشوح',\n",
    " 'پتایرح',\n",
    " 'پترولح',\n",
    " 'پخشح',\n",
    " 'پدرخشح',\n",
    " 'پرداختح',\n",
    " 'پردیسح',\n",
    " 'پسهندح',\n",
    " 'پشاهنح',\n",
    " 'پلاستح',\n",
    " 'پلاسکح',\n",
    " 'پلولهح',\n",
    " 'پنکاح',\n",
    " 'پکرمانح',\n",
    " 'پکویرح',\n",
    " 'پکیانح',\n",
    " 'چافستح',\n",
    " 'چفیبرح',\n",
    " 'چکارلح',\n",
    " 'چکارنح',\n",
    " 'چکاوهح',\n",
    " 'کابگنح',\n",
    " 'کاذرح',\n",
    " 'کازروح',\n",
    " 'کاسپینح',\n",
    " 'کالبرح',\n",
    " 'کاماح',\n",
    " 'کاوهح',\n",
    " 'کایتاح',\n",
    " 'کبافقح',\n",
    " 'کترامح',\n",
    " 'کتوکاح',\n",
    " 'کحافظح',\n",
    " 'کخاکح',\n",
    " 'کدماح',\n",
    " 'کرازیح',\n",
    " 'کرماشاح',\n",
    " 'کرویح',\n",
    " 'کزغالح',\n",
    " 'کساوهح',\n",
    " 'کساپاح',\n",
    " 'کسراح',\n",
    " 'کسرامح',\n",
    " 'کسعدیح',\n",
    " 'کطبسح',\n",
    " 'کفرآورح',\n",
    " 'کفراح',\n",
    " 'کفپارسح',\n",
    " 'کقزویح',\n",
    " 'کلوندح',\n",
    " 'کماسهح',\n",
    " 'کمرجانح',\n",
    " 'کمنگنزح',\n",
    " 'کمیناح',\n",
    " 'کنورح',\n",
    " 'کهرامح',\n",
    " 'کهمداح',\n",
    " 'کوثرح',\n",
    " 'کورزح',\n",
    " 'کویرح',\n",
    " 'کپارسح',\n",
    " 'کپاناح',\n",
    " 'کپرورح',\n",
    " 'کپشیرح',\n",
    " 'کچادح',\n",
    " 'کگازح',\n",
    " 'کگلح',\n",
    " 'کگهرح',\n",
    " 'کی بی سیح',\n",
    " 'کیسونح',\n",
    " 'گوهرانح',\n",
    " 'گکیشح']\n",
    "right_offers = [(i,) for i in right_offers]\n",
    "right_offers = spark.createDataFrame(data= right_offers,  schema= valid_symbols_df.schema)\n",
    "valid_symbols_df = valid_symbols_df.union(right_offers).dropDuplicates()\n",
    "display_df(valid_symbols_df)\n",
    "\n",
    "handly_collected_valid_symbols = [\n",
    "    'فسلير',\n",
    "    'نگین',\n",
    "    'نیرو',\n",
    "    'غگز',\n",
    "    'آینده'\n",
    "]\n",
    "handly_collected_valid_symbols = [(i,) for i in handly_collected_valid_symbols]\n",
    "handly_collected_valid_symbols = spark.createDataFrame(data= handly_collected_valid_symbols,  schema= valid_symbols_df.schema)\n",
    "valid_symbols_df = valid_symbols_df.union(handly_collected_valid_symbols).dropDuplicates()\n",
    "display_df(valid_symbols_df)\n",
    "\n",
    "\n",
    "invalid_symbols = [\n",
    "                    'وکوثر',\n",
    "                    'حکمت',\n",
    "                    'ومهر',\n",
    "                    'جوین',\n",
    "                    'وقوام',\n",
    "                    'ممسنی',\n",
    "                    'غناب',\n",
    "                    'کارا',\n",
    "                    'کاوه',\n",
    "                    'گنگین',\n",
    "                    'وپویا',\n",
    "                    'ولپارس',\n",
    "                    'نوری',\n",
    "                    'شجی',\n",
    "                    'ثعمسا',\n",
    "                    'بگیلان',\n",
    "                    'بجهرم',\n",
    "                    'آرمانح',\n",
    "                    'شساخت',\n",
    "                    'ثخوز',\n",
    "                    'قاروم', # capital increase\n",
    "                    'امید',\n",
    "                    'وهنر',\n",
    "                    'تنوین',\n",
    "                    'وگردش',\n",
    "                    'آریان', # two different stocks with the same symbol\n",
    "                    'وآتوس', \n",
    "                    'همراه' # capital increase!\n",
    "    \n",
    "]\n",
    "\n",
    "valid_symbols_df = valid_symbols_df.filter(~F.col('symbol').isin(invalid_symbols))\n",
    "display_df(valid_symbols_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1ec79",
   "metadata": {},
   "source": [
    "## data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7742e756",
   "metadata": {},
   "source": [
    "### prepare trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f685558c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:16:45 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:16:47 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26223382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:17:02 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----------------+------+------------+----------+--------------------+------------------------------------+------------------------------------+\n",
      "|date    |time  |secondsWithinDay|symbol|nTradeShares|tradePrice|tradeSettlementValue|buyerAccountId                      |sellerAccountId                     |\n",
      "+--------+------+----------------+------+------------+----------+--------------------+------------------------------------+------------------------------------+\n",
      "|13980110|115203|12963603        |ثامان |24928       |3390.0    |8.450592            |ECC77A89-C9AD-494F-8B49-4F178C2D7F3E|2AF253F2-7044-44EA-858B-09DA6A224E86|\n",
      "|13980110|120816|12963616        |ثاباد |2000        |2320.0    |0.464               |9288482E-9715-4DE3-AAB6-D20D2FB157DE|02F7AA8E-29E7-4594-ACD4-FDAEE6BA957B|\n",
      "|13980110|122054|12963654        |آسیا  |7573        |1876.0    |1.4206948           |5D9B391F-C8F1-48E8-A9D0-2215FFCB9FCB|C7470FDD-F4DA-472D-895A-EBD1ED249BAD|\n",
      "+--------+------+----------------+------+------------+----------+--------------------+------------------------------------+------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trade_df = (\n",
    "    raw_trade_df\n",
    "    .withColumn('secondsWithinDay', modify_time_udf('time'))\n",
    "    .join(valid_symbols_df, on = ['symbol'], how = 'inner')\n",
    "    .select(\n",
    "        'date',\n",
    "        'time',\n",
    "        'secondsWithinDay',\n",
    "        'symbol',\n",
    "        'nTradeShares',\n",
    "        'tradePrice',\n",
    "        'tradeSettlementValue',\n",
    "        dropSpace(F.col('buyerAccountId')).alias('buyerAccountId'),\n",
    "        dropSpace(F.col('sellerAccountId')).alias('sellerAccountId')\n",
    "    )\n",
    ")\n",
    "\n",
    "display_df(trade_df)\n",
    "# Note: 'time' columns is not reliable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "770cc438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:17:03 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:17:04 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing nTradeShares:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:17:06 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:17:07 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing tradeSettlementValue:  0.0\n"
     ]
    }
   ],
   "source": [
    "print('missing nTradeShares: ', round(trade_df.filter(F.col('nTradeShares') == 0).count() / trade_df.count(), 5))\n",
    "print('missing tradeSettlementValue: ', round(trade_df.filter(F.col('tradeSettlementValue') == 0).count() / trade_df.count(), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc780728",
   "metadata": {},
   "source": [
    "### prepare initial portfolio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9740e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12109854\n",
      "+--------+------+------------------------------------+-----------+\n",
      "|date    |symbol|accountId                           |nHeldShares|\n",
      "+--------+------+------------------------------------+-----------+\n",
      "|13980105|خساپا |7432095E-8BDB-41E5-B841-AAD78C46548B|12956      |\n",
      "|13980105|خساپا |58EC36FA-E468-4D74-9C95-14B630E6C68F|7561       |\n",
      "|13980105|ثامان |0DCCFEE2-FA77-44D8-A27D-139B38EDD72A|3824       |\n",
      "+--------+------+------------------------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mapping = (\n",
    "    dict(\n",
    "    zip(\n",
    "        ['SPDATE', 'SPSYMB', 'SPACC#', 'SPTROH'],\n",
    "        ['date', 'symbol', 'accountId', 'nHeldShares'],\n",
    "    )\n",
    "    )\n",
    ")\n",
    "\n",
    "portfolio_df = (\n",
    "    raw_portfolio_df\n",
    "    .select(\n",
    "    [F.col(c).alias(mapping.get(c, c)) for c in raw_portfolio_df.columns]\n",
    "    )\n",
    "    .select(\n",
    "        'date',\n",
    "        'symbol',\n",
    "        dropSpace(F.col('accountId')).alias('accountId'),\n",
    "        'nHeldShares'\n",
    "    )\n",
    ")\n",
    "\n",
    "portfolio_df = replace_arabic_characters_and_correct_symbol_names(portfolio_df)\n",
    "display_df(portfolio_df)\n",
    "\n",
    "\n",
    "replaceChar = F.udf(lambda s: s[:-1], T.StringType())\n",
    "\n",
    "def agg(x):\n",
    "    t = ''\n",
    "    for i in x.split(' '):\n",
    "        t += i\n",
    "    return t\n",
    "\n",
    "def cleaning(data):\n",
    "    data = (\n",
    "        data\n",
    "        .withColumn(\n",
    "        'symbol',\n",
    "        F.when(F.col('symbol').endswith('ج'),\n",
    "         replaceChar(F.col('symbol'))).otherwise(\n",
    "            F.col('symbol')\n",
    "        )\n",
    "        )\n",
    "    )\n",
    "    for i in ['اوج', 'بکهنوج', 'ساروج', 'نبروج', 'وسخراج']:\n",
    "            data = (\n",
    "                data\n",
    "                .withColumn(\n",
    "                    'symbol', F.when(F.col('symbol') == i[:-1], i).otherwise(F.col('symbol'))\n",
    "                )\n",
    "            )\n",
    "    data = data.dropDuplicates()\n",
    "    return data\n",
    "\n",
    "portfolio_df = cleaning(portfolio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f7b8d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:17:21 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:17:38 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:17:48 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8769334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:17:53 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+--------+------+-----------+\n",
      "|accountId                           |date    |symbol|nHeldShares|\n",
      "+------------------------------------+--------+------+-----------+\n",
      "|D29753D9-5B38-4CCE-8AEB-51AA71A12851|13980105|توریل |22970      |\n",
      "|24AC333D-8E93-42F6-8CD4-C1D8AE4AA12A|13980105|وایران|5449       |\n",
      "|3494AD79-A6C4-4864-854B-7951C2049D9C|13980105|کهرام |948        |\n",
      "+------------------------------------+--------+------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "portfolio_df = (\n",
    "    portfolio_df\n",
    "    .join(valid_symbols_df, on = ['symbol'], how = 'inner')\n",
    "    .groupBy(['accountId','date','symbol'])\n",
    "    .agg(\n",
    "        F.sum('nHeldShares').alias('nHeldShares')\n",
    "    )\n",
    ")\n",
    "\n",
    "display_df(portfolio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea4552df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:17:54 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    portfolio_df\n",
    "    .filter(F.col('nHeldShares') < 0)\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e36b40",
   "metadata": {},
   "source": [
    "#### check symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c87b783c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:17:57 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:17:57 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:17:58 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:18:10 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:18:15 WARN DAGScheduler: Broadcasting large task binary with size 35.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "price_symbols = price_df.select('symbol').distinct().withColumn('price', F.lit(1))\n",
    "trade_symbols = trade_df.select('symbol').distinct().withColumn('trade', F.lit(1))\n",
    "portfolio_symbols = portfolio_df.select('symbol').distinct().withColumn('portfolio', F.lit(1))\n",
    "\n",
    "symbols_df = (\n",
    "    trade_symbols\n",
    "    .join(portfolio_symbols, on = ['symbol'], how = 'outer')\n",
    "    .join(price_symbols, on = ['symbol'], how = 'outer')\n",
    ")\n",
    "\n",
    "print(symbols_df.filter(F.col('price').isNull()).select('symbol').rdd.flatMap(lambda x: x).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d8c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55809c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8bf5411",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window().partitionBy(\"symbol\").orderBy('date')\n",
    "w2 = Window().partitionBy(\"symbol\").orderBy(price_df.date.desc())\n",
    "\n",
    "price_return_df = (price_df.select('symbol', 'mktcap',\n",
    "   ((\n",
    "       F.first(\"close_price\",True).over(w2) - F.first(\"close_price\",True).over(w)\n",
    "       ) \n",
    "       / F.first(\"close_price\",True).over(w)\n",
    "       ).alias('price_return'),\n",
    "       )\n",
    "   .dropDuplicates(['symbol'])\n",
    ")\n",
    "tempt = price_df.na.drop(\n",
    "    how = 'any',\n",
    ")\n",
    "large_small_stocks =( \n",
    "    tempt[tempt.date    == 13980328]\n",
    "    .withColumn('sizeDecile', F.ntile(10).over(Window.partitionBy().orderBy('mktcap')))\n",
    ") \n",
    "price_return_df = price_return_df .join(\n",
    "    large_small_stocks.select(\n",
    "        F.col('symbol'),\n",
    "    F.col('sizeDecile'),\n",
    "    ) , on =['symbol']\n",
    ").select(\n",
    "    F.col('symbol'),\n",
    "    F.col('mktcap'),\n",
    "    F.col('price_return'),\n",
    "    F.col('sizeDecile'),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f91287f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:18:17 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:18:17 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:18:18 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:18:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:18:25 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:18:26 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:18:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:18:28 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+------------+\n",
      "|sizeDecile|medianmktcap|meanReturn|medianReturn|\n",
      "+----------+------------+----------+------------+\n",
      "|         1|    33021.78|      0.52|       0.044|\n",
      "|         2|     69850.0|      0.49|       0.389|\n",
      "|         3|    111675.0|       0.6|       0.493|\n",
      "|         4|    147260.0|      0.61|       0.514|\n",
      "|         5|    203036.0|      0.62|       0.562|\n",
      "|         6|    296800.0|      0.57|       0.519|\n",
      "|         7|    435278.0|      0.69|       0.545|\n",
      "|         8|    703566.0|      0.78|       0.558|\n",
      "|         9|   1570800.0|      0.62|       0.383|\n",
      "|        10|   8119500.0|      0.25|       0.205|\n",
      "+----------+------------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    price_return_df\n",
    "    .groupBy('sizeDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(mktcap, array(0.5))')[0], 3).alias('medianmktcap'),\n",
    "        F.round(F.mean('price_return'), 2).alias('meanReturn'),\n",
    "        F.round(F.expr('percentile(price_return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .orderBy('sizeDecile')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26270665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aadcc966",
   "metadata": {},
   "source": [
    "### general insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce268b2f",
   "metadata": {},
   "source": [
    "#### check compatibility of the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1136345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:18:32 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:18:33 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:18:43 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:18:53 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:19:19 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4371963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:19:25 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-----+---------+\n",
      "|accountId                           |trade|portfolio|\n",
      "+------------------------------------+-----+---------+\n",
      "|00019AFD-C89B-4B63-98BB-18BF5A112C6F|0    |1        |\n",
      "|000217BA-3C48-4458-8CAA-691CA19C7187|0    |1        |\n",
      "|000249D5-649B-4C99-AE9E-82AB979E80C9|0    |1        |\n",
      "+------------------------------------+-----+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_investors_df = (\n",
    "    trade_df\n",
    "    .select(F.col('buyerAccountId').alias('accountId'))\n",
    "    .union(trade_df.select(F.col('sellerAccountId').alias('accountId')))\n",
    "    .dropDuplicates()\n",
    "    .withColumn('trade', F.lit(1))\n",
    "    .join(portfolio_df.select('accountId', F.lit(1).alias('portfolio')).dropDuplicates(), on = ['accountId'], how = 'outer')\n",
    "    .fillna(0, subset = ['trade', 'portfolio'])\n",
    ")\n",
    "\n",
    "display_df(common_investors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c64cfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:19:27 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:19:31 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "[Stage 281:==========================================>         (162 + 38) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "share of missing portfolio accounts among traders: 21.13 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trade_only = common_investors_df.filter( (F.col('trade') == 1) & (F.col('portfolio') == 0)).count()\n",
    "all_trade = common_investors_df.filter(F.col('trade') == 1).count()\n",
    "\n",
    "print('share of missing portfolio accounts among traders:', round(100 * trade_only / all_trade, 2), '%')\n",
    "# It seems reasonable to attribute this missing portion to the new entrants!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcd296ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:19:34 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:19:38 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "[Stage 327:=======================================>            (150 + 50) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "share of missing trades among investors who have nitial portfolio: 86.21 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "portfolio_only = common_investors_df.filter( (F.col('trade') == 0) & (F.col('portfolio') == 1)).count()\n",
    "all_portfolio = common_investors_df.filter(F.col('portfolio') == 1).count()\n",
    "\n",
    "print('share of missing trades among investors who have nitial portfolio:', round(100 * portfolio_only / all_portfolio, 2), '%')\n",
    "# It seems reasonable to attribute this missing portion to the new entrants!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f648283",
   "metadata": {},
   "source": [
    "#### number of unique investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8734063d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:19:40 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:19:48 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:19:51 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:20:04 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "737297"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    trade_df\n",
    "    .select(F.col('buyerAccountId').alias('accountId'))\n",
    "    .union(trade_df.select(F.col('sellerAccountId').alias('accountId')))\n",
    "    .dropDuplicates()\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1404424a",
   "metadata": {},
   "source": [
    "#### number of stocks within investors' initial portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca33d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:20:06 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:20:14 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:20:17 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+---+---+----+\n",
      "|25%|50%|  mean|75%|90%| 99%|\n",
      "+---+---+------+---+---+----+\n",
      "|1.0|1.0|2.0799|2.0|4.0|15.0|\n",
      "+---+---+------+---+---+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    portfolio_df\n",
    "    .groupBy('accountId')\n",
    "    .count()\n",
    "    .agg(\n",
    "        F.expr('percentile(count, array(0.25))')[0].alias('25%'),\n",
    "        F.expr('percentile(count, array(0.50))')[0].alias('50%'),\n",
    "        F.round(F.mean('count'), 4).alias('mean'),\n",
    "        F.expr('percentile(count, array(0.75))')[0].alias('75%'),\n",
    "        F.expr('percentile(count, array(0.9))')[0].alias('90%'),\n",
    "        F.expr('percentile(count, array(0.99))')[0].alias('99%'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5bcdbb",
   "metadata": {},
   "source": [
    "#### distribution of trade value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "703087f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:20:18 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:20:25 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "[Stage 376:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+------+-----------+------------------+------+-----------------+\n",
      "|    10%|    25%|    50%|  mean|        75%|               90%|   95%|              99%|\n",
      "+-------+-------+-------+------+-----------+------------------+------+-----------------+\n",
      "|0.09855|0.25481|1.00125|3.3809|2.965605225|7.5548333000000145|12.528|32.33864667300008|\n",
      "+-------+-------+-------+------+-----------+------------------+------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    trade_df\n",
    "    .agg(\n",
    "        F.expr('percentile(tradeSettlementValue, array(0.1))')[0].alias('10%'),\n",
    "        F.expr('percentile(tradeSettlementValue, array(0.25))')[0].alias('25%'),\n",
    "        F.expr('percentile(tradeSettlementValue, array(0.50))')[0].alias('50%'),\n",
    "        F.round(F.mean('tradeSettlementValue'), 4).alias('mean'),\n",
    "        F.expr('percentile(tradeSettlementValue, array(0.75))')[0].alias('75%'),\n",
    "        F.expr('percentile(tradeSettlementValue, array(0.90))')[0].alias('90%'),\n",
    "        F.expr('percentile(tradeSettlementValue, array(0.95))')[0].alias('95%'),\n",
    "        F.expr('percentile(tradeSettlementValue, array(0.99))')[0].alias('99%')\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9a817",
   "metadata": {},
   "source": [
    "#### compare trade value of new entrants with other investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2175dbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:25:42 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:25:47 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:25:59 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:26:06 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:26:49 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "[Stage 429:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+-------------+\n",
      "|hasPortfolio|median_buyValue|mean_buyValue|\n",
      "+------------+---------------+-------------+\n",
      "|           1|            1.0|         3.44|\n",
      "|           0|           0.78|         2.57|\n",
      "+------------+---------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    common_investors_df\n",
    "    .select(F.col('accountId').alias('buyerAccountId'), F.col('portfolio').alias('hasPortfolio'))\n",
    "    .join(trade_df, on = ['buyerAccountId'], how = 'right')\n",
    "    .groupBy('hasPortfolio')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(tradeSettlementValue, array(0.5))')[0], 2).alias('median_buyValue'),\n",
    "        F.round(F.mean('tradeSettlementValue'), 2).alias('mean_buyValue')\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540fccf5",
   "metadata": {},
   "source": [
    "## make daily portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f441ad93",
   "metadata": {},
   "source": [
    "### flatten trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b418b750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:26:56 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:27:10 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:29:09 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:29:12 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:29:30 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15170298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:29:35 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------------------------------------+------------+---------+-------+\n",
      "|date    |symbol|accountId                           |nTradeShares|cashOut  |cashIn |\n",
      "+--------+------+------------------------------------+------------+---------+-------+\n",
      "|13980105|غصینو |0000448F-BDB5-48FF-9539-DB56E27ACCF9|1775        |0.0      |-1.42  |\n",
      "|13980105|ثنام  |0002412C-87BD-4EEB-8E14-00FCD817C052|7105        |0.0      |-0.9947|\n",
      "|13980105|ومعلم |0002412C-87BD-4EEB-8E14-00FCD817C052|-229        |0.0717915|0.0    |\n",
      "+--------+------+------------------------------------+------------+---------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "buy_trade_df = (\n",
    "    trade_df\n",
    "        .select(\n",
    "        'date',\n",
    "        'symbol',\n",
    "        F.col('buyerAccountId').alias('accountId'),\n",
    "        'nTradeShares',\n",
    "        (-F.col('tradeSettlementValue')).alias('settlementValue'),\n",
    "        )\n",
    ")\n",
    "\n",
    "sell_trade_df = (\n",
    "    trade_df\n",
    "        .select(\n",
    "            'date',\n",
    "            'symbol',\n",
    "            F.col('sellerAccountId').alias('accountId'),\n",
    "            (-F.col('nTradeShares')).alias('nTradeShares'),\n",
    "            F.col('tradeSettlementValue').alias('settlementValue')\n",
    "        )\n",
    ")\n",
    "\n",
    "raw_flat_trade_df = (\n",
    "    buy_trade_df\n",
    "    .union(sell_trade_df)\n",
    "    .groupBy(['date', 'symbol', 'accountId'])\n",
    "    .agg(\n",
    "        F.sum('nTradeShares').alias('nTradeShares'),\n",
    "        F.sum(F.when(F.col('settlementValue') > 0, F.col('settlementValue'))).alias('cashOut'),\n",
    "        F.sum(F.when(F.col('settlementValue') < 0, F.col('settlementValue'))).alias('cashIn')\n",
    "    )\n",
    "    .fillna(0, subset = ['cashOut', 'cashIn'])\n",
    "    .orderBy('date', 'accountId')\n",
    ")\n",
    "\n",
    "display_df(raw_flat_trade_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08ad61c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:29:36 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:29:38 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "[Stage 479:=====================================>              (146 + 54) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.42 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(round(100*raw_flat_trade_df.filter(\n",
    "    (F.col('cashIn') != 0)&\n",
    "    (F.col('cashOut') != 0) ).count() / raw_flat_trade_df.count(), 2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83403428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:29:40 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:29:42 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "[Stage 503:====================================================>  (64 + 3) / 67]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(raw_flat_trade_df.filter(F.col('nTradeShares') == 0).count())\n",
    "print(trade_df.filter(F.col('tradeSettlementValue') == 0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f63a68b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:29:44 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:29:45 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "[Stage 527:=============================================>      (176 + 24) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(raw_flat_trade_df.filter(F.col('cashIn') > 0 ).count())\n",
    "print(raw_flat_trade_df.filter(F.col('cashOut') < 0 ).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ab82a",
   "metadata": {},
   "source": [
    "### Active days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8f5c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_days_df = (\n",
    "#     raw_flat_trade_df\n",
    "#     .groupBy('accountId', 'date')\n",
    "#     .agg(\n",
    "#         F.sum('cashIn').alias('netCashIn'),\n",
    "#         F.sum('cashOut').alias('netCashOut'),\n",
    "#     )\n",
    "#     .withColumn('netCash', F.col('netCashIn') + F.col('netCashOut'))\n",
    "#     .groupBy('accountId')\n",
    "#     .agg(\n",
    "#         F.count(F.when(F.col('netCash') < 0, F.lit(1))).alias('nBuyDays'),\n",
    "#         F.count(F.when(F.col('netCash') > 0, F.lit(1))).alias('nSellDays'),\n",
    "#     )\n",
    "#     .fillna(0, subset = ['nBuyDays', 'nSellDays'])\n",
    "# )\n",
    "\n",
    "# display_df(active_days_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bde74756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_days_df.write.mode('overwrite').parquet('/home/user1/Data/activeDays.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a9ddc",
   "metadata": {},
   "source": [
    "### make daily portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a07adcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:29:51 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:30:28 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:30:49 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:30:53 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:31:20 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:31:48 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23765673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:31:59 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------------------------------------+----------+----------+---------+\n",
      "|date    |symbol|accountId                           |heldShares|netCashOut|netCashIn|\n",
      "+--------+------+------------------------------------+----------+----------+---------+\n",
      "|13980105|چکاپا |00026661-733B-49E0-AC93-ED5812290A9B|1740      |0.0       |0.0      |\n",
      "|13980221|چکاپا |00026661-733B-49E0-AC93-ED5812290A9B|0         |0.83346   |0.0      |\n",
      "|13980105|ارفع  |00029878-6EF9-49A7-B231-61DBED05BDE7|32796     |0.0       |0.0      |\n",
      "+--------+------+------------------------------------+----------+----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_daily_portfolio():\n",
    "    window = (\n",
    "        Window.partitionBy('accountId', 'symbol')\n",
    "        .orderBy('date')\n",
    "        .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "    )\n",
    "    return (F.sum('nHeldShares').over(window), F.sum('cashOut').over(window), F.sum('cashIn').over(window))\n",
    "\n",
    "raw_daily_portfolio_df = (\n",
    "    portfolio_df\n",
    "    .select('date',\n",
    "            'symbol', \n",
    "            'accountId', \n",
    "            'nHeldShares', \n",
    "            F.lit(0).alias('cashOut'),\n",
    "            F.lit(0).alias('cashIn')\n",
    "           )\n",
    "    .union(\n",
    "        raw_flat_trade_df\n",
    "        .withColumnRenamed('nTradeShares', 'nHeldShares')\n",
    "    )\n",
    "    .groupBy('date', 'symbol', 'accountId')\n",
    "    .agg(\n",
    "        F.sum('nHeldShares').alias('nHeldShares'),\n",
    "        F.sum('cashOut').alias('cashOut'),\n",
    "        F.sum('cashIn').alias('cashIn')\n",
    "    )\n",
    "    .orderBy('accountId', 'date')\n",
    "    .withColumn('heldShares', make_daily_portfolio()[0])\n",
    "    .withColumn('netCashOut', make_daily_portfolio()[1])\n",
    "    .withColumn('netCashIn', make_daily_portfolio()[2])\n",
    "    .drop('nHeldShares', 'settlementValue', 'cashIn', 'cashOut')\n",
    ")\n",
    "\n",
    "display_df(raw_daily_portfolio_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8d88ef",
   "metadata": {},
   "source": [
    "#### invalid holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1260a1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:32:03 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:32:06 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------+--------------+\n",
      "|accountId                           |symbol |invalidHolding|\n",
      "+------------------------------------+-------+--------------+\n",
      "|006BE8C1-A950-44B8-B2B5-FD293FAFD7B6|وساپا  |1             |\n",
      "|0122EC9B-B0A1-4510-8D41-55731733AE20|ومعلم  |1             |\n",
      "|01ED3611-405C-432F-B2A0-E0CC337FA36F|فرابورس|1             |\n",
      "+------------------------------------+-------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:32:09 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:32:11 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14601858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:32:16 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+------+--------+------------+---------+-------+\n",
      "|accountId                           |symbol|date    |nTradeShares|cashOut  |cashIn |\n",
      "+------------------------------------+------+--------+------------+---------+-------+\n",
      "|0000448F-BDB5-48FF-9539-DB56E27ACCF9|غصینو |13980105|1775        |0.0      |-1.42  |\n",
      "|0002412C-87BD-4EEB-8E14-00FCD817C052|ثنام  |13980105|7105        |0.0      |-0.9947|\n",
      "|0002412C-87BD-4EEB-8E14-00FCD817C052|ومعلم |13980105|-229        |0.0717915|0.0    |\n",
      "+------------------------------------+------+--------+------------+---------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:32:20 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:32:21 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23160625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:32:29 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+------+--------+----------+----------+---------+\n",
      "|accountId                           |symbol|date    |heldShares|netCashOut|netCashIn|\n",
      "+------------------------------------+------+--------+----------+----------+---------+\n",
      "|00026661-733B-49E0-AC93-ED5812290A9B|چکاپا |13980105|1740      |0.0       |0.0      |\n",
      "|00026661-733B-49E0-AC93-ED5812290A9B|چکاپا |13980221|0         |0.83346   |0.0      |\n",
      "|00029878-6EF9-49A7-B231-61DBED05BDE7|ارفع  |13980105|32796     |0.0       |0.0      |\n",
      "+------------------------------------+------+--------+----------+----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "invalid_holdings_df = (\n",
    "    raw_daily_portfolio_df\n",
    "    .filter(F.col('heldShares') < 0)\n",
    "    .select('accountId', 'symbol')\n",
    "    .dropDuplicates()\n",
    "    .withColumn('invalidHolding', F.lit(1))\n",
    ")\n",
    "display_df(invalid_holdings_df)\n",
    "\n",
    "\n",
    "flat_trade_df = (\n",
    "    raw_flat_trade_df\n",
    "    .join(invalid_holdings_df, on = ['accountId', 'symbol'], how = 'left')\n",
    "    .filter(F.col('invalidHolding').isNull())\n",
    "    .drop('invalidHolding')\n",
    ")\n",
    "display_df(flat_trade_df)\n",
    "\n",
    "\n",
    "daily_portfolio_df = (\n",
    "    raw_daily_portfolio_df\n",
    "    .join(invalid_holdings_df, on = ['accountId', 'symbol'], how = 'left')\n",
    "    .filter(F.col('invalidHolding').isNull())\n",
    "    .drop('invalidHolding')\n",
    ")\n",
    "display_df(daily_portfolio_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8921a7",
   "metadata": {},
   "source": [
    "### calculate gain from trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd50b51f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:32:31 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:32:39 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:32:42 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+------------------+-------------------+\n",
      "|accountId                           |netCashOut        |netCashIn          |\n",
      "+------------------------------------+------------------+-------------------+\n",
      "|00359890-DDBC-4ED6-85EF-6265CF05DF25|20.6662591        |-46.4365793        |\n",
      "|018942A6-B259-41C2-951E-0EB9BB59A917|434.3139919       |-485.2588124       |\n",
      "|019CED96-7DAB-4AEA-88C0-0FBA460524CD|443.46564280000007|-400.21939330000015|\n",
      "+------------------------------------+------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gain_from_trade_df = (\n",
    "    flat_trade_df\n",
    "    .groupBy('accountId')\n",
    "    .agg(\n",
    "        F.sum('cashOut').alias('netCashOut'),\n",
    "        F.sum('cashIn').alias('netCashIn'),\n",
    "    )\n",
    "#     .withColumn('sumTradeValue', F.col('netCashOut') + F.col('netCashIn'))\n",
    "#     .withColumn('absSumTradeValue', F.col('netCashOut') - F.col('netCashIn'))\n",
    ")\n",
    "\n",
    "display_df(gain_from_trade_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d852f98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(round(gain_from_trade_df.filter(F.col('sumTradeValue') < 0).count() / gain_from_trade_df.count() , 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d0b98",
   "metadata": {},
   "source": [
    "### calculate value of the initial portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99972117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:32:46 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:32:49 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:32:49 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:33:02 WARN DAGScheduler: Broadcasting large task binary with size 36.0 MiB\n",
      "22/02/22 17:33:12 WARN DAGScheduler: Broadcasting large task binary with size 36.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4215194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:33:17 WARN DAGScheduler: Broadcasting large task binary with size 36.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+---------------------+\n",
      "|accountId                           |initialPortfolioValue|\n",
      "+------------------------------------+---------------------+\n",
      "|C25D209E-2DCB-410C-9106-59E3C3E4C65A|97.1563532           |\n",
      "|0EAD58BA-E047-4097-B5D8-C3EF111727CE|253.3049908          |\n",
      "|4DFC1FC2-675B-4AB7-84A3-A54BE91FFF72|1.4946859            |\n",
      "+------------------------------------+---------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "initial_portfolio_value_df = (\n",
    "    portfolio_df\n",
    "    .join(price_df.select('date', 'symbol', 'close_price'), on = ['date', 'symbol'], how = 'left')\n",
    "    .dropna(subset = ['close_price'])\n",
    "    .join(invalid_holdings_df, on = ['accountId', 'symbol'], how = 'left')\n",
    "    .filter(F.col('invalidHolding').isNull())\n",
    "    .withColumn('value', F.col('nHeldShares') * F.col('close_price'))\n",
    "    .groupBy('accountId')\n",
    "    .agg(\n",
    "        (F.sum('value') / 10**7).alias('initialPortfolioValue')\n",
    "    )\n",
    ")\n",
    "\n",
    "display_df(initial_portfolio_value_df)\n",
    "# count after join?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "471edd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:33:20 WARN DAGScheduler: Broadcasting large task binary with size 36.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:33:26 WARN DAGScheduler: Broadcasting large task binary with size 36.0 MiB\n",
      "[Stage 815:===========================================>        (166 + 34) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(initial_portfolio_value_df.filter(F.col('initialPortfolioValue').isNull()).count())\n",
    "print(initial_portfolio_value_df.filter(F.col('initialPortfolioValue') <= 0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7555037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:33:32 WARN DAGScheduler: Broadcasting large task binary with size 36.0 MiB\n",
      "22/02/22 17:33:37 WARN DAGScheduler: Broadcasting large task binary with size 36.0 MiB\n",
      "[Stage 841:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+----+-----+----+-----+------+-------+\n",
      "|min|  1%| 25%| 50%| mean| 75%|  90%|   99%|  99.9%|\n",
      "+---+----+----+----+-----+----+-----+------+-------+\n",
      "|0.0|0.01|0.22|0.77|202.0|3.36|13.91|246.35|7846.94|\n",
      "+---+----+----+----+-----+----+-----+------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    initial_portfolio_value_df\n",
    "    .agg(\n",
    "        F.round(F.min('initialPortfolioValue'), 2).alias('min'),\n",
    "        F.round(F.expr('percentile(initialPortfolioValue, array(0.01))')[0], 2).alias('1%'),\n",
    "        F.round(F.expr('percentile(initialPortfolioValue, array(0.25))')[0], 2).alias('25%'),\n",
    "        F.round(F.expr('percentile(initialPortfolioValue, array(0.5))')[0], 2).alias('50%'),\n",
    "        F.round(F.mean('initialPortfolioValue'), 2).alias('mean'),\n",
    "        F.round(F.expr('percentile(initialPortfolioValue, array(0.75))')[0], 2).alias('75%'),\n",
    "        F.round(F.expr('percentile(initialPortfolioValue, array(0.9))')[0], 2).alias('90%'),\n",
    "        F.round(F.expr('percentile(initialPortfolioValue, array(0.99))')[0], 2).alias('99%'),\n",
    "        F.round(F.expr('percentile(initialPortfolioValue, array(0.999))')[0], 2).alias('99.9%'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2d20769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_portfolio_value_df.write.mode('overwrite').parquet('/home/user1/Data/initial_portfolio_value_df.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b160c9ac",
   "metadata": {},
   "source": [
    "### calculate value of the final portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37d21e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:34:25 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:34:26 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:34:36 WARN DAGScheduler: Broadcasting large task binary with size 36.0 MiB\n",
      "22/02/22 17:34:45 WARN DAGScheduler: Broadcasting large task binary with size 35.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4313618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:34:51 WARN DAGScheduler: Broadcasting large task binary with size 35.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------------------+\n",
      "|accountId                           |finalPortfolioValue|\n",
      "+------------------------------------+-------------------+\n",
      "|5B291534-2FE5-4A4A-B75B-B4D44060A1AF|30.643591          |\n",
      "|0F6CC9D2-EF36-4537-BEBF-32F9386A468B|55.4984274         |\n",
      "|33046B40-C4EB-4CEE-974F-D6F1185F3434|15.5446366         |\n",
      "+------------------------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_portfolio_value_df = (\n",
    "    daily_portfolio_df\n",
    "    .withColumn('rowNumber', F.row_number().over(Window.partitionBy('accountId', 'symbol').orderBy('date')))\n",
    "    .withColumn('maxRowNumber', F.max('rowNumber').over(Window.partitionBy('accountId', 'symbol')))\n",
    "    .filter(F.col('rowNumber') == F.col('maxRowNumber'))\n",
    "    .filter(F.col('heldShares') > 0)\n",
    "    .withColumn('date', F.lit(MAX_PRICE_DATE))\n",
    "    .join(price_df.select('date', 'symbol', 'close_price'), on = ['date', 'symbol'], how = 'left')\n",
    "    .dropna(subset = ['close_price'])\n",
    "    .withColumn('value', F.col('heldShares') * F.col('close_price'))\n",
    "    .groupBy('accountId')\n",
    "    .agg(\n",
    "        (F.sum('value') / 10**7).alias('finalPortfolioValue')\n",
    "    )   \n",
    ")\n",
    "\n",
    "display_df(final_portfolio_value_df)\n",
    "# count after join?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "189eaef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:34:54 WARN DAGScheduler: Broadcasting large task binary with size 35.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:35:00 WARN DAGScheduler: Broadcasting large task binary with size 35.9 MiB\n",
      "[Stage 951:===============================================>    (182 + 18) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(final_portfolio_value_df.filter(F.col('finalPortfolioValue').isNull()).count())\n",
    "print(final_portfolio_value_df.filter(F.col('finalPortfolioValue') <= 0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "edd6e870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:35:07 WARN DAGScheduler: Broadcasting large task binary with size 36.0 MiB\n",
      "22/02/22 17:35:11 WARN DAGScheduler: Broadcasting large task binary with size 36.0 MiB\n",
      "[Stage 1007:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----+------+----+-----+------+--------+\n",
      "|min|10%| 25%| 50%|  mean| 75%|  90%|   99%|   99.9%|\n",
      "+---+---+----+----+------+----+-----+------+--------+\n",
      "|0.0|0.1|0.39|1.31|253.34|5.34|20.99|359.29|10445.95|\n",
      "+---+---+----+----+------+----+-----+------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    final_portfolio_value_df\n",
    "    .agg(\n",
    "        F.round(F.min('finalPortfolioValue'), 2).alias('min'),\n",
    "        F.round(F.expr('percentile(finalPortfolioValue, array(0.1))')[0], 2).alias('10%'),\n",
    "        F.round(F.expr('percentile(finalPortfolioValue, array(0.25))')[0], 2).alias('25%'),\n",
    "        F.round(F.expr('percentile(finalPortfolioValue, array(0.5))')[0], 2).alias('50%'),\n",
    "        F.round(F.mean('finalPortfolioValue'), 2).alias('mean'),\n",
    "        F.round(F.expr('percentile(finalPortfolioValue, array(0.75))')[0], 2).alias('75%'),\n",
    "        F.round(F.expr('percentile(finalPortfolioValue, array(0.9))')[0], 2).alias('90%'),\n",
    "        F.round(F.expr('percentile(finalPortfolioValue, array(0.99))')[0], 2).alias('99%'),\n",
    "        F.round(F.expr('percentile(finalPortfolioValue, array(0.999))')[0], 2).alias('99.9%'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1298c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_portfolio_value_df.write.mode('overwrite').parquet('/home/user1/Data/final_portfolio_value_df.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385da296",
   "metadata": {},
   "source": [
    "## calculate returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2991a55a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:35:57 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:36:04 WARN DAGScheduler: Broadcasting large task binary with size 36.0 MiB\n",
      "22/02/22 17:36:08 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "22/02/22 17:36:11 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4362652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:36:27 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "[Stage 1059:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------------+---------+---------------------+-------------------+-------------------+------------+\n",
      "|accountId                           |netCashOut   |netCashIn|initialPortfolioValue|finalPortfolioValue|return             |returnDecile|\n",
      "+------------------------------------+-------------+---------+---------------------+-------------------+-------------------+------------+\n",
      "|92C26116-9961-4133-BAD7-793AA7BEF8F1|16183.5065146|0.0      |106698.0908808       |0.0                |-0.8483243103882736|1           |\n",
      "|D227A812-A177-4D00-8C99-2F95F6229465|0.0          |-1762.5  |379.5506             |765.051            |-0.64284177040449  |1           |\n",
      "|FD0C12C3-368D-4EF8-A6C5-DA93CD0DF1BC|0.0          |-1762.5  |379.5506             |765.051            |-0.64284177040449  |1           |\n",
      "+------------------------------------+-------------+---------+---------------------+-------------------+-------------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "return_df = (\n",
    "    gain_from_trade_df\n",
    "    .join(initial_portfolio_value_df, on = 'accountId', how = 'outer')\n",
    "    .join(final_portfolio_value_df, on = 'accountId', how = 'outer')\n",
    "    .fillna(0, subset = ['netCashIn', 'netCashOut', 'initialPortfolioValue', 'finalPortfolioValue'])\n",
    "    .withColumn('return', \n",
    "                ((F.col('finalPortfolioValue') + F.col('netCashOut')) / (F.col('initialPortfolioValue') + (-F.col('netCashIn')))) - 1)\n",
    "    .filter(F.col('return').isNotNull())\n",
    "    .withColumn('returnDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('return')))\n",
    ")\n",
    "\n",
    "display_df(return_df)\n",
    "# null returns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4927024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:36:33 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100530"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    return_df\n",
    "    .filter(F.col('return') == 0)\n",
    "    .count()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1cca050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:36:40 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "[Stage 1111:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|returnDecile|medianReturn|\n",
      "+------------+------------+\n",
      "|           1|      -0.003|\n",
      "|           2|       0.074|\n",
      "|           3|       0.125|\n",
      "|           4|       0.199|\n",
      "|           5|       0.234|\n",
      "|           6|       0.366|\n",
      "|           7|       0.456|\n",
      "|           8|       0.568|\n",
      "|           9|       0.778|\n",
      "|          10|       1.328|\n",
      "+------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    return_df\n",
    "    .groupBy('returnDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba304564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:36:52 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "[Stage 1137:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----+----+----+----+----+----+----+-----+\n",
      "|  min|   1%| 10%| 25%| 50%|mean| 75%| 90%| 99%|99.9%|\n",
      "+-----+-----+----+----+----+----+----+----+----+-----+\n",
      "|-0.85|-0.08|0.04|0.12|0.29|0.51|0.57|0.97|5.21| 5.34|\n",
      "+-----+-----+----+----+----+----+----+----+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    return_df\n",
    "    .agg(\n",
    "       F.round(F.min('return'), 2).alias('min'),\n",
    "        F.round(F.expr('percentile(return, array(0.01))')[0], 2).alias('1%'),\n",
    "        F.round(F.expr('percentile(return, array(0.1))')[0], 2).alias('10%'),\n",
    "        F.round(F.expr('percentile(return, array(0.25))')[0], 2).alias('25%'),\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 2).alias('50%'),\n",
    "        F.round(F.mean('return'), 2).alias('mean'),\n",
    "        F.round(F.expr('percentile(return, array(0.75))')[0], 2).alias('75%'),\n",
    "        F.round(F.expr('percentile(return, array(0.9))')[0], 2).alias('90%'),\n",
    "        F.round(F.expr('percentile(return, array(0.99))')[0], 2).alias('99%'),\n",
    "        F.round(F.expr('percentile(return, array(0.999))')[0], 2).alias('99.9%'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2d7359d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:37:55 WARN DAGScheduler: Broadcasting large task binary with size 36.3 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "return_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/return_output.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9304442a",
   "metadata": {},
   "source": [
    "### final portfolio value output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81a77650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:38:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:38:13 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "22/02/22 17:38:16 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "22/02/22 17:38:20 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4313613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:38:35 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------------------+-------------------+-------------------------+\n",
      "|accountId                           |finalPortfolioValue|return             |finalPortfolioValueDecile|\n",
      "+------------------------------------+-------------------+-------------------+-------------------------+\n",
      "|82F6B832-AF99-4DEF-B80B-EAEA734EC0B3|1.7E-6             |0.14925041323980337|1                        |\n",
      "|CEBDD90D-C07D-4500-A436-32550D6E9556|2.52E-5            |0.0                |1                        |\n",
      "|16900519-92CB-4EF5-BCC5-87B095791742|2.52E-5            |0.0                |1                        |\n",
      "+------------------------------------+-------------------+-------------------+-------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_final_portfolio_value = (\n",
    "    final_portfolio_value_df\n",
    "    .join(return_df.select('accountId', 'return'), on = 'accountId')\n",
    "    .withColumn('finalPortfolioValueDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('finalPortfolioValue')))\n",
    ")\n",
    "\n",
    "display_df(output_final_portfolio_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bdff893f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:38:43 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "[Stage 1247:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-------------------------+----------+------------+\n",
      "|finalPortfolioValueDecile|medianFinalPortfolioValue|meanReturn|medianReturn|\n",
      "+-------------------------+-------------------------+----------+------------+\n",
      "|                        1|                    0.028|      0.22|       0.074|\n",
      "|                        2|                    0.176|      0.39|       0.366|\n",
      "|                        3|                    0.392|      0.41|       0.366|\n",
      "|                        4|                    0.605|      0.42|       0.366|\n",
      "|                        5|                    1.097|      0.42|       0.222|\n",
      "|                        6|                    1.685|      0.79|       0.337|\n",
      "|                        7|                    2.848|      0.72|       0.335|\n",
      "|                        8|                    5.343|      0.73|       0.415|\n",
      "|                        9|                   11.776|      0.62|        0.37|\n",
      "|                       10|                   55.482|      0.41|       0.251|\n",
      "+-------------------------+-------------------------+----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    output_final_portfolio_value\n",
    "    .groupBy('finalPortfolioValueDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(finalPortfolioValue, array(0.5))')[0], 3).alias('medianFinalPortfolioValue'),\n",
    "        F.round(F.mean('return'), 2).alias('meanReturn'),\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .orderBy('finalPortfolioValueDecile')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67bce316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:38:58 WARN DAGScheduler: Broadcasting large task binary with size 36.3 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_final_portfolio_value.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/final_portfolio_output.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2173cf42",
   "metadata": {},
   "source": [
    "### initial portfolio value output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f5e118a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:39:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:39:12 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "22/02/22 17:39:16 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "22/02/22 17:39:19 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4215194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:39:34 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+---------------------+-------------------+---------------------------+\n",
      "|accountId                           |initialPortfolioValue|return             |initialPortfolioValueDecile|\n",
      "+------------------------------------+---------------------+-------------------+---------------------------+\n",
      "|82F6B832-AF99-4DEF-B80B-EAEA734EC0B3|1.7E-6               |0.14925041323980337|1                          |\n",
      "|CEBDD90D-C07D-4500-A436-32550D6E9556|2.52E-5              |0.0                |1                          |\n",
      "|16900519-92CB-4EF5-BCC5-87B095791742|2.52E-5              |0.0                |1                          |\n",
      "+------------------------------------+---------------------+-------------------+---------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_initial_portfolio_value = (\n",
    "    initial_portfolio_value_df\n",
    "    .join(return_df.select('accountId', 'return'), on = 'accountId')\n",
    "    .withColumn('initialPortfolioValueDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('initialPortfolioValue')))\n",
    ")\n",
    "\n",
    "display_df(output_initial_portfolio_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0ba26784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:39:43 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "[Stage 1359:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+---------------------------+----------+------------+\n",
      "|initialPortfolioValueDecile|medianInitialPortfolioValue|meanReturn|medianReturn|\n",
      "+---------------------------+---------------------------+----------+------------+\n",
      "|                          1|                      0.026|       0.3|     0.07377|\n",
      "|                          2|                      0.122|      0.43|     0.36643|\n",
      "|                          3|                      0.225|      0.75|     0.32882|\n",
      "|                          4|                      0.379|      0.73|     0.43381|\n",
      "|                          5|                      0.563|      0.51|     0.31347|\n",
      "|                          6|                      1.032|      0.68|     0.38178|\n",
      "|                          7|                      1.816|      0.58|     0.32526|\n",
      "|                          8|                      3.359|      0.49|     0.37011|\n",
      "|                          9|                      7.661|      0.41|     0.34505|\n",
      "|                         10|                     36.009|      0.33|     0.24296|\n",
      "+---------------------------+---------------------------+----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    output_initial_portfolio_value\n",
    "    .groupBy('initialPortfolioValueDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(initialPortfolioValue, array(0.5))')[0], 3).alias('medianInitialPortfolioValue'),\n",
    "        F.round(F.mean('return'), 2).alias('meanReturn'),\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 5).alias('medianReturn')\n",
    "    )\n",
    "    .orderBy('initialPortfolioValueDecile')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c42db78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:39:57 WARN DAGScheduler: Broadcasting large task binary with size 36.3 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "output_initial_portfolio_value.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/inital_portfolio_output.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4358eef",
   "metadata": {},
   "source": [
    "### calculate frequency of trades and active days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc91189f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:40:04 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:40:15 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:40:17 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+--------+---------+\n",
      "|accountId                           |nBuyDays|nSellDays|\n",
      "+------------------------------------+--------+---------+\n",
      "|00359890-DDBC-4ED6-85EF-6265CF05DF25|12      |6        |\n",
      "|018942A6-B259-41C2-951E-0EB9BB59A917|12      |14       |\n",
      "|019CED96-7DAB-4AEA-88C0-0FBA460524CD|12      |14       |\n",
      "+------------------------------------+--------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "active_days_df = (\n",
    "    raw_flat_trade_df\n",
    "    .groupBy('accountId', 'date')\n",
    "    .agg(\n",
    "        F.sum('cashIn').alias('netCashIn'),\n",
    "        F.sum('cashOut').alias('netCashOut')\n",
    "    )\n",
    "    .withColumn('netCash', F.col('netCashIn') + F.col('netCashOut'))\n",
    "    .groupBy('accountId')\n",
    "    .agg(\n",
    "        F.count(F.when(F.col('netCash') < 0, F.lit(1))).alias('nBuyDays'),\n",
    "        F.count(F.when(F.col('netCash') > 0, F.lit(1))).alias('nSellDays')\n",
    "    )\n",
    "    .fillna(0, subset = ['nBuyDays', 'nSellDays'])\n",
    ")\n",
    "\n",
    "display_df(active_days_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac2e1e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:40:20 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:41:30 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:44:13 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 128689 ms exceeds timeout 120000 ms\n",
      "22/02/22 17:44:21 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "22/02/22 17:45:38 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:45:48 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "737297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:45:51 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+--------------+-------------------+--------------------+-----------------+----------+--------+---------+\n",
      "|accountId                           |tradeFrequency|meanTradeValue     |netSumTradeValue    |absSumTradeValue |activeDays|nBuyDays|nSellDays|\n",
      "+------------------------------------+--------------+-------------------+--------------------+-----------------+----------+--------+---------+\n",
      "|00066819-D00A-433B-9638-13C5933EC09F|7             |0.4669592285714286 |-0.7658454          |3.2687146        |6         |4       |2        |\n",
      "|000E126E-9959-4796-A329-C9839A3C0FED|5             |0.45314329999999997|0.043616500000000086|2.2657165        |5         |3       |2        |\n",
      "|00187BB3-23F8-4225-A743-1E4C5015024E|34            |2.2187337499999997 |-58.936947499999995 |75.43694749999999|6         |5       |1        |\n",
      "+------------------------------------+--------------+-------------------+--------------------+-----------------+----------+--------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trade_kpi_df = (\n",
    "    buy_trade_df\n",
    "    .union(sell_trade_df)\n",
    "    .groupBy('accountId')\n",
    "    .agg(\n",
    "        F.count(F.lit(1)).alias('tradeFrequency'),\n",
    "        F.mean(F.abs('settlementValue')).alias('meanTradeValue'),\n",
    "        F.sum('settlementValue').alias('netSumTradeValue'),\n",
    "        F.sum(F.abs('settlementValue')).alias('absSumTradeValue'),\n",
    "        F.countDistinct('date').alias('activeDays'),\n",
    "    )\n",
    "    .join(active_days_df, on = 'accountId')\n",
    ")\n",
    "\n",
    "display_df(trade_kpi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "34facbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:45:52 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:45:55 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+-----+--------------+--------------+--------------+----------------+\n",
      "|25% percentile|50% percentile| mean|75% percentile|90% percentile|99% percentile|99.9% percentile|\n",
      "+--------------+--------------+-----+--------------+--------------+--------------+----------------+\n",
      "|           5.0|          10.0|71.13|          36.0|         125.0|         973.0|          4172.7|\n",
      "+--------------+--------------+-----+--------------+--------------+--------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    trade_kpi_df\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(tradeFrequency, array(0.25))')[0], 2).alias('25% percentile'),\n",
    "        F.round(F.expr('percentile(tradeFrequency, array(0.5))')[0], 2).alias('50% percentile'),\n",
    "        F.round(F.mean('tradeFrequency'), 2).alias('mean'),\n",
    "        F.round(F.expr('percentile(tradeFrequency, array(0.75))')[0], 2).alias('75% percentile'),\n",
    "        F.round(F.expr('percentile(tradeFrequency, array(0.9))')[0], 2).alias('90% percentile'),\n",
    "        F.round(F.expr('percentile(tradeFrequency, array(0.99))')[0], 2).alias('99% percentile'),\n",
    "        F.round(F.expr('percentile(tradeFrequency, array(0.999))')[0], 2).alias('99.9% percentile'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "63c557d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:45:56 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:45:58 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "[Stage 1506:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+----+--------------+--------------+--------------+----------------+\n",
      "|25% percentile|50% percentile|mean|75% percentile|90% percentile|99% percentile|99.9% percentile|\n",
      "+--------------+--------------+----+--------------+--------------+--------------+----------------+\n",
      "|          0.42|          0.71|3.48|          1.76|          3.62|         12.21|           32.28|\n",
      "+--------------+--------------+----+--------------+--------------+--------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    trade_kpi_df\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(meanTradeValue, array(0.25))')[0], 2).alias('25% percentile'),\n",
    "        F.round(F.expr('percentile(meanTradeValue, array(0.5))')[0], 2).alias('50% percentile'),\n",
    "        F.round(F.mean('meanTradeValue'), 2).alias('mean'),\n",
    "        F.round(F.expr('percentile(meanTradeValue, array(0.75))')[0], 2).alias('75% percentile'),\n",
    "        F.round(F.expr('percentile(meanTradeValue, array(0.9))')[0], 2).alias('90% percentile'),\n",
    "        F.round(F.expr('percentile(meanTradeValue, array(0.99))')[0], 2).alias('99% percentile'),\n",
    "        F.round(F.expr('percentile(meanTradeValue, array(0.999))')[0], 2).alias('99.9% percentile'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc72756a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:46:14 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:46:16 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "[Stage 1533:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+----+--------------+--------------+--------------+----------------+\n",
      "|25% percentile|50% percentile|mean|75% percentile|90% percentile|99% percentile|99.9% percentile|\n",
      "+--------------+--------------+----+--------------+--------------+--------------+----------------+\n",
      "|         -2.56|         -0.67| 0.0|          0.43|          8.89|        160.36|         1738.53|\n",
      "+--------------+--------------+----+--------------+--------------+--------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    trade_kpi_df\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(netSumTradeValue, array(0.25))')[0], 2).alias('25% percentile'),\n",
    "        F.round(F.expr('percentile(netSumTradeValue, array(0.5))')[0], 2).alias('50% percentile'),\n",
    "        F.round(F.mean('netSumTradeValue'), 2).alias('mean'),\n",
    "        F.round(F.expr('percentile(netSumTradeValue, array(0.75))')[0], 2).alias('75% percentile'),\n",
    "        F.round(F.expr('percentile(netSumTradeValue, array(0.9))')[0], 2).alias('90% percentile'),\n",
    "        F.round(F.expr('percentile(netSumTradeValue, array(0.99))')[0], 2).alias('99% percentile'),\n",
    "        F.round(F.expr('percentile(netSumTradeValue, array(0.999))')[0], 2).alias('99.9% percentile'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7628e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:46:33 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:46:35 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "[Stage 1560:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+------+--------------+--------------+--------------+----------------+\n",
      "|25% percentile|50% percentile|  mean|75% percentile|90% percentile|99% percentile|99.9% percentile|\n",
      "+--------------+--------------+------+--------------+--------------+--------------+----------------+\n",
      "|          2.93|          6.25|240.49|         45.11|        257.59|       3311.74|        22552.29|\n",
      "+--------------+--------------+------+--------------+--------------+--------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    trade_kpi_df\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(absSumTradeValue, array(0.25))')[0], 2).alias('25% percentile'),\n",
    "        F.round(F.expr('percentile(absSumTradeValue, array(0.5))')[0], 2).alias('50% percentile'),\n",
    "        F.round(F.mean('absSumTradeValue'), 2).alias('mean'),\n",
    "        F.round(F.expr('percentile(absSumTradeValue, array(0.75))')[0], 2).alias('75% percentile'),\n",
    "        F.round(F.expr('percentile(absSumTradeValue, array(0.9))')[0], 2).alias('90% percentile'),\n",
    "        F.round(F.expr('percentile(absSumTradeValue, array(0.99))')[0], 2).alias('99% percentile'),\n",
    "        F.round(F.expr('percentile(absSumTradeValue, array(0.999))')[0], 2).alias('99.9% percentile'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4932f062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:46:50 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:46:52 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+-----+--------------+--------------+--------------+----------------+\n",
      "|25% percentile|50% percentile| mean|75% percentile|90% percentile|99% percentile|99.9% percentile|\n",
      "+--------------+--------------+-----+--------------+--------------+--------------+----------------+\n",
      "|           3.0|           7.0|10.22|          13.0|          25.0|          49.0|            55.0|\n",
      "+--------------+--------------+-----+--------------+--------------+--------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    trade_kpi_df\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(activeDays, array(0.25))')[0], 2).alias('25% percentile'),\n",
    "        F.round(F.expr('percentile(activeDays, array(0.5))')[0], 2).alias('50% percentile'),\n",
    "        F.round(F.mean('activeDays'), 2).alias('mean'),\n",
    "        F.round(F.expr('percentile(activeDays, array(0.75))')[0], 2).alias('75% percentile'),\n",
    "        F.round(F.expr('percentile(activeDays, array(0.9))')[0], 2).alias('90% percentile'),\n",
    "        F.round(F.expr('percentile(activeDays, array(0.99))')[0], 2).alias('99% percentile'),\n",
    "        F.round(F.expr('percentile(activeDays, array(0.999))')[0], 2).alias('99.9% percentile'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9a55f696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:46:53 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:46:55 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+----+--------------+--------------+--------------+----------------+\n",
      "|25% percentile|50% percentile|mean|75% percentile|90% percentile|99% percentile|99.9% percentile|\n",
      "+--------------+--------------+----+--------------+--------------+--------------+----------------+\n",
      "|           2.0|           4.0|5.66|           7.0|          14.0|          27.0|            35.0|\n",
      "+--------------+--------------+----+--------------+--------------+--------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    trade_kpi_df\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(nBuyDays, array(0.25))')[0], 2).alias('25% percentile'),\n",
    "        F.round(F.expr('percentile(nBuyDays, array(0.5))')[0], 2).alias('50% percentile'),\n",
    "        F.round(F.mean('nBuyDays'), 2).alias('mean'),\n",
    "        F.round(F.expr('percentile(nBuyDays, array(0.75))')[0], 2).alias('75% percentile'),\n",
    "        F.round(F.expr('percentile(nBuyDays, array(0.9))')[0], 2).alias('90% percentile'),\n",
    "        F.round(F.expr('percentile(nBuyDays, array(0.99))')[0], 2).alias('99% percentile'),\n",
    "        F.round(F.expr('percentile(nBuyDays, array(0.999))')[0], 2).alias('99.9% percentile'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2270b6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:46:57 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:46:58 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+----+--------------+--------------+--------------+----------------+\n",
      "|25% percentile|50% percentile|mean|75% percentile|90% percentile|99% percentile|99.9% percentile|\n",
      "+--------------+--------------+----+--------------+--------------+--------------+----------------+\n",
      "|           1.0|           3.0|4.56|           6.0|          12.0|          25.0|            34.0|\n",
      "+--------------+--------------+----+--------------+--------------+--------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    trade_kpi_df\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(nSellDays, array(0.25))')[0], 2).alias('25% percentile'),\n",
    "        F.round(F.expr('percentile(nSellDays, array(0.5))')[0], 2).alias('50% percentile'),\n",
    "        F.round(F.mean('nSellDays'), 2).alias('mean'),\n",
    "        F.round(F.expr('percentile(nSellDays, array(0.75))')[0], 2).alias('75% percentile'),\n",
    "        F.round(F.expr('percentile(nSellDays, array(0.9))')[0], 2).alias('90% percentile'),\n",
    "        F.round(F.expr('percentile(nSellDays, array(0.99))')[0], 2).alias('99% percentile'),\n",
    "        F.round(F.expr('percentile(nSellDays, array(0.999))')[0], 2).alias('99.9% percentile'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "69836438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:46:59 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:47:02 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "[Stage 1681:==============================================>    (182 + 18) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(trade_kpi_df.count() - trade_kpi_df.dropna().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ac8cec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:47:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:47:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:47:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:47:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:47:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:47:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:47:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:47:17 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "22/02/22 17:47:26 WARN DAGScheduler: Broadcasting large task binary with size 36.2 MiB\n",
      "22/02/22 17:47:28 WARN DAGScheduler: Broadcasting large task binary with size 36.2 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:47:41 WARN DAGScheduler: Broadcasting large task binary with size 36.2 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+--------------+--------------+----------------+----------------+----------+--------+---------+------------------+--------------------+--------------------+----------------------+----------------------+----------------+--------------+---------------+\n",
      "|accountId                           |tradeFrequency|meanTradeValue|netSumTradeValue|absSumTradeValue|activeDays|nBuyDays|nSellDays|return            |tradeFrequencyDecile|meanTradeValueDecile|netSumTradeValueDecile|absSumTradeValueDecile|activeDaysDecile|nBuyDaysDecile|nSellDaysDecile|\n",
      "+------------------------------------+--------------+--------------+----------------+----------------+----------+--------+---------+------------------+--------------------+--------------------+----------------------+----------------------+----------------+--------------+---------------+\n",
      "|F323D25A-C1B3-44FA-A147-ED2AA4466413|2             |0.012146      |0.0             |0.024292        |1         |0       |0        |0.0               |2                   |1                   |7                     |1                     |1               |1             |1              |\n",
      "|AD3950F8-67C4-4EF6-83CC-93B035FFD77B|2             |0.11347       |0.0             |0.22694         |1         |0       |0        |0.0               |2                   |1                   |7                     |1                     |1               |1             |1              |\n",
      "|71A1AEA3-C2CB-4BAF-BC1B-CE4CC8537F30|2             |0.354         |0.0             |0.708           |1         |0       |0        |0.4676271186440679|2                   |2                   |7                     |1                     |1               |1             |1              |\n",
      "+------------------------------------+--------------+--------------+----------------+----------------+----------+--------+---------+------------------+--------------------+--------------------+----------------------+----------------------+----------------+--------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trade_output_df = (\n",
    "    trade_kpi_df\n",
    "    .join(return_df.select('accountId', 'return').dropDuplicates(), on = ['accountId'])\n",
    "    .dropna()\n",
    "    .withColumn('tradeFrequencyDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('tradeFrequency')))\n",
    "    .withColumn('meanTradeValueDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('meanTradeValue')))\n",
    "    .withColumn('netSumTradeValueDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('netSumTradeValue')))\n",
    "    .withColumn('absSumTradeValueDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('absSumTradeValue')))\n",
    "    .withColumn('activeDaysDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('activeDays')))\n",
    "    .withColumn('nBuyDaysDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('nBuyDays')))\n",
    "    .withColumn('nSellDaysDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('nSellDays')))\n",
    ")\n",
    "\n",
    "display_df(trade_output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3dadb7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:47:49 WARN DAGScheduler: Broadcasting large task binary with size 36.2 MiB\n",
      "22/02/22 17:47:57 WARN DAGScheduler: Broadcasting large task binary with size 36.2 MiB\n",
      "[Stage 1831:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(round(trade_output_df.filter(F.col('return') >= 0.35).count() / trade_output_df.count() ,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "535e3153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:48:05 WARN DAGScheduler: Broadcasting large task binary with size 36.2 MiB\n",
      "[Stage 1865:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|medianReturn|\n",
      "+------------+\n",
      "|        0.15|\n",
      "+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    trade_output_df\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "178daac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:48:14 WARN DAGScheduler: Broadcasting large task binary with size 36.2 MiB\n",
      "[Stage 1899:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|tradeFrequencyDecile|medianReturn|\n",
      "+--------------------+------------+\n",
      "|                   1|       0.093|\n",
      "|                   2|        0.17|\n",
      "|                   3|        0.18|\n",
      "|                   4|       0.187|\n",
      "|                   5|       0.182|\n",
      "|                   6|       0.164|\n",
      "|                   7|        0.13|\n",
      "|                   8|       0.108|\n",
      "|                   9|       0.096|\n",
      "|                  10|       0.082|\n",
      "+--------------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    trade_output_df\n",
    "    .groupBy('tradeFrequencyDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .orderBy('tradeFrequencyDecile')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c416f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "530f71a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:48:20 WARN DAGScheduler: Broadcasting large task binary with size 36.4 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trade_output_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/trade_output.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f061bd",
   "metadata": {},
   "source": [
    "### identify block holders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "723c64d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:48:27 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:48:27 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:48:40 WARN DAGScheduler: Broadcasting large task binary with size 35.9 MiB\n",
      "22/02/22 17:48:47 WARN DAGScheduler: Broadcasting large task binary with size 35.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:48:53 WARN DAGScheduler: Broadcasting large task binary with size 35.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+----+\n",
      "|accountId                           |isBH|\n",
      "+------------------------------------+----+\n",
      "|ADB8AE92-2497-4A8E-BDE9-B4B3CE40F1BF|1   |\n",
      "|6BE23C8C-C5EA-4535-BC26-00ED4DDD036F|1   |\n",
      "|3C20A6C2-BE54-4E86-A94D-C038F59EF6C6|1   |\n",
      "+------------------------------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bh_df = (\n",
    "    daily_portfolio_df\n",
    "    .select('date', 'symbol', 'accountId', 'heldShares')\n",
    "    .join(price_df.select('date', 'symbol', 'shrout'), on = ['date', 'symbol'])\n",
    "    .withColumn('ownership', F.col('heldShares') / F.col('shrout'))\n",
    "    .filter( (F.col('ownership') >= 0.01) & F.col('ownership').isNotNull() )\n",
    "    .select('accountId')\n",
    "    .distinct()\n",
    "    .withColumn('isBH', F.lit(1))\n",
    ")\n",
    "\n",
    "display_df(bh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "38fc40ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:49:13 WARN DAGScheduler: Broadcasting large task binary with size 35.9 MiB\n",
      "22/02/22 17:49:16 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4362652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:49:27 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------------------+----+\n",
      "|accountId                           |return             |isBH|\n",
      "+------------------------------------+-------------------+----+\n",
      "|92C26116-9961-4133-BAD7-793AA7BEF8F1|-0.8483243103882736|1   |\n",
      "|D227A812-A177-4D00-8C99-2F95F6229465|-0.64284177040449  |1   |\n",
      "|FD0C12C3-368D-4EF8-A6C5-DA93CD0DF1BC|-0.64284177040449  |1   |\n",
      "+------------------------------------+-------------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bh_output_df = (\n",
    "    return_df\n",
    "    .select('accountId', 'return')\n",
    "    .dropna()\n",
    "    .join(bh_df, on = 'accountId', how = 'left')\n",
    "    .fillna(0, 'isBH')\n",
    ")\n",
    "\n",
    "display_df(bh_output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b5f1ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:49:36 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "[Stage 2084:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|isBH|medianTradeFrequency|\n",
      "+----+--------------------+\n",
      "|   1|               0.275|\n",
      "|   0|               0.286|\n",
      "+----+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    bh_output_df\n",
    "    .groupBy('isBH')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianTradeFrequency')\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5049fb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:49:50 WARN DAGScheduler: Broadcasting large task binary with size 36.3 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bh_output_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/bhOutput.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c60934",
   "metadata": {},
   "source": [
    "### number of stocks within initial portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cab6bed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:49:56 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:50:04 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4216142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:50:07 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-----------------------------+\n",
      "|accountId                           |nStocksWithinInitialPortfolio|\n",
      "+------------------------------------+-----------------------------+\n",
      "|59EAFFF2-1231-40B6-8D0F-1742E1596108|1                            |\n",
      "|87C3D7FD-E2A3-4E03-B2E6-161672D2C9ED|1                            |\n",
      "|16A0B31E-95A7-41F4-A98B-E8EFC4EDC514|1                            |\n",
      "+------------------------------------+-----------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_stocks_within_initial_portfolio_df = (\n",
    "    portfolio_df\n",
    "    .groupBy('accountId')\n",
    "    .agg(\n",
    "        F.count(F.lit(1)).alias('nStocksWithinInitialPortfolio')\n",
    "    )\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "display_df(n_stocks_within_initial_portfolio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19ace9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:50:09 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 17:50:11 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+---+---+----+-----+\n",
      "|25%|50%|  mean|75%|90%| 99%|99.9%|\n",
      "+---+---+------+---+---+----+-----+\n",
      "|1.0|1.0|2.0799|2.0|4.0|15.0| 45.0|\n",
      "+---+---+------+---+---+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    n_stocks_within_initial_portfolio_df\n",
    "    .agg(\n",
    "        F.expr('percentile(nStocksWithinInitialPortfolio, array(0.25))')[0].alias('25%'),\n",
    "        F.expr('percentile(nStocksWithinInitialPortfolio, array(0.50))')[0].alias('50%'),\n",
    "        F.round(F.mean('nStocksWithinInitialPortfolio'), 4).alias('mean'),\n",
    "        F.expr('percentile(nStocksWithinInitialPortfolio, array(0.75))')[0].alias('75%'),\n",
    "        F.expr('percentile(nStocksWithinInitialPortfolio, array(0.9))')[0].alias('90%'),\n",
    "        F.expr('percentile(nStocksWithinInitialPortfolio, array(0.99))')[0].alias('99%'),\n",
    "        F.expr('percentile(nStocksWithinInitialPortfolio, array(0.999))')[0].alias('99.9%'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cb2e38a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:50:12 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:50:21 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "22/02/22 17:50:25 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "22/02/22 17:50:29 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4215840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:50:43 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------------------+-----------------------------+-----------------------------------+\n",
      "|accountId                           |return             |nStocksWithinInitialPortfolio|nStocksWithinInitialPortfolioDecile|\n",
      "+------------------------------------+-------------------+-----------------------------+-----------------------------------+\n",
      "|00019AFD-C89B-4B63-98BB-18BF5A112C6F|0.07377049180327866|1                            |1                                  |\n",
      "|000217BA-3C48-4458-8CAA-691CA19C7187|0.3664259927797835 |1                            |1                                  |\n",
      "|000249D5-649B-4C99-AE9E-82AB979E80C9|0.07377049180327866|1                            |1                                  |\n",
      "+------------------------------------+-------------------+-----------------------------+-----------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "n_stocks_within_initial_portfolio_output_df = (\n",
    "    return_df\n",
    "    .select('accountId', 'return')\n",
    "    .dropna()\n",
    "    .join(n_stocks_within_initial_portfolio_df, on = 'accountId', how = 'inner')\n",
    "    .withColumn('nStocksWithinInitialPortfolioDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('nStocksWithinInitialPortfolio')))\n",
    ")\n",
    "\n",
    "display_df(n_stocks_within_initial_portfolio_output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "864f21c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:50:52 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "[Stage 2224:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------------+\n",
      "|nStocksWithinInitialPortfolioDecile|medianReturn|\n",
      "+-----------------------------------+------------+\n",
      "|                                  1|       0.366|\n",
      "|                                  2|       0.366|\n",
      "|                                  3|       0.366|\n",
      "|                                  4|       0.366|\n",
      "|                                  5|       0.366|\n",
      "|                                  6|       0.366|\n",
      "|                                  7|       0.366|\n",
      "|                                  8|       0.343|\n",
      "|                                  9|       0.268|\n",
      "|                                 10|       0.222|\n",
      "+-----------------------------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    n_stocks_within_initial_portfolio_output_df\n",
    "    .groupBy('nStocksWithinInitialPortfolioDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .orderBy('nStocksWithinInitialPortfolioDecile')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8613fe93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:51:01 WARN DAGScheduler: Broadcasting large task binary with size 36.3 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "n_stocks_within_initial_portfolio_output_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/n_initial_portfolio.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7933d8",
   "metadata": {},
   "source": [
    "### number of stocks within final portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b6f432cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:51:11 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:51:11 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:51:23 WARN DAGScheduler: Broadcasting large task binary with size 36.0 MiB\n",
      "22/02/22 17:51:33 WARN DAGScheduler: Broadcasting large task binary with size 35.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4313618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:51:39 WARN DAGScheduler: Broadcasting large task binary with size 35.9 MiB\n",
      "[Stage 2308:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+---------------------------+\n",
      "|accountId                           |nStocksWithinFinalPortfolio|\n",
      "+------------------------------------+---------------------------+\n",
      "|5B291534-2FE5-4A4A-B75B-B4D44060A1AF|14                         |\n",
      "|0F6CC9D2-EF36-4537-BEBF-32F9386A468B|56                         |\n",
      "|33046B40-C4EB-4CEE-974F-D6F1185F3434|7                          |\n",
      "+------------------------------------+---------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "n_stocks_within_final_portfolio_df = (\n",
    "    daily_portfolio_df\n",
    "    .withColumn('rowNumber', F.row_number().over(Window.partitionBy('accountId', 'symbol').orderBy('date')))\n",
    "    .withColumn('maxRowNumber', F.max('rowNumber').over(Window.partitionBy('accountId', 'symbol')))\n",
    "    .filter(F.col('rowNumber') == F.col('maxRowNumber'))\n",
    "    .filter(F.col('heldShares') > 0)\n",
    "    .withColumn('date', F.lit(MAX_PRICE_DATE))\n",
    "    .join(price_df.select('date', 'symbol', 'close_price'), on = ['date', 'symbol'], how = 'left')\n",
    "    .dropna(subset = ['close_price'])\n",
    "    .groupBy('accountId')\n",
    "    .agg(\n",
    "        F.countDistinct('symbol').alias('nStocksWithinFinalPortfolio')\n",
    "    )   \n",
    ")\n",
    "\n",
    "display_df(n_stocks_within_final_portfolio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d3a10563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:51:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:51:55 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "22/02/22 17:51:58 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "22/02/22 17:52:01 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4313613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:52:16 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------------------+---------------------------+---------------------------------+\n",
      "|accountId                           |return             |nStocksWithinFinalPortfolio|nStocksWithinFinalPortfolioDecile|\n",
      "+------------------------------------+-------------------+---------------------------+---------------------------------+\n",
      "|00019AFD-C89B-4B63-98BB-18BF5A112C6F|0.07377049180327866|1                          |1                                |\n",
      "|000217BA-3C48-4458-8CAA-691CA19C7187|0.3664259927797835 |1                          |1                                |\n",
      "|000249D5-649B-4C99-AE9E-82AB979E80C9|0.07377049180327866|1                          |1                                |\n",
      "+------------------------------------+-------------------+---------------------------+---------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_stocks_within_final_portfolio_output_df = (\n",
    "    return_df\n",
    "    .select('accountId', 'return')\n",
    "    .dropna()\n",
    "    .join(n_stocks_within_final_portfolio_df, on = 'accountId', how = 'inner')\n",
    "    .withColumn('nStocksWithinFinalPortfolioDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('nStocksWithinFinalPortfolio')))\n",
    ")\n",
    "\n",
    "display_df(n_stocks_within_final_portfolio_output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "932ef467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:52:24 WARN DAGScheduler: Broadcasting large task binary with size 36.2 MiB\n",
      "[Stage 2401:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+------------+\n",
      "|nStocksWithinFinalPortfolioDecile|medianReturn|\n",
      "+---------------------------------+------------+\n",
      "|                                1|       0.366|\n",
      "|                                2|       0.366|\n",
      "|                                3|       0.366|\n",
      "|                                4|       0.366|\n",
      "|                                5|       0.366|\n",
      "|                                6|       0.366|\n",
      "|                                7|        0.35|\n",
      "|                                8|       0.314|\n",
      "|                                9|       0.264|\n",
      "|                               10|       0.197|\n",
      "+---------------------------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    n_stocks_within_final_portfolio_output_df\n",
    "    .groupBy('nStocksWithinFinalPortfolioDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .orderBy('nStocksWithinFinalPortfolioDecile')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "92ee5b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:52:35 WARN DAGScheduler: Broadcasting large task binary with size 36.3 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "n_stocks_within_final_portfolio_output_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/n_final_portfolio.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a87605",
   "metadata": {},
   "source": [
    "### turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c1ab037f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:52:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/22 17:52:51 WARN DAGScheduler: Broadcasting large task binary with size 36.1 MiB\n",
      "22/02/22 17:52:55 WARN DAGScheduler: Broadcasting large task binary with size 36.2 MiB\n",
      "22/02/22 17:52:59 WARN DAGScheduler: Broadcasting large task binary with size 36.2 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:53:06 WARN DAGScheduler: Broadcasting large task binary with size 36.2 MiB\n",
      "[Stage 2500:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+--------+--------------+-------------------+\n",
      "|accountId                           |turnover|turnoverDecile|return             |\n",
      "+------------------------------------+--------+--------------+-------------------+\n",
      "|010B09FF-38E2-4440-9E3D-460E44548D88|null    |1             |0.183003099402258  |\n",
      "|029D5E79-ABF9-4EBE-B113-F43D9245588E|null    |1             |0.19860501119716534|\n",
      "|042E34A4-2946-4DB8-8AA0-E0787EC0F3A5|null    |1             |0.0                |\n",
      "+------------------------------------+--------+--------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "turnover_df = (\n",
    "    trade_kpi_df\n",
    "    .join(final_portfolio_value_df, on =['accountId'], how = 'left')\n",
    "    .withColumn('turnover', F.col('absSumTradeValue') / F.col('finalPortfolioValue'))\n",
    "    .join(return_df.select('accountId', 'return'), on = 'accountId')\n",
    "    .withColumn('turnoverDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy(F.col('turnover'))))\n",
    "    .select(\n",
    "        'accountId',\n",
    "        'turnover',\n",
    "        'turnoverDecile',\n",
    "        'return'\n",
    "    )\n",
    ")\n",
    "\n",
    "display_df(turnover_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4eee8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:53:16 WARN DAGScheduler: Broadcasting large task binary with size 36.2 MiB\n",
      "[Stage 2534:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|turnoverDecile|medianReturn|\n",
      "+--------------+------------+\n",
      "|             1|       0.163|\n",
      "|             2|       0.295|\n",
      "|             3|        0.17|\n",
      "|             4|       0.093|\n",
      "|             5|       0.156|\n",
      "|             6|       0.142|\n",
      "|             7|       0.168|\n",
      "|             8|       0.152|\n",
      "|             9|       0.089|\n",
      "|            10|       0.082|\n",
      "+--------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    turnover_df\n",
    "    .groupBy('turnoverDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .orderBy('turnoverDecile')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "24a07c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:53:23 WARN DAGScheduler: Broadcasting large task binary with size 36.4 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "turnover_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/turnover.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dd9b65",
   "metadata": {},
   "source": [
    "### time series of the number of stocks within portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a16aa62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:53:25 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:53:29 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:53:30 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/22 17:53:32 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13980105, 13980106, 13980107, 13980110, 13980111, 13980117, 13980118, 13980119, 13980120, 13980121, 13980124, 13980125, 13980126, 13980127, 13980128, 13980131, 13980202, 13980203, 13980204, 13980207, 13980208, 13980209, 13980210, 13980211, 13980214, 13980215, 13980216, 13980217, 13980218, 13980221, 13980222, 13980223, 13980224, 13980225, 13980228, 13980229, 13980230, 13980231, 13980301, 13980304, 13980305, 13980307, 13980308, 13980311, 13980312, 13980313, 13980318, 13980319, 13980320, 13980321, 13980322, 13980325, 13980326, 13980327, 13980328, 13980329]\n"
     ]
    }
   ],
   "source": [
    "dates_list = (\n",
    "    price_df\n",
    "    .select('date')\n",
    "    .distinct()\n",
    "    .orderBy('date')\n",
    "    .rdd.flatMap(lambda x: x).collect()\n",
    ")\n",
    "\n",
    "print(dates_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3598a7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13980105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:53:36 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:53:46 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13980106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:53:52 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:54:02 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13980107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:54:08 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:54:17 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13980110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:54:22 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:54:32 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13980111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:54:38 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:54:47 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13980117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:54:54 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:55:04 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13980118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:55:10 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:55:20 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13980119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:55:26 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:55:35 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13980120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:55:41 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:55:51 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13980121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:55:56 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:56:06 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13980124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:56:12 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:56:22 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13980125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:56:28 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/22 17:56:38 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13980126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user1/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/user1/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n",
      "22/02/22 17:56:44 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "[Stage 3326:=======================================>           (155 + 45) / 200]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(date)\n\u001b[1;32m      6\u001b[0m result \u001b[39m=\u001b[39m (\n\u001b[1;32m      7\u001b[0m     daily_portfolio_df\n\u001b[1;32m      8\u001b[0m     \u001b[39m.\u001b[39mfilter(F\u001b[39m.\u001b[39mcol(\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m date)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m nStocksWithinPortfolioOfAllInvestors\u001b[39m.\u001b[39mappend(result\u001b[39m.\u001b[39;49mcollect()[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\n\u001b[1;32m     23\u001b[0m nInvestors\u001b[39m.\u001b[39mappend(result\u001b[39m.\u001b[39mcollect()[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py:693\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=682'>683</a>\u001b[0m \u001b[39m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=683'>684</a>\u001b[0m \n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=684'>685</a>\u001b[0m \u001b[39m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=689'>690</a>\u001b[0m \u001b[39m[Row(age=2, name='Alice'), Row(age=5, name='Bob')]\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=690'>691</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=691'>692</a>\u001b[0m \u001b[39mwith\u001b[39;00m SCCallSiteSync(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sc) \u001b[39mas\u001b[39;00m css:\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=692'>693</a>\u001b[0m     sock_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mcollectToPython()\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py?line=693'>694</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(PickleSerializer())))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/py4j/java_gateway.py?line=1312'>1313</a>\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/py4j/java_gateway.py?line=1314'>1315</a>\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/py4j/java_gateway.py?line=1315'>1316</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/py4j/java_gateway.py?line=1316'>1317</a>\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/py4j/java_gateway.py?line=1317'>1318</a>\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> <a href='file:///~/.local/lib/python3.8/site-packages/py4j/java_gateway.py?line=1319'>1320</a>\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/py4j/java_gateway.py?line=1320'>1321</a>\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/py4j/java_gateway.py?line=1321'>1322</a>\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/py4j/java_gateway.py?line=1323'>1324</a>\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/py4j/java_gateway.py?line=1035'>1036</a>\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/py4j/java_gateway.py?line=1036'>1037</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///~/.local/lib/python3.8/site-packages/py4j/java_gateway.py?line=1037'>1038</a>\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/py4j/java_gateway.py?line=1038'>1039</a>\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   <a href='file:///~/.local/lib/python3.8/site-packages/py4j/java_gateway.py?line=1039'>1040</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/clientserver.py:475\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/py4j/clientserver.py?line=472'>473</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/py4j/clientserver.py?line=473'>474</a>\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/.local/lib/python3.8/site-packages/py4j/clientserver.py?line=474'>475</a>\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/py4j/clientserver.py?line=475'>476</a>\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/py4j/clientserver.py?line=476'>477</a>\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/.local/lib/python3.8/site-packages/py4j/clientserver.py?line=477'>478</a>\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/socket.py?line=666'>667</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/socket.py?line=667'>668</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///usr/lib/python3.8/socket.py?line=668'>669</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/socket.py?line=669'>670</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    <a href='file:///usr/lib/python3.8/socket.py?line=670'>671</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 17:57:05 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "Exception in thread \"serve-DataFrame\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.base/java.net.PlainSocketImpl.socketAccept(Native Method)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:458)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:565)\n",
      "\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:533)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:64)\n"
     ]
    }
   ],
   "source": [
    "nStocksWithinPortfolioOfAllInvestors = []\n",
    "nInvestors = []\n",
    "\n",
    "for date in dates_list:\n",
    "    print(date)\n",
    "    result = (\n",
    "        daily_portfolio_df\n",
    "        .filter(F.col('date') <= date)\n",
    "        .withColumn('rowNumber', F.row_number().over(Window.partitionBy('accountId', 'symbol').orderBy('date')))\n",
    "        .withColumn('maxRowNumber', F.max('rowNumber').over(Window.partitionBy('accountId', 'symbol')))\n",
    "        .filter(F.col('rowNumber') == F.col('maxRowNumber'))\n",
    "        .filter( (F.col('heldShares') > 0) & (F.col('heldShares').isNotNull()) )\n",
    "        .groupBy('accountId')\n",
    "        .agg(\n",
    "            F.count(F.lit(1)).alias('nStocksWithinPortfolioOfAllInvestors'),\n",
    "        )\n",
    "        .agg(\n",
    "            F.round(F.mean('nStocksWithinPortfolioOfAllInvestors'), 3).alias('nStocksWithinPortfolioOfAllInvestors'),\n",
    "            F.count(F.lit(1)).alias('nInvestors')\n",
    "        )\n",
    "    )\n",
    "    nStocksWithinPortfolioOfAllInvestors.append(result.collect()[0][0])\n",
    "    nInvestors.append(result.collect()[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2688e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stocks_df = spark.createDataFrame(\n",
    "    pd.DataFrame({\n",
    "        'date' : dates_list,\n",
    "        'nStocksWithinPortfolioOfAllInvestors' : nStocksWithinPortfolioOfAllInvestors,\n",
    "        'nInvestors' : nInvestors\n",
    "    })\n",
    ")\n",
    "\n",
    "display_df(n_stocks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83933cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stocks_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/mean_number_of_stocks_within_portfolio.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 18:05:30 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/22 18:05:38 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "initial_ids =  [row['accountId'] for row in portfolio_df.select('accountId').distinct().collect()]\n",
    "initial_ids = set(initial_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0a93bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/22 18:17:09 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "unique_id_trade = flat_trade_df.dropDuplicates(subset=['accountId','date'])\n",
    "unique_id_trade.count()\n",
    "result = {}\n",
    "for date in dates_list:\n",
    "    print(initial_ids)\n",
    "    tempt = unique_id_trade.filter(F.col('date') == date).select('accountId').distinct().collect()\n",
    "    teades_ids = set([row['accountId'] for row in tempt])\n",
    "    result[date] = len(teades_ids -initial_ids )\n",
    "    \n",
    "    initial_ids =  set.union(initial_ids, teades_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
