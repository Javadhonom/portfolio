{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b125ac61",
   "metadata": {},
   "source": [
    "## initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e8804",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eda130c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "from functools import reduce\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ececc088",
   "metadata": {},
   "source": [
    "### configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7052f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRADE = '/home/user1/Data/'\n",
    "PATH_PORTFOLIO = '/home/user1/Data/Portfolio/'\n",
    "PRICE_PATH =  '/home/user1/Data/'\n",
    "VALID_SYMBOLS_PATH = '/home/user1/Data/'\n",
    "\n",
    "HOUR_SECONDS = 60 * 60\n",
    "MINUTE_SECONDS = 60\n",
    "\n",
    "MIN_ANALYSIS_DATE = 13980101\n",
    "MAX_ANALYSIS_DATE = 13980331\n",
    "\n",
    "N_QUANTILES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3319d2e0",
   "metadata": {},
   "source": [
    "### general functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10b0de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_df(df):\n",
    "    df.persist()\n",
    "    print(df.count())\n",
    "    df.show(3, False)\n",
    "\n",
    "def min_max(df):\n",
    "    return df.agg(F.min('date').alias('min_date'), F.max('date').alias('max_date')).show()\n",
    "\n",
    "def modify_time(x):\n",
    "    hour = x // 10000\n",
    "    minute = (x % 10000) // 100\n",
    "    second = x % 100\n",
    "    return HOUR_SECONDS * 3600 + MINUTE_SECONDS * 60 + second\n",
    "modify_time_udf = F.udf(modify_time, T.IntegerType())\n",
    "\n",
    "dropSpace = F.udf(lambda x: x.replace(' ', ''), T.StringType())\n",
    "\n",
    "mappingDict = {\n",
    "              'ما  ' : 'ما',\n",
    "              'جم  ' : 'جم',\n",
    "              'جمپیلن' : 'جم پیلن',\n",
    "              'افقملت' : 'افق ملت',\n",
    "              'آسپ' : 'آ س پ',\n",
    "              'آپ  ' : 'آپ',\n",
    "              'سپ  ' : 'سپ',\n",
    "              'غپاذر' : 'غپآذر',\n",
    "              'هدشت' : 'دهدشت',\n",
    "              'نگان' : 'زنگان',\n",
    "              'فبورس' : 'فرابورس',\n",
    "              'شیری' : 'دشیری',\n",
    "              'وتعان' : 'وتعاون',\n",
    "              'آس پ' : 'آ س پ',\n",
    "              'انرژی1': 'انرژی 1',\n",
    "              'انرژی2' : 'انرژی 2',\n",
    "              'انرژی3' : 'انرژی 3',\n",
    "              'انرژیح1' : 'انرژیح 1',\n",
    "              'انرژیح2' : 'انرژیح 2',\n",
    "              'انرژیح3' : 'انرژیح 3',\n",
    "              'فناوا' : 'فن آوا',\n",
    "              'فنآوا' : 'فن آوا',\n",
    "              'امینیکم' : 'امین یکم',\n",
    "              'هایوب' : 'های وب',\n",
    "              'کیبیسی' : 'کی بی سی',\n",
    "              'کیبیسیح' : 'کی بی سیح',\n",
    "              'واتوس' : 'وآتوس'\n",
    "              }\n",
    "\n",
    "def replace_arabic_characters_and_correct_symbol_names(data):\n",
    "    mapping = {\n",
    "        'ك': 'ک',\n",
    "        'گ': 'گ',\n",
    "        'دِ': 'د',\n",
    "        'بِ': 'ب',\n",
    "        'زِ': 'ز',\n",
    "        'ذِ': 'ذ',\n",
    "        'شِ': 'ش',\n",
    "        'سِ': 'س',\n",
    "        'ى': 'ی',\n",
    "        'ي': 'ی',\n",
    "    }\n",
    "    for i in mapping:\n",
    "        data = (\n",
    "            data\n",
    "            .withColumn('symbol', F.regexp_replace('symbol', i, mapping[i]))\n",
    "        )\n",
    "    data = (\n",
    "        data\n",
    "        .withColumn(\n",
    "        'symbol',\n",
    "        F.when((F.col('symbol').substr(1, 1) == 'ذ') & (F.col('symbol') != 'ذوب'), F.col('symbol').substr(2, 30)).otherwise(\n",
    "            F.col('symbol'))\n",
    "        )\n",
    "        .withColumn(\n",
    "        'symbol',\n",
    "        F.when(F.col('symbol').substr(1, 2) == 'گژ', F.col('symbol').substr(3, 30)).otherwise(\n",
    "            F.col('symbol'))\n",
    "        )\n",
    "        .withColumn(\n",
    "        'symbol',\n",
    "        F.when(F.col('symbol').substr(1, 1) == 'ژ', F.col('symbol').substr(2, 30)).otherwise(\n",
    "            F.col('symbol'))\n",
    "        )\n",
    "        .replace(mappingDict,subset=['symbol'])\n",
    "    )\n",
    "    return data\n",
    "\n",
    "spaceDeleteUDF1 = F.udf(lambda s: s.replace('\\u200d', ''), T.StringType())\n",
    "spaceDeleteUDF2 = F.udf(lambda s: s.replace('\\u200c', ''), T.StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469fdf04",
   "metadata": {},
   "source": [
    "### Spark instaniation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36e89f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 08:57:57 WARN Utils: Your hostname, user1-ubuntu resolves to a loopback address: 127.0.1.1; using 172.16.32.107 instead (on interface eth0)\n",
      "22/02/23 08:57:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/user1/.local/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/23 08:57:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf()\n",
    "conf.set('spark.driver.memory', '130g').set('spark.shuffle.service.index.cache.size', '1g').setAppName('Practice') #.set('spark.executer.cores', '58')\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c797ab",
   "metadata": {},
   "source": [
    "## data inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348884b3",
   "metadata": {},
   "source": [
    "### load daily trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f79ea4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27464132\n",
      "+--------+------+------+------------------------------------+------------------------------------+------------+----------+--------------------+\n",
      "|date    |time  |symbol|buyerAccountId                      |sellerAccountId                     |nTradeShares|tradePrice|tradeSettlementValue|\n",
      "+--------+------+------+------------------------------------+------------------------------------+------------+----------+--------------------+\n",
      "|13980110|115203|ثامان |ECC77A89-C9AD-494F-8B49-4F178C2D7F3E|2AF253F2-7044-44EA-858B-09DA6A224E86|24928       |3390.0    |8.450592            |\n",
      "|13980110|120816|ثاباد |9288482E-9715-4DE3-AAB6-D20D2FB157DE|02F7AA8E-29E7-4594-ACD4-FDAEE6BA957B|2000        |2320.0    |0.464               |\n",
      "|13980110|122054|آسیا  |5D9B391F-C8F1-48E8-A9D0-2215FFCB9FCB|C7470FDD-F4DA-472D-895A-EBD1ED249BAD|7573        |1876.0    |1.4206948           |\n",
      "+--------+------+------+------------------------------------+------------------------------------+------------+----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_trade_df = spark.read.parquet(PATH_TRADE + \"tradeData.parquet\")\n",
    "\n",
    "display_df(raw_trade_df)\n",
    "# capital increas?\n",
    "# make sure trade value and number of shares are not zero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e1526d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=======================================================> (65 + 2) / 67]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|min_date|max_date|\n",
      "+--------+--------+\n",
      "|13980105|13980329|\n",
      "+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "min_max(raw_trade_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64043f6e",
   "metadata": {},
   "source": [
    "### load portfolio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d850965f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=======================================================> (49 + 1) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12109854\n",
      "+------+--------+------------------------------------+------+\n",
      "|SPSYMB|SPDATE  |SPACC#                              |SPTROH|\n",
      "+------+--------+------------------------------------+------+\n",
      "|خساپا |13980105|37D6BD7D-DCF6-4B34-9ACC-AAA8111E0243|32850 |\n",
      "|خساپا |13980105|F5094FE0-46A8-4C7F-86CD-6EA2DC8D5B42|2237  |\n",
      "|اخابر |13980105|47229110-AA3E-4972-985B-670E61BAC864|384   |\n",
      "+------+--------+------------------------------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "raw_portfolio_df = spark.read.parquet(\n",
    "    PATH_PORTFOLIO + \"{}\".format(\"raw_portfolio_df.parquet\")\n",
    "    )\n",
    "display_df(raw_portfolio_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dab27c",
   "metadata": {},
   "source": [
    "### load daily price and shrout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00fd371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 08:58:48 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 08:59:11 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+--------------------+------+---------+\n",
      "|date    |symbol|close_price|close_price_adjusted|shrout|mktcap   |\n",
      "+--------+------+-----------+--------------------+------+---------+\n",
      "|13980221|آ س پ |1366.0     |1249.0              |9.0E8 |122940.0 |\n",
      "|13980125|آتیمس |30009.0    |30380.0             |1.0E9 |3000900.0|\n",
      "|13980202|آتیمس |30880.0    |31262.0             |1.0E9 |3088000.0|\n",
      "+--------+------+-----------+--------------------+------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "price_df = (\n",
    "    spark.read.parquet(PRICE_PATH.format('Cleaned_Stock_Prices_14001116.parquet'))\n",
    "    .filter(F.col('jalaliDate').between(MIN_ANALYSIS_DATE, MAX_ANALYSIS_DATE))\n",
    "    .select(\n",
    "        F.col('jalaliDate').alias('date'),\n",
    "        F.col('name').alias('symbol'),\n",
    "        'close_price',\n",
    "        'close_price_adjusted',\n",
    "        'shrout',\n",
    "        (F.col('MarketCap') / 10**7).alias('mktcap')\n",
    "    )\n",
    "    .dropDuplicates()\n",
    ")\n",
    "\n",
    "price_df = replace_arabic_characters_and_correct_symbol_names(price_df)\n",
    "\n",
    "display_df(price_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1e07d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_price_df = spark.createDataFrame(pd.DataFrame({\n",
    "                                                        'date' : [13980105],\n",
    "                                                        'symbol' : ['ومشان'],\n",
    "                                                        'close_price' : [561],\n",
    "                                                        'close_price_adjusted' : [np.nan],\n",
    "                                                        'shrout' : [20000000],\n",
    "                                                        'mktcap' : [1122]\n",
    "                                                    })\n",
    "                                      )\n",
    "\n",
    "price_df = price_df.union(added_price_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f9068e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 08:59:12 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "[Stage 22:=========================================>           (201 + 57) / 258]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|min_date|max_date|\n",
      "+--------+--------+\n",
      "|13980105|13980329|\n",
      "+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "min_max(price_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dcc44b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 08:59:17 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 08:59:19 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 08:59:22 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 08:59:30 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|count(symbol)|\n",
      "+-------------+\n",
      "|         1031|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 08:59:31 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 08:59:34 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|count(symbol)|\n",
      "+-------------+\n",
      "|         1014|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 08:59:35 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 08:59:37 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|count(symbol)|\n",
      "+-------------+\n",
      "|         1024|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "MIN_PRICE_DATE = price_df.agg(F.min('date')).collect()[0][0]\n",
    "MAX_PRICE_DATE = price_df.agg(F.max('date')).collect()[0][0]\n",
    "\n",
    "price_df.agg(F.countDistinct('symbol')).show()\n",
    "price_df.filter(F.col('date') == MIN_PRICE_DATE).agg(F.countDistinct('symbol')).show()\n",
    "price_df.filter(F.col('date') == MAX_PRICE_DATE).agg(F.countDistinct('symbol')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5a63c",
   "metadata": {},
   "source": [
    "### load valid symbols data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f80d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 08:59:47 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 08:59:51 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 08:59:51 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|symbol|\n",
      "+------+\n",
      "|دسبحان|\n",
      "|فن آوا|\n",
      "|دلقما |\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "valid_symbols_df = (\n",
    "    spark.read.parquet(VALID_SYMBOLS_PATH + '{}'.format('Symbols_14001116.parquet'))\n",
    "    .select('Ticker')\n",
    "    .withColumnRenamed('Ticker','symbol')\n",
    "    .dropDuplicates()\n",
    ")\n",
    "\n",
    "valid_symbols_df = replace_arabic_characters_and_correct_symbol_names(valid_symbols_df)\n",
    "\n",
    "display_df(valid_symbols_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44389b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 08:59:52 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 08:59:54 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 08:59:55 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 08:59:56 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|symbol|\n",
      "+------+\n",
      "|دسبحان|\n",
      "|فن آوا|\n",
      "|دلقما |\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 08:59:57 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 08:59:59 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:00:00 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:00:01 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|symbol|\n",
      "+------+\n",
      "|دسبحان|\n",
      "|فن آوا|\n",
      "|بکابح |\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:00:02 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:00:04 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:00:06 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:00:06 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|symbol|\n",
      "+------+\n",
      "|دسبحان|\n",
      "|فن آوا|\n",
      "|بکابح |\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:00:07 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:00:09 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:00:10 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|symbol|\n",
      "+------+\n",
      "|دسبحان|\n",
      "|فن آوا|\n",
      "|بکابح |\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ETFs = ['آتیمس',\n",
    " 'آرمانی',\n",
    " 'آساس',\n",
    " 'آسام',\n",
    " 'آسامید',\n",
    " 'آوا',\n",
    " 'آکورد',\n",
    " 'آگاس',\n",
    " 'ارزش',\n",
    " 'اطلس',\n",
    " 'اعتماد',\n",
    " 'افران',\n",
    " 'افق ملت',\n",
    " 'الماس',\n",
    " 'امین یکم',\n",
    " 'انار',\n",
    " 'اهرم',\n",
    " 'اوج',\n",
    " 'اوصتا',\n",
    " 'بذر',\n",
    " 'تاراز',\n",
    " 'تصمیم',\n",
    " 'ثبات',\n",
    " 'ثروتم',\n",
    " 'ثمین',\n",
    " 'ثهام',\n",
    " 'خاتم',\n",
    " 'دارا',\n",
    " 'دارا یکم',\n",
    " 'داریوش',\n",
    " 'داریک',\n",
    " 'رماس',\n",
    " 'رویش',\n",
    " 'زر',\n",
    " 'زرین',\n",
    " 'زیتون',\n",
    " 'سبز',\n",
    " 'سحرخیز',\n",
    " 'سخند',\n",
    " 'سرو',\n",
    " 'سپاس',\n",
    " 'سپر',\n",
    " 'سپیدما',\n",
    " 'سیناد',\n",
    " 'صایند',\n",
    " 'صغرب',\n",
    " 'صنم',\n",
    " 'صنوین',\n",
    " 'طلا',\n",
    " 'عیار',\n",
    " 'فراز',\n",
    " 'فردا',\n",
    " 'فیروزا',\n",
    " 'مانی',\n",
    " 'مثقال',\n",
    " 'مدیر',\n",
    " 'نارون',\n",
    " 'نسیم',\n",
    " 'نهال',\n",
    " 'هامرز',\n",
    " 'همای',\n",
    " 'وبازار',\n",
    " 'ویستا',\n",
    " 'پادا',\n",
    " 'پارند',\n",
    " 'پالایش',\n",
    " 'کارا',\n",
    " 'کاردان',\n",
    " 'کاریس',\n",
    " 'کارین',\n",
    " 'کامیاب',\n",
    " 'کمند',\n",
    " 'کهربا',\n",
    " 'کیان',\n",
    " 'گنبد',\n",
    " 'گنجین',\n",
    " 'گنجینه',\n",
    " 'گوهر',\n",
    " 'یارا',\n",
    " 'یاقوت',\n",
    " 'فیروزه',]\n",
    "ETFs = [(i,) for i in ETFs]\n",
    "ETFs = spark.createDataFrame(data= ETFs,  schema= valid_symbols_df.schema)\n",
    "valid_symbols_df = valid_symbols_df.union(ETFs).dropDuplicates()\n",
    "display_df(valid_symbols_df)\n",
    "\n",
    "\n",
    "right_offers = ['آ س پح',\n",
    " 'آرمانح',\n",
    " 'آریانح',\n",
    " 'آرینح',\n",
    " 'آکنتورح',\n",
    " 'اتکامح',\n",
    " 'اتکایح',\n",
    " 'اخابرح',\n",
    " 'ارفعح',\n",
    " 'اعتلاح',\n",
    " 'افراح',\n",
    " 'افقح',\n",
    " 'البرزح',\n",
    " 'امیدح',\n",
    " 'امینح',\n",
    " 'اوانح',\n",
    " 'بالبرح',\n",
    " 'بایکاح',\n",
    " 'بترانسح',\n",
    " 'بتکح',\n",
    " 'بدکوح',\n",
    " 'برکتح',\n",
    " 'بزاگرسح',\n",
    " 'بساماح',\n",
    " 'بسویچح',\n",
    " 'بشهابح',\n",
    " 'بصباح',\n",
    " 'بفجرح',\n",
    " 'بموتوح',\n",
    " 'بمیلاح',\n",
    " 'بنوح',\n",
    " 'بنیروح',\n",
    " 'بهپاکح',\n",
    " 'بپاسح',\n",
    " 'بکابح',\n",
    " 'بکامح',\n",
    " 'بکهنوجح',\n",
    " 'تاصیکوح',\n",
    " 'تاپکیشح',\n",
    " 'تاپیکوح',\n",
    " 'تایراح',\n",
    " 'تجلیح',\n",
    " 'تشتادح',\n",
    " 'تفیروح',\n",
    " 'تلیسهح',\n",
    " 'تماوندح',\n",
    " 'تمحرکهح',\n",
    " 'تملتح',\n",
    " 'تنوینح',\n",
    " 'توریلح',\n",
    " 'تپمپیح',\n",
    " 'تپکوح',\n",
    " 'تکشاح',\n",
    " 'تکمباح',\n",
    " 'تکنارح',\n",
    " 'تکنوح',\n",
    " 'تیپیکوح',\n",
    " 'ثابادح',\n",
    " 'ثاختح',\n",
    " 'ثاصفاح',\n",
    " 'ثالوندح',\n",
    " 'ثامانح',\n",
    " 'ثاژنح',\n",
    " 'ثباغح',\n",
    " 'ثترانح',\n",
    " 'ثرودح',\n",
    " 'ثشاهدح',\n",
    " 'ثشرقح',\n",
    " 'ثعتماح',\n",
    " 'ثعمراح',\n",
    " 'ثغربح',\n",
    " 'ثفارسح',\n",
    " 'ثقزویح',\n",
    " 'ثمسکنح',\n",
    " 'ثنورح',\n",
    " 'ثنوساح',\n",
    " 'ثپردیسح',\n",
    " 'جمح',\n",
    " 'جهرمح',\n",
    " 'حبندرح',\n",
    " 'حتایدح',\n",
    " 'حتوکاح',\n",
    " 'حخزرح',\n",
    " 'حسیناح',\n",
    " 'حفاریح',\n",
    " 'حپارساح',\n",
    " 'حپتروح',\n",
    " 'حکشتیح',\n",
    " 'حکمتح',\n",
    " 'خاذینح',\n",
    " 'خاهنح',\n",
    " 'خاورح',\n",
    " 'خبهمنح',\n",
    " 'ختراکح',\n",
    " 'ختورح',\n",
    " 'ختوقاح',\n",
    " 'خدیزلح',\n",
    " 'خریختح',\n",
    " 'خرینگح',\n",
    " 'خزامیاح',\n",
    " 'خزرح',\n",
    " 'خساپاح',\n",
    " 'خشرقح',\n",
    " 'خصدراح',\n",
    " 'خفناورح',\n",
    " 'خفنرح',\n",
    " 'خفولاح',\n",
    " 'خلنتح',\n",
    " 'خمحرکهح',\n",
    " 'خمحورح',\n",
    " 'خمهرح',\n",
    " 'خموتورح',\n",
    " 'خنصیرح',\n",
    " 'خودروح',\n",
    " 'خوسازح',\n",
    " 'خپارسح',\n",
    " 'خپویشح',\n",
    " 'خچرخشح',\n",
    " 'خکارح',\n",
    " 'خکاوهح',\n",
    " 'خکمکح',\n",
    " 'خگسترح',\n",
    " 'دابورح',\n",
    " 'دارابح',\n",
    " 'داروح',\n",
    " 'داسوهح',\n",
    " 'دالبرح',\n",
    " 'دامینح',\n",
    " 'داناح',\n",
    " 'دبالکح',\n",
    " 'دتمادح',\n",
    " 'دتهرانح',\n",
    " 'دتوزیعح',\n",
    " 'دتولیح',\n",
    " 'دتولیدح',\n",
    " 'دجابرح',\n",
    " 'ددامح',\n",
    " 'درازکح',\n",
    " 'درهآورح',\n",
    " 'دروزح',\n",
    " 'دزهراویح',\n",
    " 'دسانکوح',\n",
    " 'دسبحاح',\n",
    " 'دسبحانح',\n",
    " 'دسیناح',\n",
    " 'دشیریح',\n",
    " 'دشیمیح',\n",
    " 'دعبیدح',\n",
    " 'دفاراح',\n",
    " 'دفراح',\n",
    " 'دقاضیح',\n",
    " 'دلرح',\n",
    " 'دلقماح',\n",
    " 'دهدشتح',\n",
    " 'دپارسح',\n",
    " 'دکوثرح',\n",
    " 'دکپسولح',\n",
    " 'دکیمیح',\n",
    " 'دیرانح',\n",
    " 'رانفورح',\n",
    " 'رتاپح',\n",
    " 'رتکوح',\n",
    " 'رمپناح',\n",
    " 'رنیکح',\n",
    " 'رپارسح',\n",
    " 'رکیشح',\n",
    " 'زفکاح',\n",
    " 'زقیامح',\n",
    " 'زملاردح',\n",
    " 'زمگساح',\n",
    " 'زنجانح',\n",
    " 'زنگانح',\n",
    " 'زگلدشتح',\n",
    " 'ساذریح',\n",
    " 'سارابح',\n",
    " 'ساربیلح',\n",
    " 'ساروجح',\n",
    " 'سارومح',\n",
    " 'سامانح',\n",
    " 'سباقرح',\n",
    " 'سبجنوح',\n",
    " 'سبحانح',\n",
    " 'سبهانح',\n",
    " 'سترانح',\n",
    " 'سجامح',\n",
    " 'سخاشح',\n",
    " 'سخزرح',\n",
    " 'سخوافح',\n",
    " 'سخوزح',\n",
    " 'سدبیرح',\n",
    " 'سدشتح',\n",
    " 'سدورح',\n",
    " 'سرودح',\n",
    " 'سرچشمهح',\n",
    " 'سشرقح',\n",
    " 'سشمالح',\n",
    " 'سصفهاح',\n",
    " 'سصوفیح',\n",
    " 'سغربح',\n",
    " 'سفارح',\n",
    " 'سفارسح',\n",
    " 'سفارودح',\n",
    " 'سفاسیتح',\n",
    " 'سفانوح',\n",
    " 'سقاینح',\n",
    " 'سلارح',\n",
    " 'سمازنح',\n",
    " 'سمایهح',\n",
    " 'سمگاح',\n",
    " 'سنوینح',\n",
    " 'سنیرح',\n",
    " 'سهرمزح',\n",
    " 'سهگمتح',\n",
    " 'سپاهاح',\n",
    " 'سپح',\n",
    " 'سپرمیح',\n",
    " 'سکارونح',\n",
    " 'سکردح',\n",
    " 'سکرماح',\n",
    " 'سیدکوح',\n",
    " 'سیلامح',\n",
    " 'شاراکح',\n",
    " 'شاملاح',\n",
    " 'شبریزح',\n",
    " 'شبهرنح',\n",
    " 'شتهرانح',\n",
    " 'شتولیح',\n",
    " 'شتوکاح',\n",
    " 'شجمح',\n",
    " 'شخارکح',\n",
    " 'شدوصح',\n",
    " 'شرانلح',\n",
    " 'شرنگیح',\n",
    " 'شزنگح',\n",
    " 'شسمح',\n",
    " 'شسیناح',\n",
    " 'شصدفح',\n",
    " 'شصفهاح',\n",
    " 'شفاراح',\n",
    " 'شفارسح',\n",
    " 'شفنح',\n",
    " 'شلردح',\n",
    " 'شلعابح',\n",
    " 'شموادح',\n",
    " 'شنفتح',\n",
    " 'شپارسح',\n",
    " 'شپاسح',\n",
    " 'شپاکساح',\n",
    " 'شپتروح',\n",
    " 'شپدیسح',\n",
    " 'شپلیح',\n",
    " 'شپناح',\n",
    " 'شکبیرح',\n",
    " 'شکربنح',\n",
    " 'شکفح',\n",
    " 'شکلرح',\n",
    " 'شگلح',\n",
    " 'شیرازح',\n",
    " 'شیرانح',\n",
    " 'صباح',\n",
    " 'غاذرح',\n",
    " 'غالبرح',\n",
    " 'غبشهرح',\n",
    " 'غبهنوشح',\n",
    " 'غبهپاکح',\n",
    " 'غدامح',\n",
    " 'غدشتح',\n",
    " 'غسالمح',\n",
    " 'غشاذرح',\n",
    " 'غشانح',\n",
    " 'غشصفاح',\n",
    " 'غشهدابح',\n",
    " 'غشهدح',\n",
    " 'غشوکوح',\n",
    " 'غصینوح',\n",
    " 'غمارگح',\n",
    " 'غمشهدح',\n",
    " 'غمهراح',\n",
    " 'غمینوح',\n",
    " 'غنابح',\n",
    " 'غنوشح',\n",
    " 'غنیلیح',\n",
    " 'غویتاح',\n",
    " 'غپاکح',\n",
    " 'غپینوح',\n",
    " 'غچینح',\n",
    " 'غگرجیح',\n",
    " 'غگرگح',\n",
    " 'غگلح',\n",
    " 'فاذرح',\n",
    " 'فاراکح',\n",
    " 'فاسمینح',\n",
    " 'فافزاح',\n",
    " 'فالبرح',\n",
    " 'فالومح',\n",
    " 'فاماح',\n",
    " 'فاهوازح',\n",
    " 'فایراح',\n",
    " 'فباهنرح',\n",
    " 'فبیراح',\n",
    " 'فجامح',\n",
    " 'فجرح',\n",
    " 'فجوشح',\n",
    " 'فخاسح',\n",
    " 'فخوزح',\n",
    " 'فرآورح',\n",
    " 'فرومح',\n",
    " 'فزرینح',\n",
    " 'فساح',\n",
    " 'فسازانح',\n",
    " 'فسدیدح',\n",
    " 'فسربح',\n",
    " 'فسپاح',\n",
    " 'فلاتح',\n",
    " 'فلامیح',\n",
    " 'فلولهح',\n",
    " 'فماکح',\n",
    " 'فملیح',\n",
    " 'فن آواح',\n",
    " 'فنفتح',\n",
    " 'فنوالح',\n",
    " 'فنوردح',\n",
    " 'فولادح',\n",
    " 'فولاژح',\n",
    " 'فولایح',\n",
    " 'فوکاح',\n",
    " 'فپنتاح',\n",
    " 'قاسمح',\n",
    " 'قجامح',\n",
    " 'قرنح',\n",
    " 'قزوینح',\n",
    " 'قشرینح',\n",
    " 'قشهدح',\n",
    " 'قشکرح',\n",
    " 'قشیرح',\n",
    " 'قصفهاح',\n",
    " 'قلرستح',\n",
    " 'قنقشح',\n",
    " 'قنیشاح',\n",
    " 'قپارسح',\n",
    " 'لابساح',\n",
    " 'لازماح',\n",
    " 'لبوتانح',\n",
    " 'لخانهح',\n",
    " 'لخزرح',\n",
    " 'لراداح',\n",
    " 'لسرماح',\n",
    " 'لوتوسح',\n",
    " 'لپیامح',\n",
    " 'لکماح',\n",
    " 'مادیراح',\n",
    " 'مدارانح',\n",
    " 'مرقامح',\n",
    " 'معیارح',\n",
    " 'ملتح',\n",
    " 'میدکوح',\n",
    " 'میهنح',\n",
    " 'نبروجح',\n",
    " 'نتوسح',\n",
    " 'نشیراح',\n",
    " 'نمرینوح',\n",
    " 'نوینح',\n",
    " 'نیروح',\n",
    " 'هجرتح',\n",
    " 'همراهح',\n",
    " 'وآذرح',\n",
    " 'وآرینح',\n",
    " 'وآفریح',\n",
    " 'وآیندح',\n",
    " 'واتیح',\n",
    " 'وارسح',\n",
    " 'واعتبارح',\n",
    " 'والبرح',\n",
    " 'وامیدح',\n",
    " 'وانصارح',\n",
    " 'وبانکح',\n",
    " 'وبشهرح',\n",
    " 'وبملتح',\n",
    " 'وبهمنح',\n",
    " 'وبوعلیح',\n",
    " 'وبیمهح',\n",
    " 'وتجارتح',\n",
    " 'وتعاونح',\n",
    " 'وتوسح',\n",
    " 'وتوسمح',\n",
    " 'وتوسکاح',\n",
    " 'وتوشهح',\n",
    " 'وتوصاح',\n",
    " 'وتوکاح',\n",
    " 'وثوقح',\n",
    " 'وحافظح',\n",
    " 'وخارزمح',\n",
    " 'وخاورح',\n",
    " 'وداناح',\n",
    " 'ودیح',\n",
    " 'ورازیح',\n",
    " 'ورناح',\n",
    " 'وزمینح',\n",
    " 'وساختح',\n",
    " 'وساپاح',\n",
    " 'وسدیدح',\n",
    " 'وسرمدح',\n",
    " 'وسناح',\n",
    " 'وسپهح',\n",
    " 'وسکابح',\n",
    " 'وسیناح',\n",
    " 'وسینح',\n",
    " 'وشمالح',\n",
    " 'وصناح',\n",
    " 'وصندوقح',\n",
    " 'وصنعتح',\n",
    " 'وغدیرح',\n",
    " 'وقوامح',\n",
    " 'ولبهمنح',\n",
    " 'ولتجارح',\n",
    " 'ولرازح',\n",
    " 'ولساپاح',\n",
    " 'ولشرقح',\n",
    " 'ولصنمح',\n",
    " 'ولغدرح',\n",
    " 'ولقمانح',\n",
    " 'ولملتح',\n",
    " 'ولیزح',\n",
    " 'ومعادنح',\n",
    " 'وملتح',\n",
    " 'ومللح',\n",
    " 'وملیح',\n",
    " 'ونفتح',\n",
    " 'ونوینح',\n",
    " 'ونیروح',\n",
    " 'ونیکیح',\n",
    " 'وهامونح',\n",
    " 'وهورح',\n",
    " 'وپارسح',\n",
    " 'وپاسارح',\n",
    " 'وپتروح',\n",
    " 'وپخشح',\n",
    " 'وکادوح',\n",
    " 'وکارح',\n",
    " 'وکوثرح',\n",
    " 'وگردشح',\n",
    " 'پارتاح',\n",
    " 'پارسانح',\n",
    " 'پارسیانح',\n",
    " 'پاساح',\n",
    " 'پاکشوح',\n",
    " 'پتایرح',\n",
    " 'پترولح',\n",
    " 'پخشح',\n",
    " 'پدرخشح',\n",
    " 'پرداختح',\n",
    " 'پردیسح',\n",
    " 'پسهندح',\n",
    " 'پشاهنح',\n",
    " 'پلاستح',\n",
    " 'پلاسکح',\n",
    " 'پلولهح',\n",
    " 'پنکاح',\n",
    " 'پکرمانح',\n",
    " 'پکویرح',\n",
    " 'پکیانح',\n",
    " 'چافستح',\n",
    " 'چفیبرح',\n",
    " 'چکارلح',\n",
    " 'چکارنح',\n",
    " 'چکاوهح',\n",
    " 'کابگنح',\n",
    " 'کاذرح',\n",
    " 'کازروح',\n",
    " 'کاسپینح',\n",
    " 'کالبرح',\n",
    " 'کاماح',\n",
    " 'کاوهح',\n",
    " 'کایتاح',\n",
    " 'کبافقح',\n",
    " 'کترامح',\n",
    " 'کتوکاح',\n",
    " 'کحافظح',\n",
    " 'کخاکح',\n",
    " 'کدماح',\n",
    " 'کرازیح',\n",
    " 'کرماشاح',\n",
    " 'کرویح',\n",
    " 'کزغالح',\n",
    " 'کساوهح',\n",
    " 'کساپاح',\n",
    " 'کسراح',\n",
    " 'کسرامح',\n",
    " 'کسعدیح',\n",
    " 'کطبسح',\n",
    " 'کفرآورح',\n",
    " 'کفراح',\n",
    " 'کفپارسح',\n",
    " 'کقزویح',\n",
    " 'کلوندح',\n",
    " 'کماسهح',\n",
    " 'کمرجانح',\n",
    " 'کمنگنزح',\n",
    " 'کمیناح',\n",
    " 'کنورح',\n",
    " 'کهرامح',\n",
    " 'کهمداح',\n",
    " 'کوثرح',\n",
    " 'کورزح',\n",
    " 'کویرح',\n",
    " 'کپارسح',\n",
    " 'کپاناح',\n",
    " 'کپرورح',\n",
    " 'کپشیرح',\n",
    " 'کچادح',\n",
    " 'کگازح',\n",
    " 'کگلح',\n",
    " 'کگهرح',\n",
    " 'کی بی سیح',\n",
    " 'کیسونح',\n",
    " 'گوهرانح',\n",
    " 'گکیشح']\n",
    "right_offers = [(i,) for i in right_offers]\n",
    "right_offers = spark.createDataFrame(data= right_offers,  schema= valid_symbols_df.schema)\n",
    "valid_symbols_df = valid_symbols_df.union(right_offers).dropDuplicates()\n",
    "display_df(valid_symbols_df)\n",
    "\n",
    "handly_collected_valid_symbols = [\n",
    "    'فسلير',\n",
    "    'نگین',\n",
    "    'نیرو',\n",
    "    'غگز',\n",
    "    'آینده'\n",
    "]\n",
    "handly_collected_valid_symbols = [(i,) for i in handly_collected_valid_symbols]\n",
    "handly_collected_valid_symbols = spark.createDataFrame(data= handly_collected_valid_symbols,  schema= valid_symbols_df.schema)\n",
    "valid_symbols_df = valid_symbols_df.union(handly_collected_valid_symbols).dropDuplicates()\n",
    "display_df(valid_symbols_df)\n",
    "\n",
    "\n",
    "invalid_symbols = [\n",
    "                    'وکوثر',\n",
    "                    'حکمت',\n",
    "                    'ومهر',\n",
    "                    'جوین',\n",
    "                    'وقوام',\n",
    "                    'ممسنی',\n",
    "                    'غناب',\n",
    "                    'کارا',\n",
    "                    'کاوه',\n",
    "                    'گنگین',\n",
    "                    'وپویا',\n",
    "                    'ولپارس',\n",
    "                    'نوری',\n",
    "                    'شجی',\n",
    "                    'ثعمسا',\n",
    "                    'بگیلان',\n",
    "                    'بجهرم',\n",
    "                    'آرمانح',\n",
    "                    'شساخت',\n",
    "                    'ثخوز',\n",
    "                    'قاروم', # capital increase\n",
    "                    'امید',\n",
    "                    'وهنر',\n",
    "                    'تنوین',\n",
    "                    'وگردش',\n",
    "                    'آریان', # two different stocks with the same symbol\n",
    "                    'وآتوس', \n",
    "                    'همراه' # capital increase!\n",
    "    \n",
    "]\n",
    "\n",
    "valid_symbols_df = valid_symbols_df.filter(~F.col('symbol').isin(invalid_symbols))\n",
    "display_df(valid_symbols_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1ec79",
   "metadata": {},
   "source": [
    "## data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7742e756",
   "metadata": {},
   "source": [
    "### prepare trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f685558c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:00:11 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:00:13 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26223382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:00:32 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+----------------+------+------------+----------+--------------------+------------------------------------+------------------------------------+\n",
      "|date    |time  |secondsWithinDay|symbol|nTradeShares|tradePrice|tradeSettlementValue|buyerAccountId                      |sellerAccountId                     |\n",
      "+--------+------+----------------+------+------------+----------+--------------------+------------------------------------+------------------------------------+\n",
      "|13980110|115203|12963603        |ثامان |24928       |3390.0    |8.450592            |ECC77A89-C9AD-494F-8B49-4F178C2D7F3E|2AF253F2-7044-44EA-858B-09DA6A224E86|\n",
      "|13980110|120816|12963616        |ثاباد |2000        |2320.0    |0.464               |9288482E-9715-4DE3-AAB6-D20D2FB157DE|02F7AA8E-29E7-4594-ACD4-FDAEE6BA957B|\n",
      "|13980110|122054|12963654        |آسیا  |7573        |1876.0    |1.4206948           |5D9B391F-C8F1-48E8-A9D0-2215FFCB9FCB|C7470FDD-F4DA-472D-895A-EBD1ED249BAD|\n",
      "+--------+------+----------------+------+------------+----------+--------------------+------------------------------------+------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trade_df = (\n",
    "    raw_trade_df\n",
    "    .withColumn('secondsWithinDay', modify_time_udf('time'))\n",
    "    .join(valid_symbols_df, on = ['symbol'], how = 'inner')\n",
    "    .select(\n",
    "        'date',\n",
    "        'time',\n",
    "        'secondsWithinDay',\n",
    "        'symbol',\n",
    "        'nTradeShares',\n",
    "        'tradePrice',\n",
    "        'tradeSettlementValue',\n",
    "        dropSpace(F.col('buyerAccountId')).alias('buyerAccountId'),\n",
    "        dropSpace(F.col('sellerAccountId')).alias('sellerAccountId')\n",
    "    )\n",
    ")\n",
    "\n",
    "display_df(trade_df)\n",
    "# Note: 'time' columns is not reliable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "770cc438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:00:33 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:00:34 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing nTradeShares:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:00:35 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:00:37 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "[Stage 145:==================================================>    (62 + 5) / 67]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing tradeSettlementValue:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print('missing nTradeShares: ', round(trade_df.filter(F.col('nTradeShares') == 0).count() / trade_df.count(), 5))\n",
    "print('missing tradeSettlementValue: ', round(trade_df.filter(F.col('tradeSettlementValue') == 0).count() / trade_df.count(), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc780728",
   "metadata": {},
   "source": [
    "### prepare initial portfolio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82489bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPSYMB', 'SPDATE', 'SPACC#', 'SPTROH']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_portfolio_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9740e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12109854\n",
      "+--------+------+------------------------------------+-----------+\n",
      "|date    |symbol|accountId                           |nHeldShares|\n",
      "+--------+------+------------------------------------+-----------+\n",
      "|13980105|خساپا |37D6BD7D-DCF6-4B34-9ACC-AAA8111E0243|32850      |\n",
      "|13980105|خساپا |F5094FE0-46A8-4C7F-86CD-6EA2DC8D5B42|2237       |\n",
      "|13980105|اخابر |47229110-AA3E-4972-985B-670E61BAC864|384        |\n",
      "+--------+------+------------------------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mapping = (\n",
    "    dict(\n",
    "    zip(\n",
    "        ['SPDATE', 'SPSYMB', 'SPACC#', 'SPTROH'],\n",
    "        ['date', 'symbol', 'accountId', 'nHeldShares'],\n",
    "    )\n",
    "    )\n",
    ")\n",
    "\n",
    "portfolio_df = (\n",
    "    raw_portfolio_df\n",
    "    .select(\n",
    "    [F.col(c).alias(mapping.get(c, c)) for c in raw_portfolio_df.columns]\n",
    "    )\n",
    "    .select(\n",
    "        'date',\n",
    "        'symbol',\n",
    "        dropSpace(F.col('accountId')).alias('accountId'),\n",
    "        'nHeldShares'\n",
    "    )\n",
    ")\n",
    "\n",
    "portfolio_df = replace_arabic_characters_and_correct_symbol_names(portfolio_df)\n",
    "display_df(portfolio_df)\n",
    "\n",
    "\n",
    "replaceChar = F.udf(lambda s: s[:-1], T.StringType())\n",
    "\n",
    "def agg(x):\n",
    "    t = ''\n",
    "    for i in x.split(' '):\n",
    "        t += i\n",
    "    return t\n",
    "\n",
    "def cleaning(data):\n",
    "    data = (\n",
    "        data\n",
    "        .withColumn(\n",
    "        'symbol',\n",
    "        F.when(F.col('symbol').endswith('ج'),\n",
    "         replaceChar(F.col('symbol'))).otherwise(\n",
    "            F.col('symbol')\n",
    "        )\n",
    "        )\n",
    "    )\n",
    "    for i in ['اوج', 'بکهنوج', 'ساروج', 'نبروج', 'وسخراج']:\n",
    "            data = (\n",
    "                data\n",
    "                .withColumn(\n",
    "                    'symbol', F.when(F.col('symbol') == i[:-1], i).otherwise(F.col('symbol'))\n",
    "                )\n",
    "            )\n",
    "    data = data.dropDuplicates()\n",
    "    return data\n",
    "\n",
    "portfolio_df = cleaning(portfolio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f7b8d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:00:50 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:01:01 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:01:11 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8769334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:01:15 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+--------+------+-----------+\n",
      "|accountId                           |date    |symbol|nHeldShares|\n",
      "+------------------------------------+--------+------+-----------+\n",
      "|A196287E-81E5-4C65-B155-B9BEBC3BE905|13980105|پتایر |230        |\n",
      "|7176A068-09E1-4A19-9644-53529D392E4F|13980105|فلامی |1462       |\n",
      "|023156CF-DFA6-43E6-9897-79511AA14397|13980105|وسکاب |1936       |\n",
      "+------------------------------------+--------+------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "portfolio_df = (\n",
    "    portfolio_df\n",
    "    .join(valid_symbols_df, on = ['symbol'], how = 'inner')\n",
    "    .groupBy(['accountId','date','symbol'])\n",
    "    .agg(\n",
    "        F.sum('nHeldShares').alias('nHeldShares')\n",
    "    )\n",
    ")\n",
    "\n",
    "display_df(portfolio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea4552df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:01:17 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    portfolio_df\n",
    "    .filter(F.col('nHeldShares') < 0)\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e36b40",
   "metadata": {},
   "source": [
    "#### check symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c87b783c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:01:19 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:01:20 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:01:21 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:01:32 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:01:37 WARN DAGScheduler: Broadcasting large task binary with size 35.9 MiB\n",
      "[Stage 190:>                                                        (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "price_symbols = price_df.select('symbol').distinct().withColumn('price', F.lit(1))\n",
    "trade_symbols = trade_df.select('symbol').distinct().withColumn('trade', F.lit(1))\n",
    "portfolio_symbols = portfolio_df.select('symbol').distinct().withColumn('portfolio', F.lit(1))\n",
    "\n",
    "symbols_df = (\n",
    "    trade_symbols\n",
    "    .join(portfolio_symbols, on = ['symbol'], how = 'outer')\n",
    "    .join(price_symbols, on = ['symbol'], how = 'outer')\n",
    ")\n",
    "\n",
    "print(symbols_df.filter(F.col('price').isNull()).select('symbol').rdd.flatMap(lambda x: x).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8bf5411",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Window().partitionBy('symbol').orderBy('date')\n",
    "w2 = Window().partitionBy('symbol').orderBy(price_df.date.desc())\n",
    "\n",
    "price_return_df = (price_df.select('symbol', 'mktcap',\n",
    "   ((\n",
    "       F.first('close_price',True).over(w2) - F.first('close_price',True).over(w)\n",
    "       ) \n",
    "       / F.first('close_price',True).over(w)\n",
    "       ).alias('price_return'),\n",
    "       )\n",
    "   .dropDuplicates(['symbol'])\n",
    ")\n",
    "tempt = price_df.na.drop(\n",
    "    how = 'any',\n",
    ")\n",
    "large_small_stocks =( \n",
    "    tempt[tempt.date == 13980328]\n",
    "    .withColumn('sizeDecile', F.ntile(10).over(Window.partitionBy().orderBy('mktcap')))\n",
    ") \n",
    "price_return_df = price_return_df.join(\n",
    "    large_small_stocks.select(\n",
    "        F.col('symbol'),\n",
    "    F.col('sizeDecile'),\n",
    "    ) , on =['symbol']\n",
    ").select(\n",
    "    F.col('symbol'),\n",
    "    F.col('mktcap'),\n",
    "    F.col('price_return'),\n",
    "    F.col('sizeDecile'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f91287f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:01:38 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/23 09:01:39 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:01:39 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:01:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/23 09:01:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/23 09:01:47 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:01:48 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/02/23 09:01:49 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+------------+\n",
      "|sizeDecile|medianmktcap|meanReturn|medianReturn|\n",
      "+----------+------------+----------+------------+\n",
      "|         1|    33021.78|      0.52|       0.044|\n",
      "|         2|     69850.0|      0.49|       0.389|\n",
      "|         3|    111675.0|       0.6|       0.493|\n",
      "|         4|    147260.0|      0.61|       0.514|\n",
      "|         5|    203036.0|      0.62|       0.562|\n",
      "|         6|    296800.0|      0.57|       0.519|\n",
      "|         7|    435278.0|      0.69|       0.545|\n",
      "|         8|    703566.0|      0.78|       0.558|\n",
      "|         9|   1570800.0|      0.62|       0.383|\n",
      "|        10|   8119500.0|      0.25|       0.205|\n",
      "+----------+------------+----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 199:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    price_return_df\n",
    "    .groupBy('sizeDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(mktcap, array(0.5))')[0], 3).alias('medianmktcap'),\n",
    "        F.round(F.mean('price_return'), 2).alias('meanReturn'),\n",
    "        F.round(F.expr('percentile(price_return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .orderBy('sizeDecile')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadcc966",
   "metadata": {},
   "source": [
    "### general insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce268b2f",
   "metadata": {},
   "source": [
    "#### check compatibility of the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1136345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:01:53 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:01:53 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:02:03 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:02:13 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:02:40 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4371963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:02:46 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-----+---------+\n",
      "|accountId                           |trade|portfolio|\n",
      "+------------------------------------+-----+---------+\n",
      "|00019AFD-C89B-4B63-98BB-18BF5A112C6F|0    |1        |\n",
      "|000217BA-3C48-4458-8CAA-691CA19C7187|0    |1        |\n",
      "|000249D5-649B-4C99-AE9E-82AB979E80C9|0    |1        |\n",
      "+------------------------------------+-----+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_investors_df = (\n",
    "    trade_df\n",
    "    .select(F.col('buyerAccountId').alias('accountId'))\n",
    "    .union(trade_df.select(F.col('sellerAccountId').alias('accountId')))\n",
    "    .dropDuplicates()\n",
    "    .withColumn('trade', F.lit(1))\n",
    "    .join(portfolio_df.select('accountId', F.lit(1).alias('portfolio')).dropDuplicates(), on = ['accountId'], how = 'outer')\n",
    "    .fillna(0, subset = ['trade', 'portfolio'])\n",
    ")\n",
    "\n",
    "display_df(common_investors_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c64cfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:02:48 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/23 09:02:51 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "[Stage 261:====================================================>(197 + 3) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "share of missing portfolio accounts among traders: 21.13 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trade_only = common_investors_df.filter( (F.col('trade') == 1) & (F.col('portfolio') == 0)).count()\n",
    "all_trade = common_investors_df.filter(F.col('trade') == 1).count()\n",
    "\n",
    "print('share of missing portfolio accounts among traders:', round(100 * trade_only / all_trade, 2), '%')\n",
    "# It seems reasonable to attribute this missing portion to the new entrants!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcd296ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:02:55 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/23 09:02:59 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "[Stage 303:=========================================>          (160 + 40) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "share of missing trades among investors who have nitial portfolio: 86.21 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "portfolio_only = common_investors_df.filter( (F.col('trade') == 0) & (F.col('portfolio') == 1)).count()\n",
    "all_portfolio = common_investors_df.filter(F.col('portfolio') == 1).count()\n",
    "\n",
    "print('share of missing trades among investors who have nitial portfolio:', round(100 * portfolio_only / all_portfolio, 2), '%')\n",
    "# It seems reasonable to attribute this missing portion to the new entrants!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f648283",
   "metadata": {},
   "source": [
    "#### number of unique investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8734063d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:03:02 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:03:09 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:03:11 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:03:24 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "737297"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    trade_df\n",
    "    .select(F.col('buyerAccountId').alias('accountId'))\n",
    "    .union(trade_df.select(F.col('sellerAccountId').alias('accountId')))\n",
    "    .dropDuplicates()\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1404424a",
   "metadata": {},
   "source": [
    "#### number of stocks within investors' initial portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca33d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:03:27 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:03:35 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:03:38 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+---+---+----+\n",
      "|25%|50%|  mean|75%|90%| 99%|\n",
      "+---+---+------+---+---+----+\n",
      "|1.0|1.0|2.0799|2.0|4.0|15.0|\n",
      "+---+---+------+---+---+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    portfolio_df\n",
    "    .groupBy('accountId')\n",
    "    .count()\n",
    "    .agg(\n",
    "        F.expr('percentile(count, array(0.25))')[0].alias('25%'),\n",
    "        F.expr('percentile(count, array(0.50))')[0].alias('50%'),\n",
    "        F.round(F.mean('count'), 4).alias('mean'),\n",
    "        F.expr('percentile(count, array(0.75))')[0].alias('75%'),\n",
    "        F.expr('percentile(count, array(0.9))')[0].alias('90%'),\n",
    "        F.expr('percentile(count, array(0.99))')[0].alias('99%'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9a817",
   "metadata": {},
   "source": [
    "#### compare trade value of new entrants with other investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2175dbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:03:40 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/23 09:03:40 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:03:47 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/23 09:03:52 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "22/02/23 09:04:34 WARN DAGScheduler: Broadcasting large task binary with size 18.1 MiB\n",
      "[Stage 394:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------+-------------+\n",
      "|hasPortfolio|median_buyValue|mean_buyValue|\n",
      "+------------+---------------+-------------+\n",
      "|           1|            1.0|         3.44|\n",
      "|           0|           0.78|         2.57|\n",
      "+------------+---------------+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    common_investors_df\n",
    "    .select(F.col('accountId').alias('buyerAccountId'), F.col('portfolio').alias('hasPortfolio'))\n",
    "    .join(trade_df, on = ['buyerAccountId'], how = 'right')\n",
    "    .groupBy('hasPortfolio')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(tradeSettlementValue, array(0.5))')[0], 2).alias('median_buyValue'),\n",
    "        F.round(F.mean('tradeSettlementValue'), 2).alias('mean_buyValue')\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8053c16",
   "metadata": {},
   "source": [
    "#### stocks whose shares were given to the mass general public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e6c3a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:04:45 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:04:58 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:05:06 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:05:14 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:05:17 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:05:18 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:05:22 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+--------+-----------+--------------+\n",
      "|symbol|nHeldShares|nHolders|nAllHolders|shareOfHolders|\n",
      "+------+-----------+--------+-----------+--------------+\n",
      "|زماهان|120        |266735  |332130     |0.803         |\n",
      "|ومعلم |229        |209919  |261378     |0.803         |\n",
      "|سمایه |300        |185411  |302045     |0.614         |\n",
      "+------+-----------+--------+-----------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mass_public_stocks_df = (\n",
    "    portfolio_df\n",
    "    .groupBy('symbol', 'nHeldShares')\n",
    "    .agg(\n",
    "        F.countDistinct('accountId').alias('nHolders')\n",
    "    )\n",
    "    .withColumn('nAllHolders', F.sum('nHolders').over(Window.partitionBy('symbol')))\n",
    "    .withColumn('rank', F.row_number().over(Window.partitionBy('symbol').orderBy(F.desc('nHolders'))))\n",
    "    .filter(F.col('rank') == 1)\n",
    "    .drop('rank')\n",
    "    .orderBy(F.desc('nHolders'))\n",
    "    .withColumn('shareOfHolders', F.round(F.col('nHolders') / F.col('nAllHolders'), 3))\n",
    "#     .join(price_df.filter(F.col('date') == 13980105).select('symbol', 'shrout'), on = 'symbol', how = 'left')\n",
    "#     .withColumn('shareOfShares', F.round(F.col('nHeldShares')*F.col('nHolders') / F.col('shrout'), 3))\n",
    ")\n",
    "\n",
    "display_df(mass_public_stocks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66bf7921",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:05:24 WARN DAGScheduler: Broadcasting large task binary with size 18.2 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "mass_public_stocks_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/mass_public_stocks.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540fccf5",
   "metadata": {},
   "source": [
    "## make daily portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f441ad93",
   "metadata": {},
   "source": [
    "### flatten trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b418b750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 431:=====================================================> (52 + 1) / 53]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15170298\n",
      "+--------+------+------------------------------------+------------+---------+------+\n",
      "|date    |symbol|accountId                           |nTradeShares|cashOut  |cashIn|\n",
      "+--------+------+------------------------------------+------------+---------+------+\n",
      "|13980204|ومعلم |D41B1B0F-FB40-4ACE-BF3B-4AA4E6700EA2|-229        |0.074654 |0.0   |\n",
      "|13980204|پارس  |D41B1B0F-FB40-4ACE-BF3B-4AA4E6700EA2|-2          |0.0076702|0.0   |\n",
      "|13980204|بزاگرس|D41B1B0F-FB40-4ACE-BF3B-4AA4E6700EA2|-449        |0.145476 |0.0   |\n",
      "+--------+------+------------------------------------+------------+---------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "raw_flat_trade_df = spark.read.parquet(PATH_TRADE + \"{}\".format(\"raw_flat_trade_df.parquet\"))\n",
    "\n",
    "display_df(raw_flat_trade_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08ad61c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 435:======================>                               (22 + 31) / 53]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.42 %\n"
     ]
    }
   ],
   "source": [
    "print(round(100*raw_flat_trade_df.filter(\n",
    "    (F.col('cashIn') != 0)&\n",
    "    (F.col('cashOut') != 0) ).count() / raw_flat_trade_df.count(), 2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83403428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:05:32 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "[Stage 444:=============================================>        (57 + 10) / 67]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(raw_flat_trade_df.filter(F.col('nTradeShares') == 0).count())\n",
    "print(trade_df.filter(F.col('tradeSettlementValue') == 0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f63a68b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(raw_flat_trade_df.filter(F.col('cashIn') > 0 ).count())\n",
    "print(raw_flat_trade_df.filter(F.col('cashOut') < 0 ).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a9ddc",
   "metadata": {},
   "source": [
    "### make daily portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a07adcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:05:35 WARN DAGScheduler: Broadcasting large task binary with size 17.9 MiB\n",
      "22/02/23 09:06:14 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:06:28 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:06:32 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:06:41 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:06:51 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23765673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:06:59 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------------------------------------+----------+----------+---------+\n",
      "|date    |symbol|accountId                           |heldShares|netCashOut|netCashIn|\n",
      "+--------+------+------------------------------------+----------+----------+---------+\n",
      "|13980105|چکاپا |00026661-733B-49E0-AC93-ED5812290A9B|1740      |0.0       |0.0      |\n",
      "|13980221|چکاپا |00026661-733B-49E0-AC93-ED5812290A9B|0         |0.83346   |0.0      |\n",
      "|13980105|ارفع  |00029878-6EF9-49A7-B231-61DBED05BDE7|32796     |0.0       |0.0      |\n",
      "+--------+------+------------------------------------+----------+----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_daily_portfolio():\n",
    "    window = (\n",
    "        Window.partitionBy('accountId', 'symbol')\n",
    "        .orderBy('date')\n",
    "        .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "    )\n",
    "    return (F.sum('nHeldShares').over(window), F.sum('cashOut').over(window), F.sum('cashIn').over(window))\n",
    "\n",
    "raw_daily_portfolio_df = (\n",
    "    portfolio_df\n",
    "    .select('date',\n",
    "            'symbol', \n",
    "            'accountId', \n",
    "            'nHeldShares', \n",
    "            F.lit(0).alias('cashOut'),\n",
    "            F.lit(0).alias('cashIn')\n",
    "           )\n",
    "    .union(\n",
    "        raw_flat_trade_df\n",
    "        .withColumnRenamed('nTradeShares', 'nHeldShares')\n",
    "    )\n",
    "    .groupBy('date', 'symbol', 'accountId')\n",
    "    .agg(\n",
    "        F.sum('nHeldShares').alias('nHeldShares'),\n",
    "        F.sum('cashOut').alias('cashOut'),\n",
    "        F.sum('cashIn').alias('cashIn')\n",
    "    )\n",
    "    .orderBy('accountId', 'date')\n",
    "    .withColumn('heldShares', make_daily_portfolio()[0])\n",
    "    .withColumn('netCashOut', make_daily_portfolio()[1])\n",
    "    .withColumn('netCashIn', make_daily_portfolio()[2])\n",
    "    .drop('nHeldShares', 'settlementValue', 'cashIn', 'cashOut')\n",
    ")\n",
    "\n",
    "display_df(raw_daily_portfolio_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8d88ef",
   "metadata": {},
   "source": [
    "#### invalid holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1260a1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:07:01 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:07:04 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-------+--------------+\n",
      "|accountId                           |symbol |invalidHolding|\n",
      "+------------------------------------+-------+--------------+\n",
      "|006BE8C1-A950-44B8-B2B5-FD293FAFD7B6|وساپا  |1             |\n",
      "|0122EC9B-B0A1-4510-8D41-55731733AE20|ومعلم  |1             |\n",
      "|01ED3611-405C-432F-B2A0-E0CC337FA36F|فرابورس|1             |\n",
      "+------------------------------------+-------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:07:06 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14601858\n",
      "+------------------------------------+------+--------+------------+---------+------+\n",
      "|accountId                           |symbol|date    |nTradeShares|cashOut  |cashIn|\n",
      "+------------------------------------+------+--------+------------+---------+------+\n",
      "|D41B1B0F-FB40-4ACE-BF3B-4AA4E6700EA2|ومعلم |13980204|-229        |0.074654 |0.0   |\n",
      "|D41B1B0F-FB40-4ACE-BF3B-4AA4E6700EA2|پارس  |13980204|-2          |0.0076702|0.0   |\n",
      "|D41B1B0F-FB40-4ACE-BF3B-4AA4E6700EA2|بزاگرس|13980204|-449        |0.145476 |0.0   |\n",
      "+------------------------------------+------+--------+------------+---------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:07:15 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:07:16 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23160625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:07:23 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+------+--------+----------+----------+---------+\n",
      "|accountId                           |symbol|date    |heldShares|netCashOut|netCashIn|\n",
      "+------------------------------------+------+--------+----------+----------+---------+\n",
      "|00026661-733B-49E0-AC93-ED5812290A9B|چکاپا |13980105|1740      |0.0       |0.0      |\n",
      "|00026661-733B-49E0-AC93-ED5812290A9B|چکاپا |13980221|0         |0.83346   |0.0      |\n",
      "|00029878-6EF9-49A7-B231-61DBED05BDE7|ارفع  |13980105|32796     |0.0       |0.0      |\n",
      "+------------------------------------+------+--------+----------+----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "invalid_holdings_df = (\n",
    "    raw_daily_portfolio_df\n",
    "    .filter(F.col('heldShares') < 0)\n",
    "    .select('accountId', 'symbol')\n",
    "    .dropDuplicates()\n",
    "    .withColumn('invalidHolding', F.lit(1))\n",
    ")\n",
    "display_df(invalid_holdings_df)\n",
    "\n",
    "\n",
    "flat_trade_df = (\n",
    "    raw_flat_trade_df\n",
    "    .join(invalid_holdings_df, on = ['accountId', 'symbol'], how = 'left')\n",
    "    .filter(F.col('invalidHolding').isNull())\n",
    "    .drop('invalidHolding')\n",
    ")\n",
    "display_df(flat_trade_df)\n",
    "\n",
    "\n",
    "daily_portfolio_df = (\n",
    "    raw_daily_portfolio_df\n",
    "    .join(invalid_holdings_df, on = ['accountId', 'symbol'], how = 'left')\n",
    "    .filter(F.col('invalidHolding').isNull())\n",
    "    .drop('invalidHolding')\n",
    ")\n",
    "display_df(daily_portfolio_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f89a234",
   "metadata": {},
   "source": [
    "#### new entrants df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "784d72f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:07:26 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "22/02/23 09:07:36 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:07:41 WARN DAGScheduler: Broadcasting large task binary with size 18.0 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+---------+\n",
      "|accountId                           |firstDate|\n",
      "+------------------------------------+---------+\n",
      "|000E126E-9959-4796-A329-C9839A3C0FED|13980231 |\n",
      "|00B67D2A-565A-4D31-9C1F-9E329D76B018|13980209 |\n",
      "|00E62831-4844-4CF1-9611-68FB9FB76B80|13980209 |\n",
      "+------------------------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_entrant_account_ids_df = (\n",
    "    flat_trade_df\n",
    "    .groupBy('accountId')\n",
    "    .agg(\n",
    "        F.min('date').alias('firstDate')\n",
    "    )\n",
    "    .join(portfolio_df.select('accountId').distinct(), on = 'accountId', how = 'left_anti')\n",
    ")\n",
    "\n",
    "display_df(new_entrant_account_ids_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f286fd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 09:08:00 WARN DAGScheduler: Broadcasting large task binary with size 18.2 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "new_entrant_account_ids_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/new_entrant_account_ids.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bea8eeb",
   "metadata": {},
   "source": [
    "#### time series of new entrants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_entrantd_time_series_df = (\n",
    "    flat_trade_df\n",
    "    .select('date', 'accountId')\n",
    "    .dropDuplicates()\n",
    "    .join(new_entrant_account_ids_df, on = 'accountId', how = 'inner')\n",
    "    .withColumn('rank', F.row_number().over(Window.partitionBy('accountId').orderBy('date')))\n",
    "    .filter(F.col('rank') == 1)\n",
    "    .drop('rank')\n",
    "    .groupBy('date')\n",
    "    .count()\n",
    "    .orderBy('date')\n",
    ")\n",
    "\n",
    "display_df(new_entrantd_time_series_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0d66e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_entrantd_time_series_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/new_entrantd_time_series_df.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8921a7",
   "metadata": {},
   "source": [
    "### calculate gain from trade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd50b51f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gain_from_trade_df = (\n",
    "    flat_trade_df\n",
    "    .groupBy('accountId')\n",
    "    .agg(\n",
    "        F.sum('cashOut').alias('netCashOut'),\n",
    "        F.sum('cashIn').alias('netCashIn'),\n",
    "    )\n",
    ")\n",
    "\n",
    "display_df(gain_from_trade_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d0b98",
   "metadata": {},
   "source": [
    "### calculate value of the initial portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99972117",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_portfolio_value_df = (\n",
    "    portfolio_df\n",
    "    .join(price_df.select('date', 'symbol', 'close_price'), on = ['date', 'symbol'], how = 'left')\n",
    "    .dropna(subset = ['close_price'])\n",
    "    .join(invalid_holdings_df, on = ['accountId', 'symbol'], how = 'left')\n",
    "    .filter(F.col('invalidHolding').isNull())\n",
    "    .withColumn('value', F.col('nHeldShares') * F.col('close_price'))\n",
    "    .groupBy('accountId')\n",
    "    .agg(\n",
    "        (F.sum('value') / 10**7).alias('initialPortfolioValue')\n",
    "    )\n",
    ")\n",
    "\n",
    "display_df(initial_portfolio_value_df)\n",
    "# count after join?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471edd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(initial_portfolio_value_df.filter(F.col('initialPortfolioValue').isNull()).count())\n",
    "print(initial_portfolio_value_df.filter(F.col('initialPortfolioValue') <= 0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7555037",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (\n",
    "#     initial_portfolio_value_df\n",
    "#     .agg(\n",
    "#         F.round(F.min('initialPortfolioValue'), 2).alias('min'),\n",
    "#         F.round(F.expr('percentile(initialPortfolioValue, array(0.01))')[0], 2).alias('1%'),\n",
    "#         F.round(F.expr('percentile(initialPortfolioValue, array(0.25))')[0], 2).alias('25%'),\n",
    "#         F.round(F.expr('percentile(initialPortfolioValue, array(0.5))')[0], 2).alias('50%'),\n",
    "#         F.round(F.mean('initialPortfolioValue'), 2).alias('mean'),\n",
    "#         F.round(F.expr('percentile(initialPortfolioValue, array(0.75))')[0], 2).alias('75%'),\n",
    "#         F.round(F.expr('percentile(initialPortfolioValue, array(0.9))')[0], 2).alias('90%'),\n",
    "#         F.round(F.expr('percentile(initialPortfolioValue, array(0.99))')[0], 2).alias('99%'),\n",
    "#         F.round(F.expr('percentile(initialPortfolioValue, array(0.999))')[0], 2).alias('99.9%'),\n",
    "#     )\n",
    "#     .show()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d20769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_portfolio_value_df.write.mode('overwrite').parquet('/home/user1/Data/initial_portfolio_value_df.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b160c9ac",
   "metadata": {},
   "source": [
    "### calculate value of the final portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d21e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_portfolio_value_df = (\n",
    "    daily_portfolio_df\n",
    "    .withColumn('rowNumber', F.row_number().over(Window.partitionBy('accountId', 'symbol').orderBy('date')))\n",
    "    .withColumn('maxRowNumber', F.max('rowNumber').over(Window.partitionBy('accountId', 'symbol')))\n",
    "    .filter(F.col('rowNumber') == F.col('maxRowNumber'))\n",
    "    .filter(F.col('heldShares') > 0)\n",
    "    .withColumn('date', F.lit(MAX_PRICE_DATE))\n",
    "    .join(price_df.select('date', 'symbol', 'close_price'), on = ['date', 'symbol'], how = 'left')\n",
    "    .dropna(subset = ['close_price'])\n",
    "    .withColumn('value', F.col('heldShares') * F.col('close_price'))\n",
    "    .groupBy('accountId')\n",
    "    .agg(\n",
    "        (F.sum('value') / 10**7).alias('finalPortfolioValue')\n",
    "    )   \n",
    ")\n",
    "\n",
    "display_df(final_portfolio_value_df)\n",
    "# count after join?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189eaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_portfolio_value_df.filter(F.col('finalPortfolioValue').isNull()).count())\n",
    "print(final_portfolio_value_df.filter(F.col('finalPortfolioValue') <= 0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd6e870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     final_portfolio_value_df\n",
    "#     .agg(\n",
    "#         F.round(F.min('finalPortfolioValue'), 2).alias('min'),\n",
    "#         F.round(F.expr('percentile(finalPortfolioValue, array(0.1))')[0], 2).alias('10%'),\n",
    "#         F.round(F.expr('percentile(finalPortfolioValue, array(0.25))')[0], 2).alias('25%'),\n",
    "#         F.round(F.expr('percentile(finalPortfolioValue, array(0.5))')[0], 2).alias('50%'),\n",
    "#         F.round(F.mean('finalPortfolioValue'), 2).alias('mean'),\n",
    "#         F.round(F.expr('percentile(finalPortfolioValue, array(0.75))')[0], 2).alias('75%'),\n",
    "#         F.round(F.expr('percentile(finalPortfolioValue, array(0.9))')[0], 2).alias('90%'),\n",
    "#         F.round(F.expr('percentile(finalPortfolioValue, array(0.99))')[0], 2).alias('99%'),\n",
    "#         F.round(F.expr('percentile(finalPortfolioValue, array(0.999))')[0], 2).alias('99.9%'),\n",
    "#     )\n",
    "#     .show()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_portfolio_value_df.write.mode('overwrite').parquet('/home/user1/Data/final_portfolio_value_df.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4559c87",
   "metadata": {},
   "source": [
    "### time series of the net cash in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e5958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_portfolio_value_df = (\n",
    "    final_portfolio_value_df\n",
    "    .join(initial_portfolio_value_df, on = ['accountId'], how = 'outer')\n",
    "    .fillna(0)\n",
    "    .withColumn('maxPortfolioValue', F.greatest(F.col('initialPortfolioValue'), F.col('finalPortfolioValue')))\n",
    "    .withColumn('type', F.when(F.col('maxPortfolioValue') < 10, 'lessThan10MT')\n",
    "                         .when(F.col('maxPortfolioValue').between(10, 20), 'between10MTand20MT')\n",
    "                         .when(F.col('maxPortfolioValue').between(20, 50), 'between20MTand50MT')\n",
    "                         .otherwise('greaterThan50MT')\n",
    "               )\n",
    "    .select('accountId', 'type')\n",
    "    .dropDuplicates()\n",
    ")\n",
    "\n",
    "display_df(max_portfolio_value_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e94749",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_list = price_df.select('date').distinct().orderBy('date').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "cash_time_series_df = (\n",
    "    flat_trade_df\n",
    "    .withColumn('netCash', F.col('cashIn') + F.col('cashOut'))\n",
    "    .join(max_portfolio_value_df, on = 'accountId', how = 'inner')\n",
    "    .groupBy('type', 'date')\n",
    "    .agg(\n",
    "        F.round((-F.sum('netCash'))).alias('netCash'),\n",
    "        F.countDistinct('accountId').alias('nAccounts')\n",
    "    )\n",
    "    .orderBy('date', 'type')\n",
    ")\n",
    "\n",
    "cash_time_series_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc6d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cash_time_series_df.write.mode('overwrite').parquet('/home/user1/Data/cash_time_series.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385da296",
   "metadata": {},
   "source": [
    "## calculate returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2991a55a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "return_df = (\n",
    "    gain_from_trade_df\n",
    "    .join(initial_portfolio_value_df, on = 'accountId', how = 'outer')\n",
    "    .join(final_portfolio_value_df, on = 'accountId', how = 'outer')\n",
    "    .fillna(0, subset = ['netCashIn', 'netCashOut', 'initialPortfolioValue', 'finalPortfolioValue'])\n",
    "    .withColumn('return', \n",
    "                ((F.col('finalPortfolioValue') + F.col('netCashOut')) / (F.col('initialPortfolioValue') + (-F.col('netCashIn')))) - 1)\n",
    "    .filter(F.col('return').isNotNull())\n",
    "    .withColumn('returnDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('return')))\n",
    ")\n",
    "\n",
    "display_df(return_df)\n",
    "# null returns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4927024",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    return_df\n",
    "    .filter(F.col('return') == 0)\n",
    "    .count()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cca050",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    return_df\n",
    "    .groupBy('returnDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba304564",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    return_df\n",
    "    .agg(\n",
    "       F.round(F.min('return'), 2).alias('min'),\n",
    "        F.round(F.expr('percentile(return, array(0.01))')[0], 2).alias('1%'),\n",
    "        F.round(F.expr('percentile(return, array(0.1))')[0], 2).alias('10%'),\n",
    "        F.round(F.expr('percentile(return, array(0.25))')[0], 2).alias('25%'),\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 2).alias('50%'),\n",
    "        F.round(F.mean('return'), 2).alias('mean'),\n",
    "        F.round(F.expr('percentile(return, array(0.75))')[0], 2).alias('75%'),\n",
    "        F.round(F.expr('percentile(return, array(0.9))')[0], 2).alias('90%'),\n",
    "        F.round(F.expr('percentile(return, array(0.99))')[0], 2).alias('99%'),\n",
    "        F.round(F.expr('percentile(return, array(0.999))')[0], 2).alias('99.9%'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7359d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/return_output.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9304442a",
   "metadata": {},
   "source": [
    "### final portfolio value output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a77650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_final_portfolio_value = (\n",
    "    final_portfolio_value_df\n",
    "    .join(return_df.select('accountId', 'return'), on = 'accountId')\n",
    "    .withColumn('finalPortfolioValueDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('finalPortfolioValue')))\n",
    ")\n",
    "\n",
    "display_df(output_final_portfolio_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    output_final_portfolio_value\n",
    "    .groupBy('finalPortfolioValueDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(finalPortfolioValue, array(0.5))')[0], 3).alias('medianFinalPortfolioValue'),\n",
    "        F.round(F.mean('return'), 2).alias('meanReturn'),\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .orderBy('finalPortfolioValueDecile')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bce316",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_final_portfolio_value.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/final_portfolio_output.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2173cf42",
   "metadata": {},
   "source": [
    "### initial portfolio value output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5e118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_initial_portfolio_value = (\n",
    "    initial_portfolio_value_df\n",
    "    .join(return_df.select('accountId', 'return'), on = 'accountId')\n",
    "    .withColumn('initialPortfolioValueDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('initialPortfolioValue')))\n",
    ")\n",
    "\n",
    "display_df(output_initial_portfolio_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba26784",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    output_initial_portfolio_value\n",
    "    .groupBy('initialPortfolioValueDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(initialPortfolioValue, array(0.5))')[0], 3).alias('medianInitialPortfolioValue'),\n",
    "        F.round(F.mean('return'), 2).alias('meanReturn'),\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 5).alias('medianReturn')\n",
    "    )\n",
    "    .orderBy('initialPortfolioValueDecile')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c42db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_initial_portfolio_value.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/inital_portfolio_output.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4358eef",
   "metadata": {},
   "source": [
    "### calculate frequency of trades and active days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc91189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_days_df = (\n",
    "    raw_flat_trade_df\n",
    "    .groupBy('accountId', 'date')\n",
    "    .agg(\n",
    "        F.sum('cashIn').alias('netCashIn'),\n",
    "        F.sum('cashOut').alias('netCashOut')\n",
    "    )\n",
    "    .withColumn('netCash', F.col('netCashIn') + F.col('netCashOut'))\n",
    "    .groupBy('accountId')\n",
    "    .agg(\n",
    "        F.count(F.when(F.col('netCash') < 0, F.lit(1))).alias('nBuyDays'),\n",
    "        F.count(F.when(F.col('netCash') > 0, F.lit(1))).alias('nSellDays')\n",
    "    )\n",
    "    .fillna(0, subset = ['nBuyDays', 'nSellDays'])\n",
    ")\n",
    "\n",
    "display_df(active_days_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a9d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_trade_df = (\n",
    "    trade_df\n",
    "        .select(\n",
    "        'date',\n",
    "        'symbol',\n",
    "        F.col('buyerAccountId').alias('accountId'),\n",
    "        'nTradeShares',\n",
    "        (-F.col('tradeSettlementValue')).alias('settlementValue'),\n",
    "        )\n",
    ")\n",
    "\n",
    "sell_trade_df = (\n",
    "    trade_df\n",
    "        .select(\n",
    "            'date',\n",
    "            'symbol',\n",
    "            F.col('sellerAccountId').alias('accountId'),\n",
    "            (-F.col('nTradeShares')).alias('nTradeShares'),\n",
    "            F.col('tradeSettlementValue').alias('settlementValue')\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2e1e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_kpi_df = (\n",
    "    buy_trade_df\n",
    "    .union(sell_trade_df)\n",
    "    .groupBy('accountId')\n",
    "    .agg(\n",
    "        F.count(F.lit(1)).alias('tradeFrequency'),\n",
    "        F.mean(F.abs('settlementValue')).alias('meanTradeValue'),\n",
    "        F.sum('settlementValue').alias('netSumTradeValue'),\n",
    "        F.sum(F.abs('settlementValue')).alias('absSumTradeValue'),\n",
    "        F.countDistinct('date').alias('activeDays'),\n",
    "    )\n",
    "    .join(active_days_df, on = 'accountId')\n",
    ")\n",
    "\n",
    "display_df(trade_kpi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34facbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    trade_kpi_df\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(tradeFrequency, array(0.25))')[0], 2).alias('25% percentile'),\n",
    "        F.round(F.expr('percentile(tradeFrequency, array(0.5))')[0], 2).alias('50% percentile'),\n",
    "        F.round(F.mean('tradeFrequency'), 2).alias('mean'),\n",
    "        F.round(F.expr('percentile(tradeFrequency, array(0.75))')[0], 2).alias('75% percentile'),\n",
    "        F.round(F.expr('percentile(tradeFrequency, array(0.9))')[0], 2).alias('90% percentile'),\n",
    "        F.round(F.expr('percentile(tradeFrequency, array(0.99))')[0], 2).alias('99% percentile'),\n",
    "        F.round(F.expr('percentile(tradeFrequency, array(0.999))')[0], 2).alias('99.9% percentile'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c557d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     trade_kpi_df\n",
    "#     .agg(\n",
    "#         F.round(F.expr('percentile(meanTradeValue, array(0.25))')[0], 2).alias('25% percentile'),\n",
    "#         F.round(F.expr('percentile(meanTradeValue, array(0.5))')[0], 2).alias('50% percentile'),\n",
    "#         F.round(F.mean('meanTradeValue'), 2).alias('mean'),\n",
    "#         F.round(F.expr('percentile(meanTradeValue, array(0.75))')[0], 2).alias('75% percentile'),\n",
    "#         F.round(F.expr('percentile(meanTradeValue, array(0.9))')[0], 2).alias('90% percentile'),\n",
    "#         F.round(F.expr('percentile(meanTradeValue, array(0.99))')[0], 2).alias('99% percentile'),\n",
    "#         F.round(F.expr('percentile(meanTradeValue, array(0.999))')[0], 2).alias('99.9% percentile'),\n",
    "#     )\n",
    "#     .show()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     trade_kpi_df\n",
    "#     .agg(\n",
    "#         F.round(F.expr('percentile(netSumTradeValue, array(0.25))')[0], 2).alias('25% percentile'),\n",
    "#         F.round(F.expr('percentile(netSumTradeValue, array(0.5))')[0], 2).alias('50% percentile'),\n",
    "#         F.round(F.mean('netSumTradeValue'), 2).alias('mean'),\n",
    "#         F.round(F.expr('percentile(netSumTradeValue, array(0.75))')[0], 2).alias('75% percentile'),\n",
    "#         F.round(F.expr('percentile(netSumTradeValue, array(0.9))')[0], 2).alias('90% percentile'),\n",
    "#         F.round(F.expr('percentile(netSumTradeValue, array(0.99))')[0], 2).alias('99% percentile'),\n",
    "#         F.round(F.expr('percentile(netSumTradeValue, array(0.999))')[0], 2).alias('99.9% percentile'),\n",
    "#     )\n",
    "#     .show()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7628e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     trade_kpi_df\n",
    "#     .agg(\n",
    "#         F.round(F.expr('percentile(absSumTradeValue, array(0.25))')[0], 2).alias('25% percentile'),\n",
    "#         F.round(F.expr('percentile(absSumTradeValue, array(0.5))')[0], 2).alias('50% percentile'),\n",
    "#         F.round(F.mean('absSumTradeValue'), 2).alias('mean'),\n",
    "#         F.round(F.expr('percentile(absSumTradeValue, array(0.75))')[0], 2).alias('75% percentile'),\n",
    "#         F.round(F.expr('percentile(absSumTradeValue, array(0.9))')[0], 2).alias('90% percentile'),\n",
    "#         F.round(F.expr('percentile(absSumTradeValue, array(0.99))')[0], 2).alias('99% percentile'),\n",
    "#         F.round(F.expr('percentile(absSumTradeValue, array(0.999))')[0], 2).alias('99.9% percentile'),\n",
    "#     )\n",
    "#     .show()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    trade_kpi_df\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(activeDays, array(0.25))')[0], 2).alias('25% percentile'),\n",
    "        F.round(F.expr('percentile(activeDays, array(0.5))')[0], 2).alias('50% percentile'),\n",
    "        F.round(F.mean('activeDays'), 2).alias('mean'),\n",
    "        F.round(F.expr('percentile(activeDays, array(0.75))')[0], 2).alias('75% percentile'),\n",
    "        F.round(F.expr('percentile(activeDays, array(0.9))')[0], 2).alias('90% percentile'),\n",
    "        F.round(F.expr('percentile(activeDays, array(0.99))')[0], 2).alias('99% percentile'),\n",
    "        F.round(F.expr('percentile(activeDays, array(0.999))')[0], 2).alias('99.9% percentile'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a55f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    trade_kpi_df\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(nBuyDays, array(0.25))')[0], 2).alias('25% percentile'),\n",
    "        F.round(F.expr('percentile(nBuyDays, array(0.5))')[0], 2).alias('50% percentile'),\n",
    "        F.round(F.mean('nBuyDays'), 2).alias('mean'),\n",
    "        F.round(F.expr('percentile(nBuyDays, array(0.75))')[0], 2).alias('75% percentile'),\n",
    "        F.round(F.expr('percentile(nBuyDays, array(0.9))')[0], 2).alias('90% percentile'),\n",
    "        F.round(F.expr('percentile(nBuyDays, array(0.99))')[0], 2).alias('99% percentile'),\n",
    "        F.round(F.expr('percentile(nBuyDays, array(0.999))')[0], 2).alias('99.9% percentile'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2270b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    trade_kpi_df\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(nSellDays, array(0.25))')[0], 2).alias('25% percentile'),\n",
    "        F.round(F.expr('percentile(nSellDays, array(0.5))')[0], 2).alias('50% percentile'),\n",
    "        F.round(F.mean('nSellDays'), 2).alias('mean'),\n",
    "        F.round(F.expr('percentile(nSellDays, array(0.75))')[0], 2).alias('75% percentile'),\n",
    "        F.round(F.expr('percentile(nSellDays, array(0.9))')[0], 2).alias('90% percentile'),\n",
    "        F.round(F.expr('percentile(nSellDays, array(0.99))')[0], 2).alias('99% percentile'),\n",
    "        F.round(F.expr('percentile(nSellDays, array(0.999))')[0], 2).alias('99.9% percentile'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69836438",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trade_kpi_df.count() - trade_kpi_df.dropna().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8cec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trade_output_df = (\n",
    "    trade_kpi_df\n",
    "    .join(return_df.select('accountId', 'return').dropDuplicates(), on = ['accountId'])\n",
    "    .dropna()\n",
    "    .withColumn('tradeFrequencyDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('tradeFrequency')))\n",
    "    .withColumn('meanTradeValueDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('meanTradeValue')))\n",
    "    .withColumn('netSumTradeValueDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('netSumTradeValue')))\n",
    "    .withColumn('absSumTradeValueDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('absSumTradeValue')))\n",
    "    .withColumn('activeDaysDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('activeDays')))\n",
    "    .withColumn('nBuyDaysDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('nBuyDays')))\n",
    "    .withColumn('nSellDaysDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('nSellDays')))\n",
    ")\n",
    "\n",
    "display_df(trade_output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dadb7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(trade_output_df.filter(F.col('return') >= 0.35).count() / trade_output_df.count() ,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    trade_output_df\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178daac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    trade_output_df\n",
    "    .groupBy('tradeFrequencyDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .orderBy('tradeFrequencyDecile')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f71a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_output_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/trade_output.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f061bd",
   "metadata": {},
   "source": [
    "### identify block holders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c64d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_df = (\n",
    "    daily_portfolio_df\n",
    "    .select('date', 'symbol', 'accountId', 'heldShares')\n",
    "    .join(price_df.select('date', 'symbol', 'shrout'), on = ['date', 'symbol'])\n",
    "    .withColumn('ownership', F.col('heldShares') / F.col('shrout'))\n",
    "    .filter( (F.col('ownership') >= 0.01) & F.col('ownership').isNotNull() )\n",
    "    .select('accountId')\n",
    "    .distinct()\n",
    "    .withColumn('isBH', F.lit(1))\n",
    ")\n",
    "\n",
    "display_df(bh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fc40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_output_df = (\n",
    "    return_df\n",
    "    .select('accountId', 'return')\n",
    "    .dropna()\n",
    "    .join(bh_df, on = 'accountId', how = 'left')\n",
    "    .fillna(0, 'isBH')\n",
    ")\n",
    "\n",
    "display_df(bh_output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f1ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    bh_output_df\n",
    "    .groupBy('isBH')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianTradeFrequency')\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5049fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_output_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/bhOutput.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c60934",
   "metadata": {},
   "source": [
    "### number of stocks within initial portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab6bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stocks_within_initial_portfolio_df = (\n",
    "    portfolio_df\n",
    "    .groupBy('accountId')\n",
    "    .agg(\n",
    "        F.count(F.lit(1)).alias('nStocksWithinInitialPortfolio')\n",
    "    )\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "display_df(n_stocks_within_initial_portfolio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ace9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    n_stocks_within_initial_portfolio_df\n",
    "    .agg(\n",
    "        F.expr('percentile(nStocksWithinInitialPortfolio, array(0.25))')[0].alias('25%'),\n",
    "        F.expr('percentile(nStocksWithinInitialPortfolio, array(0.50))')[0].alias('50%'),\n",
    "        F.round(F.mean('nStocksWithinInitialPortfolio'), 4).alias('mean'),\n",
    "        F.expr('percentile(nStocksWithinInitialPortfolio, array(0.75))')[0].alias('75%'),\n",
    "        F.expr('percentile(nStocksWithinInitialPortfolio, array(0.9))')[0].alias('90%'),\n",
    "        F.expr('percentile(nStocksWithinInitialPortfolio, array(0.99))')[0].alias('99%'),\n",
    "        F.expr('percentile(nStocksWithinInitialPortfolio, array(0.999))')[0].alias('99.9%'),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2e38a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stocks_within_initial_portfolio_output_df = (\n",
    "    return_df\n",
    "    .select('accountId', 'return')\n",
    "    .dropna()\n",
    "    .join(n_stocks_within_initial_portfolio_df, on = 'accountId', how = 'inner')\n",
    "    .withColumn('nStocksWithinInitialPortfolioDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('nStocksWithinInitialPortfolio')))\n",
    ")\n",
    "\n",
    "display_df(n_stocks_within_initial_portfolio_output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864f21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    n_stocks_within_initial_portfolio_output_df\n",
    "    .groupBy('nStocksWithinInitialPortfolioDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .orderBy('nStocksWithinInitialPortfolioDecile')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8613fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stocks_within_initial_portfolio_output_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/n_initial_portfolio.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7933d8",
   "metadata": {},
   "source": [
    "### number of stocks within final portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f432cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stocks_within_final_portfolio_df = (\n",
    "    daily_portfolio_df\n",
    "    .withColumn('rowNumber', F.row_number().over(Window.partitionBy('accountId', 'symbol').orderBy('date')))\n",
    "    .withColumn('maxRowNumber', F.max('rowNumber').over(Window.partitionBy('accountId', 'symbol')))\n",
    "    .filter(F.col('rowNumber') == F.col('maxRowNumber'))\n",
    "    .filter(F.col('heldShares') > 0)\n",
    "    .withColumn('date', F.lit(MAX_PRICE_DATE))\n",
    "    .join(price_df.select('date', 'symbol', 'close_price'), on = ['date', 'symbol'], how = 'left')\n",
    "    .dropna(subset = ['close_price'])\n",
    "    .groupBy('accountId')\n",
    "    .agg(\n",
    "        F.countDistinct('symbol').alias('nStocksWithinFinalPortfolio')\n",
    "    )   \n",
    ")\n",
    "\n",
    "display_df(n_stocks_within_final_portfolio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a10563",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stocks_within_final_portfolio_output_df = (\n",
    "    return_df\n",
    "    .select('accountId', 'return')\n",
    "    .dropna()\n",
    "    .join(n_stocks_within_final_portfolio_df, on = 'accountId', how = 'inner')\n",
    "    .withColumn('nStocksWithinFinalPortfolioDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy('nStocksWithinFinalPortfolio')))\n",
    ")\n",
    "\n",
    "display_df(n_stocks_within_final_portfolio_output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932ef467",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    n_stocks_within_final_portfolio_output_df\n",
    "    .groupBy('nStocksWithinFinalPortfolioDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .orderBy('nStocksWithinFinalPortfolioDecile')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee5b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stocks_within_final_portfolio_output_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/n_final_portfolio.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a87605",
   "metadata": {},
   "source": [
    "### turnover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab037f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "turnover_df = (\n",
    "    trade_kpi_df\n",
    "    .join(final_portfolio_value_df, on =['accountId'], how = 'left')\n",
    "    .withColumn('turnover', F.col('absSumTradeValue') / F.col('finalPortfolioValue'))\n",
    "    .join(return_df.select('accountId', 'return'), on = 'accountId')\n",
    "    .withColumn('turnoverDecile', F.ntile(N_QUANTILES).over(Window.partitionBy().orderBy(F.col('turnover'))))\n",
    "    .select(\n",
    "        'accountId',\n",
    "        'turnover',\n",
    "        'turnoverDecile',\n",
    "        'return'\n",
    "    )\n",
    ")\n",
    "\n",
    "display_df(turnover_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eee8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    turnover_df\n",
    "    .groupBy('turnoverDecile')\n",
    "    .agg(\n",
    "        F.round(F.expr('percentile(return, array(0.5))')[0], 3).alias('medianReturn')\n",
    "    )\n",
    "    .orderBy('turnoverDecile')\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a07c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "turnover_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/turnover.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dd9b65",
   "metadata": {},
   "source": [
    "### time series of the number of stocks within portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16aa62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_list = (\n",
    "    price_df\n",
    "    .select('date')\n",
    "    .distinct()\n",
    "    .orderBy('date')\n",
    "    .rdd.flatMap(lambda x: x).collect()\n",
    ")\n",
    "\n",
    "print(dates_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3598a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nStocksWithinPortfolioOfAllInvestors = []\n",
    "nInvestors = []\n",
    "\n",
    "for date in dates_list:\n",
    "    print(date)\n",
    "    result = (\n",
    "        daily_portfolio_df\n",
    "        .filter(F.col('date') <= date)\n",
    "        .withColumn('rowNumber', F.row_number().over(Window.partitionBy('accountId', 'symbol').orderBy('date')))\n",
    "        .withColumn('maxRowNumber', F.max('rowNumber').over(Window.partitionBy('accountId', 'symbol')))\n",
    "        .filter(F.col('rowNumber') == F.col('maxRowNumber'))\n",
    "        .filter( (F.col('heldShares') > 0) & (F.col('heldShares').isNotNull()) )\n",
    "        .groupBy('accountId')\n",
    "        .agg(\n",
    "            F.count(F.lit(1)).alias('nStocksWithinPortfolioOfAllInvestors'),\n",
    "        )\n",
    "        .agg(\n",
    "            F.round(F.mean('nStocksWithinPortfolioOfAllInvestors'), 3).alias('nStocksWithinPortfolioOfAllInvestors'),\n",
    "            F.count(F.lit(1)).alias('nInvestors')\n",
    "        )\n",
    "    )\n",
    "    nStocksWithinPortfolioOfAllInvestors.append(result.collect()[0][0])\n",
    "    nInvestors.append(result.collect()[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2688e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stocks_df = spark.createDataFrame(\n",
    "    pd.DataFrame({\n",
    "        'date' : dates_list,\n",
    "        'nStocksWithinPortfolioOfAllInvestors' : nStocksWithinPortfolioOfAllInvestors,\n",
    "        'nInvestors' : nInvestors\n",
    "    })\n",
    ")\n",
    "\n",
    "display_df(n_stocks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83933cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stocks_df.write.mode('overwrite').parquet('/home/user1/Data/Esmaeil/mean_number_of_stocks_within_portfolio.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b51f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_ids =  [row['accountId'] for row in portfolio_df.select('accountId').distinct().collect()]\n",
    "initial_ids = set(initial_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a93bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id_trade = flat_trade_df.dropDuplicates(subset=['accountId','date'])\n",
    "unique_id_trade.count()\n",
    "result = {}\n",
    "for date in dates_list[:3]:\n",
    "    print(len(initial_ids))\n",
    "    tempt = unique_id_trade.filter(F.col('date') == date).select('accountId').distinct().collect()\n",
    "    teades_ids = set([row['accountId'] for row in tempt])\n",
    "    result[date] = len(teades_ids -initial_ids )\n",
    "    \n",
    "    initial_ids =  set.union(initial_ids, teades_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14de4eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
